{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOy4AC8SyHlcqi1NQWnq3Z6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Park-New-project/2022_AI_Study_Course/blob/main/%5BAI%5D_221031.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49et6O3_Ql1O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c22395c9-eafe-4fea-bdca-95bf35616442"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.6.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQSwpFrX4-DX",
        "outputId": "8aada784-44c5-485f-b2cc-92ef2f162d78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow==2.6.1 in /usr/local/lib/python3.7/dist-packages (2.6.1)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.1) (3.19.6)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.1) (1.1.0)\n",
            "Requirement already satisfied: clang~=5.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.1) (5.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.1) (3.7.4.3)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.1) (3.1.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.37.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.1) (1.50.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.1) (3.3.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.1) (1.6.3)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.1) (0.2.0)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.1) (0.4.0)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.1) (2.9.1)\n",
            "Requirement already satisfied: keras~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.1) (2.6.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.1) (1.1.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.1) (2.6.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.1) (1.12)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.1) (1.15.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.1) (0.15.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.1) (0.38.3)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.1) (1.19.5)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.1) (1.12.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow==2.6.1) (1.5.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.6.1) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.6.1) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.6.1) (2.14.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.6.1) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.6.1) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.6.1) (2.23.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.6.1) (57.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.6.1) (3.4.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.6.1) (5.2.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.6.1) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.6.1) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow==2.6.1) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow==2.6.1) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow==2.6.1) (3.10.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.6.1) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.6.1) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.6.1) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.6.1) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.6.1) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow==2.6.1) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras==2.6"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgbQMeox4_dj",
        "outputId": "48612348-1b7f-4348-c84d-087bbb58c0a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras==2.6 in /usr/local/lib/python3.7/dist-packages (2.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "26RQX8_07VWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_read = pd.read_csv(\"/content/gdrive/MyDrive/Colab/data/wine.csv\", header=None)\n",
        "df_read"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "nvF3aFQL5BGC",
        "outputId": "9817072e-8816-4f97-8cfd-70e2f36d3bfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        0     1     2    3      4     5      6        7     8     9     10  \\\n",
              "0      7.4  0.70  0.00  1.9  0.076  11.0   34.0  0.99780  3.51  0.56   9.4   \n",
              "1      7.8  0.88  0.00  2.6  0.098  25.0   67.0  0.99680  3.20  0.68   9.8   \n",
              "2      7.8  0.76  0.04  2.3  0.092  15.0   54.0  0.99700  3.26  0.65   9.8   \n",
              "3     11.2  0.28  0.56  1.9  0.075  17.0   60.0  0.99800  3.16  0.58   9.8   \n",
              "4      7.4  0.70  0.00  1.9  0.076  11.0   34.0  0.99780  3.51  0.56   9.4   \n",
              "...    ...   ...   ...  ...    ...   ...    ...      ...   ...   ...   ...   \n",
              "6492   6.2  0.21  0.29  1.6  0.039  24.0   92.0  0.99114  3.27  0.50  11.2   \n",
              "6493   6.6  0.32  0.36  8.0  0.047  57.0  168.0  0.99490  3.15  0.46   9.6   \n",
              "6494   6.5  0.24  0.19  1.2  0.041  30.0  111.0  0.99254  2.99  0.46   9.4   \n",
              "6495   5.5  0.29  0.30  1.1  0.022  20.0  110.0  0.98869  3.34  0.38  12.8   \n",
              "6496   6.0  0.21  0.38  0.8  0.020  22.0   98.0  0.98941  3.26  0.32  11.8   \n",
              "\n",
              "      11  12  \n",
              "0      5   1  \n",
              "1      5   1  \n",
              "2      5   1  \n",
              "3      6   1  \n",
              "4      5   1  \n",
              "...   ..  ..  \n",
              "6492   6   0  \n",
              "6493   5   0  \n",
              "6494   6   0  \n",
              "6495   7   0  \n",
              "6496   6   0  \n",
              "\n",
              "[6497 rows x 13 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4f993049-7b12-4935-9f78-3be35548660e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.076</td>\n",
              "      <td>11.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.99780</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.6</td>\n",
              "      <td>0.098</td>\n",
              "      <td>25.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>0.99680</td>\n",
              "      <td>3.20</td>\n",
              "      <td>0.68</td>\n",
              "      <td>9.8</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.04</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0.092</td>\n",
              "      <td>15.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0.99700</td>\n",
              "      <td>3.26</td>\n",
              "      <td>0.65</td>\n",
              "      <td>9.8</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.2</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.56</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.075</td>\n",
              "      <td>17.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>0.99800</td>\n",
              "      <td>3.16</td>\n",
              "      <td>0.58</td>\n",
              "      <td>9.8</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.076</td>\n",
              "      <td>11.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.99780</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6492</th>\n",
              "      <td>6.2</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.29</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.039</td>\n",
              "      <td>24.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>0.99114</td>\n",
              "      <td>3.27</td>\n",
              "      <td>0.50</td>\n",
              "      <td>11.2</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6493</th>\n",
              "      <td>6.6</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.36</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.047</td>\n",
              "      <td>57.0</td>\n",
              "      <td>168.0</td>\n",
              "      <td>0.99490</td>\n",
              "      <td>3.15</td>\n",
              "      <td>0.46</td>\n",
              "      <td>9.6</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6494</th>\n",
              "      <td>6.5</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.19</td>\n",
              "      <td>1.2</td>\n",
              "      <td>0.041</td>\n",
              "      <td>30.0</td>\n",
              "      <td>111.0</td>\n",
              "      <td>0.99254</td>\n",
              "      <td>2.99</td>\n",
              "      <td>0.46</td>\n",
              "      <td>9.4</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6495</th>\n",
              "      <td>5.5</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.30</td>\n",
              "      <td>1.1</td>\n",
              "      <td>0.022</td>\n",
              "      <td>20.0</td>\n",
              "      <td>110.0</td>\n",
              "      <td>0.98869</td>\n",
              "      <td>3.34</td>\n",
              "      <td>0.38</td>\n",
              "      <td>12.8</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6496</th>\n",
              "      <td>6.0</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.020</td>\n",
              "      <td>22.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>0.98941</td>\n",
              "      <td>3.26</td>\n",
              "      <td>0.32</td>\n",
              "      <td>11.8</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6497 rows × 13 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4f993049-7b12-4935-9f78-3be35548660e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4f993049-7b12-4935-9f78-3be35548660e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4f993049-7b12-4935-9f78-3be35548660e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df_read.sample(frac=1) # 전체 데이터가 많을 때 일부만 랜덤하게 data 추출\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "j_0QQaBT5vFr",
        "outputId": "23ba954d-352b-49d3-c3d7-dedb285edb04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       0     1     2      3      4     5      6        7     8     9      10  \\\n",
              "4975  6.6  0.18  0.28   1.70  0.041  53.0  161.0  0.99207  3.13  0.45  10.20   \n",
              "2455  8.2  0.38  0.49  13.60  0.042  58.0  166.0  0.99855  3.10  0.54   9.40   \n",
              "5534  7.0  0.46  0.20  16.70  0.046  50.0  184.0  0.99898  3.08  0.56   9.40   \n",
              "933   7.4  0.61  0.01   2.00  0.074  13.0   38.0  0.99748  3.48  0.65   9.80   \n",
              "6036  6.5  0.29  0.30   9.15  0.051  25.0  166.0  0.99339  3.24  0.56  11.35   \n",
              "...   ...   ...   ...    ...    ...   ...    ...      ...   ...   ...    ...   \n",
              "1945  5.6  0.34  0.10   1.30  0.031  20.0   68.0  0.99060  3.36  0.51  11.20   \n",
              "2172  7.2  0.20  0.34   2.70  0.032  49.0  151.0  0.99000  3.16  0.39  12.70   \n",
              "5487  6.0  0.28  0.24  17.80  0.047  42.0  111.0  0.99896  3.10  0.45   8.90   \n",
              "5385  7.4  0.29  0.48  12.80  0.037  61.5  182.0  0.99808  3.02  0.34   8.80   \n",
              "2484  6.1  0.34  0.27   2.60  0.024  20.0  105.0  0.99060  3.40  0.67  12.20   \n",
              "\n",
              "      11  12  \n",
              "4975   6   0  \n",
              "2455   5   0  \n",
              "5534   5   0  \n",
              "933    5   1  \n",
              "6036   6   0  \n",
              "...   ..  ..  \n",
              "1945   7   0  \n",
              "2172   7   0  \n",
              "5487   6   0  \n",
              "5385   5   0  \n",
              "2484   7   0  \n",
              "\n",
              "[6497 rows x 13 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7fd38d54-7f4a-4f76-b39d-337c3be597e0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4975</th>\n",
              "      <td>6.6</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.28</td>\n",
              "      <td>1.70</td>\n",
              "      <td>0.041</td>\n",
              "      <td>53.0</td>\n",
              "      <td>161.0</td>\n",
              "      <td>0.99207</td>\n",
              "      <td>3.13</td>\n",
              "      <td>0.45</td>\n",
              "      <td>10.20</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2455</th>\n",
              "      <td>8.2</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.49</td>\n",
              "      <td>13.60</td>\n",
              "      <td>0.042</td>\n",
              "      <td>58.0</td>\n",
              "      <td>166.0</td>\n",
              "      <td>0.99855</td>\n",
              "      <td>3.10</td>\n",
              "      <td>0.54</td>\n",
              "      <td>9.40</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5534</th>\n",
              "      <td>7.0</td>\n",
              "      <td>0.46</td>\n",
              "      <td>0.20</td>\n",
              "      <td>16.70</td>\n",
              "      <td>0.046</td>\n",
              "      <td>50.0</td>\n",
              "      <td>184.0</td>\n",
              "      <td>0.99898</td>\n",
              "      <td>3.08</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.40</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>933</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0.01</td>\n",
              "      <td>2.00</td>\n",
              "      <td>0.074</td>\n",
              "      <td>13.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>0.99748</td>\n",
              "      <td>3.48</td>\n",
              "      <td>0.65</td>\n",
              "      <td>9.80</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6036</th>\n",
              "      <td>6.5</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.30</td>\n",
              "      <td>9.15</td>\n",
              "      <td>0.051</td>\n",
              "      <td>25.0</td>\n",
              "      <td>166.0</td>\n",
              "      <td>0.99339</td>\n",
              "      <td>3.24</td>\n",
              "      <td>0.56</td>\n",
              "      <td>11.35</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1945</th>\n",
              "      <td>5.6</td>\n",
              "      <td>0.34</td>\n",
              "      <td>0.10</td>\n",
              "      <td>1.30</td>\n",
              "      <td>0.031</td>\n",
              "      <td>20.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>0.99060</td>\n",
              "      <td>3.36</td>\n",
              "      <td>0.51</td>\n",
              "      <td>11.20</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2172</th>\n",
              "      <td>7.2</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.34</td>\n",
              "      <td>2.70</td>\n",
              "      <td>0.032</td>\n",
              "      <td>49.0</td>\n",
              "      <td>151.0</td>\n",
              "      <td>0.99000</td>\n",
              "      <td>3.16</td>\n",
              "      <td>0.39</td>\n",
              "      <td>12.70</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5487</th>\n",
              "      <td>6.0</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.24</td>\n",
              "      <td>17.80</td>\n",
              "      <td>0.047</td>\n",
              "      <td>42.0</td>\n",
              "      <td>111.0</td>\n",
              "      <td>0.99896</td>\n",
              "      <td>3.10</td>\n",
              "      <td>0.45</td>\n",
              "      <td>8.90</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5385</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.48</td>\n",
              "      <td>12.80</td>\n",
              "      <td>0.037</td>\n",
              "      <td>61.5</td>\n",
              "      <td>182.0</td>\n",
              "      <td>0.99808</td>\n",
              "      <td>3.02</td>\n",
              "      <td>0.34</td>\n",
              "      <td>8.80</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2484</th>\n",
              "      <td>6.1</td>\n",
              "      <td>0.34</td>\n",
              "      <td>0.27</td>\n",
              "      <td>2.60</td>\n",
              "      <td>0.024</td>\n",
              "      <td>20.0</td>\n",
              "      <td>105.0</td>\n",
              "      <td>0.99060</td>\n",
              "      <td>3.40</td>\n",
              "      <td>0.67</td>\n",
              "      <td>12.20</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6497 rows × 13 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7fd38d54-7f4a-4f76-b39d-337c3be597e0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7fd38d54-7f4a-4f76-b39d-337c3be597e0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7fd38d54-7f4a-4f76-b39d-337c3be597e0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "092qp4DB6ksd",
        "outputId": "912d2bb7-bf02-4a7d-ee84-1c356dc2d9e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 6497 entries, 4975 to 2484\n",
            "Data columns (total 13 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   0       6497 non-null   float64\n",
            " 1   1       6497 non-null   float64\n",
            " 2   2       6497 non-null   float64\n",
            " 3   3       6497 non-null   float64\n",
            " 4   4       6497 non-null   float64\n",
            " 5   5       6497 non-null   float64\n",
            " 6   6       6497 non-null   float64\n",
            " 7   7       6497 non-null   float64\n",
            " 8   8       6497 non-null   float64\n",
            " 9   9       6497 non-null   float64\n",
            " 10  10      6497 non-null   float64\n",
            " 11  11      6497 non-null   int64  \n",
            " 12  12      6497 non-null   int64  \n",
            "dtypes: float64(11), int64(2)\n",
            "memory usage: 710.6 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=df.iloc[:,0:12]\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "PeblbLYV6pXA",
        "outputId": "9ee835e1-dfe8-4558-f1f3-fe9c3cfa63cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       0     1     2      3      4     5      6        7     8     9      10  \\\n",
              "4975  6.6  0.18  0.28   1.70  0.041  53.0  161.0  0.99207  3.13  0.45  10.20   \n",
              "2455  8.2  0.38  0.49  13.60  0.042  58.0  166.0  0.99855  3.10  0.54   9.40   \n",
              "5534  7.0  0.46  0.20  16.70  0.046  50.0  184.0  0.99898  3.08  0.56   9.40   \n",
              "933   7.4  0.61  0.01   2.00  0.074  13.0   38.0  0.99748  3.48  0.65   9.80   \n",
              "6036  6.5  0.29  0.30   9.15  0.051  25.0  166.0  0.99339  3.24  0.56  11.35   \n",
              "...   ...   ...   ...    ...    ...   ...    ...      ...   ...   ...    ...   \n",
              "1945  5.6  0.34  0.10   1.30  0.031  20.0   68.0  0.99060  3.36  0.51  11.20   \n",
              "2172  7.2  0.20  0.34   2.70  0.032  49.0  151.0  0.99000  3.16  0.39  12.70   \n",
              "5487  6.0  0.28  0.24  17.80  0.047  42.0  111.0  0.99896  3.10  0.45   8.90   \n",
              "5385  7.4  0.29  0.48  12.80  0.037  61.5  182.0  0.99808  3.02  0.34   8.80   \n",
              "2484  6.1  0.34  0.27   2.60  0.024  20.0  105.0  0.99060  3.40  0.67  12.20   \n",
              "\n",
              "      11  \n",
              "4975   6  \n",
              "2455   5  \n",
              "5534   5  \n",
              "933    5  \n",
              "6036   6  \n",
              "...   ..  \n",
              "1945   7  \n",
              "2172   7  \n",
              "5487   6  \n",
              "5385   5  \n",
              "2484   7  \n",
              "\n",
              "[6497 rows x 12 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-80755f81-53ce-446e-91eb-34dd5231524f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4975</th>\n",
              "      <td>6.6</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.28</td>\n",
              "      <td>1.70</td>\n",
              "      <td>0.041</td>\n",
              "      <td>53.0</td>\n",
              "      <td>161.0</td>\n",
              "      <td>0.99207</td>\n",
              "      <td>3.13</td>\n",
              "      <td>0.45</td>\n",
              "      <td>10.20</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2455</th>\n",
              "      <td>8.2</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.49</td>\n",
              "      <td>13.60</td>\n",
              "      <td>0.042</td>\n",
              "      <td>58.0</td>\n",
              "      <td>166.0</td>\n",
              "      <td>0.99855</td>\n",
              "      <td>3.10</td>\n",
              "      <td>0.54</td>\n",
              "      <td>9.40</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5534</th>\n",
              "      <td>7.0</td>\n",
              "      <td>0.46</td>\n",
              "      <td>0.20</td>\n",
              "      <td>16.70</td>\n",
              "      <td>0.046</td>\n",
              "      <td>50.0</td>\n",
              "      <td>184.0</td>\n",
              "      <td>0.99898</td>\n",
              "      <td>3.08</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.40</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>933</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0.01</td>\n",
              "      <td>2.00</td>\n",
              "      <td>0.074</td>\n",
              "      <td>13.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>0.99748</td>\n",
              "      <td>3.48</td>\n",
              "      <td>0.65</td>\n",
              "      <td>9.80</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6036</th>\n",
              "      <td>6.5</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.30</td>\n",
              "      <td>9.15</td>\n",
              "      <td>0.051</td>\n",
              "      <td>25.0</td>\n",
              "      <td>166.0</td>\n",
              "      <td>0.99339</td>\n",
              "      <td>3.24</td>\n",
              "      <td>0.56</td>\n",
              "      <td>11.35</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1945</th>\n",
              "      <td>5.6</td>\n",
              "      <td>0.34</td>\n",
              "      <td>0.10</td>\n",
              "      <td>1.30</td>\n",
              "      <td>0.031</td>\n",
              "      <td>20.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>0.99060</td>\n",
              "      <td>3.36</td>\n",
              "      <td>0.51</td>\n",
              "      <td>11.20</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2172</th>\n",
              "      <td>7.2</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.34</td>\n",
              "      <td>2.70</td>\n",
              "      <td>0.032</td>\n",
              "      <td>49.0</td>\n",
              "      <td>151.0</td>\n",
              "      <td>0.99000</td>\n",
              "      <td>3.16</td>\n",
              "      <td>0.39</td>\n",
              "      <td>12.70</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5487</th>\n",
              "      <td>6.0</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.24</td>\n",
              "      <td>17.80</td>\n",
              "      <td>0.047</td>\n",
              "      <td>42.0</td>\n",
              "      <td>111.0</td>\n",
              "      <td>0.99896</td>\n",
              "      <td>3.10</td>\n",
              "      <td>0.45</td>\n",
              "      <td>8.90</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5385</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.48</td>\n",
              "      <td>12.80</td>\n",
              "      <td>0.037</td>\n",
              "      <td>61.5</td>\n",
              "      <td>182.0</td>\n",
              "      <td>0.99808</td>\n",
              "      <td>3.02</td>\n",
              "      <td>0.34</td>\n",
              "      <td>8.80</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2484</th>\n",
              "      <td>6.1</td>\n",
              "      <td>0.34</td>\n",
              "      <td>0.27</td>\n",
              "      <td>2.60</td>\n",
              "      <td>0.024</td>\n",
              "      <td>20.0</td>\n",
              "      <td>105.0</td>\n",
              "      <td>0.99060</td>\n",
              "      <td>3.40</td>\n",
              "      <td>0.67</td>\n",
              "      <td>12.20</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6497 rows × 12 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-80755f81-53ce-446e-91eb-34dd5231524f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-80755f81-53ce-446e-91eb-34dd5231524f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-80755f81-53ce-446e-91eb-34dd5231524f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y=df.iloc[:,12]\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HNeyqeNP7Grr",
        "outputId": "cc6ea86c-f089-446f-ab58-cc2668383809"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4975    0\n",
              "2455    0\n",
              "5534    0\n",
              "933     1\n",
              "6036    0\n",
              "       ..\n",
              "1945    0\n",
              "2172    0\n",
              "5487    0\n",
              "5385    0\n",
              "2484    0\n",
              "Name: 12, Length: 6497, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2, shuffle=True)"
      ],
      "metadata": {
        "id": "uOiSBukm7hfP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "KhL3S54M70Dq",
        "outputId": "84781281-cd39-49b5-b710-6753deff0221"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        0      1     2      3      4      5      6        7     8     9   \\\n",
              "2248   7.1  0.260  0.34  14.40  0.067   35.0  189.0  0.99860  3.07  0.53   \n",
              "4179   7.7  0.300  0.26  18.95  0.053   36.0  174.0  0.99976  3.20  0.50   \n",
              "5675   7.4  0.370  0.26   9.60  0.050   33.0  134.0  0.99608  3.13  0.46   \n",
              "3217   6.4  0.370  0.49  13.30  0.045   53.0  243.0  0.99820  3.14  0.48   \n",
              "4338   6.8  0.320  0.28   4.80  0.034   25.0  100.0  0.99026  3.08  0.47   \n",
              "...    ...    ...   ...    ...    ...    ...    ...      ...   ...   ...   \n",
              "760    9.0  0.580  0.25   2.80  0.075    9.0  104.0  0.99779  3.23  0.57   \n",
              "259   10.0  0.310  0.47   2.60  0.085   14.0   33.0  0.99965  3.36  0.80   \n",
              "5678   5.4  0.265  0.28   7.80  0.052   27.0   91.0  0.99432  3.19  0.38   \n",
              "5122   6.0  0.230  0.15   9.70  0.048  101.0  207.0  0.99571  3.05  0.30   \n",
              "28     7.1  0.710  0.00   1.90  0.080   14.0   35.0  0.99720  3.47  0.55   \n",
              "\n",
              "        10  11  \n",
              "2248   9.1   7  \n",
              "4179  10.4   5  \n",
              "5675  10.4   5  \n",
              "3217   8.5   6  \n",
              "4338  12.4   7  \n",
              "...    ...  ..  \n",
              "760    9.7   5  \n",
              "259   10.5   7  \n",
              "5678  10.4   6  \n",
              "5122   9.1   5  \n",
              "28     9.4   5  \n",
              "\n",
              "[5197 rows x 12 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8b8659de-63d0-4a87-ad5b-9d19f6b649a2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2248</th>\n",
              "      <td>7.1</td>\n",
              "      <td>0.260</td>\n",
              "      <td>0.34</td>\n",
              "      <td>14.40</td>\n",
              "      <td>0.067</td>\n",
              "      <td>35.0</td>\n",
              "      <td>189.0</td>\n",
              "      <td>0.99860</td>\n",
              "      <td>3.07</td>\n",
              "      <td>0.53</td>\n",
              "      <td>9.1</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4179</th>\n",
              "      <td>7.7</td>\n",
              "      <td>0.300</td>\n",
              "      <td>0.26</td>\n",
              "      <td>18.95</td>\n",
              "      <td>0.053</td>\n",
              "      <td>36.0</td>\n",
              "      <td>174.0</td>\n",
              "      <td>0.99976</td>\n",
              "      <td>3.20</td>\n",
              "      <td>0.50</td>\n",
              "      <td>10.4</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5675</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.370</td>\n",
              "      <td>0.26</td>\n",
              "      <td>9.60</td>\n",
              "      <td>0.050</td>\n",
              "      <td>33.0</td>\n",
              "      <td>134.0</td>\n",
              "      <td>0.99608</td>\n",
              "      <td>3.13</td>\n",
              "      <td>0.46</td>\n",
              "      <td>10.4</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3217</th>\n",
              "      <td>6.4</td>\n",
              "      <td>0.370</td>\n",
              "      <td>0.49</td>\n",
              "      <td>13.30</td>\n",
              "      <td>0.045</td>\n",
              "      <td>53.0</td>\n",
              "      <td>243.0</td>\n",
              "      <td>0.99820</td>\n",
              "      <td>3.14</td>\n",
              "      <td>0.48</td>\n",
              "      <td>8.5</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4338</th>\n",
              "      <td>6.8</td>\n",
              "      <td>0.320</td>\n",
              "      <td>0.28</td>\n",
              "      <td>4.80</td>\n",
              "      <td>0.034</td>\n",
              "      <td>25.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.99026</td>\n",
              "      <td>3.08</td>\n",
              "      <td>0.47</td>\n",
              "      <td>12.4</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>760</th>\n",
              "      <td>9.0</td>\n",
              "      <td>0.580</td>\n",
              "      <td>0.25</td>\n",
              "      <td>2.80</td>\n",
              "      <td>0.075</td>\n",
              "      <td>9.0</td>\n",
              "      <td>104.0</td>\n",
              "      <td>0.99779</td>\n",
              "      <td>3.23</td>\n",
              "      <td>0.57</td>\n",
              "      <td>9.7</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>259</th>\n",
              "      <td>10.0</td>\n",
              "      <td>0.310</td>\n",
              "      <td>0.47</td>\n",
              "      <td>2.60</td>\n",
              "      <td>0.085</td>\n",
              "      <td>14.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>0.99965</td>\n",
              "      <td>3.36</td>\n",
              "      <td>0.80</td>\n",
              "      <td>10.5</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5678</th>\n",
              "      <td>5.4</td>\n",
              "      <td>0.265</td>\n",
              "      <td>0.28</td>\n",
              "      <td>7.80</td>\n",
              "      <td>0.052</td>\n",
              "      <td>27.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>0.99432</td>\n",
              "      <td>3.19</td>\n",
              "      <td>0.38</td>\n",
              "      <td>10.4</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5122</th>\n",
              "      <td>6.0</td>\n",
              "      <td>0.230</td>\n",
              "      <td>0.15</td>\n",
              "      <td>9.70</td>\n",
              "      <td>0.048</td>\n",
              "      <td>101.0</td>\n",
              "      <td>207.0</td>\n",
              "      <td>0.99571</td>\n",
              "      <td>3.05</td>\n",
              "      <td>0.30</td>\n",
              "      <td>9.1</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>7.1</td>\n",
              "      <td>0.710</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.90</td>\n",
              "      <td>0.080</td>\n",
              "      <td>14.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0.99720</td>\n",
              "      <td>3.47</td>\n",
              "      <td>0.55</td>\n",
              "      <td>9.4</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5197 rows × 12 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8b8659de-63d0-4a87-ad5b-9d19f6b649a2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8b8659de-63d0-4a87-ad5b-9d19f6b649a2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8b8659de-63d0-4a87-ad5b-9d19f6b649a2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "dzHh0Qqd70vB",
        "outputId": "fee3bf69-602f-46f0-b357-3cd4c5187a93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        0     1     2      3      4     5      6        7     8     9     10  \\\n",
              "2288   6.7  0.17  0.37   2.00  0.039  34.0  125.0  0.99220  3.26  0.60  10.8   \n",
              "1158   6.7  0.41  0.43   2.80  0.076  22.0   54.0  0.99572  3.42  1.16  10.6   \n",
              "1949   6.3  0.12  0.36   2.10  0.044  47.0  146.0  0.99140  3.27  0.74  11.4   \n",
              "1156   8.5  0.18  0.51   1.75  0.071  45.0   88.0  0.99524  3.33  0.76  11.8   \n",
              "5690   6.4  0.14  0.28   7.90  0.057  21.0   82.0  0.99425  3.26  0.36  10.0   \n",
              "...    ...   ...   ...    ...    ...   ...    ...      ...   ...   ...   ...   \n",
              "482   10.6  0.36  0.59   2.20  0.152   6.0   18.0  0.99860  3.04  1.05   9.4   \n",
              "5169   6.9  0.26  0.27   4.20  0.031  20.0   80.0  0.99089  3.12  0.39  11.5   \n",
              "4564   5.5  0.34  0.26   2.20  0.021  31.0  119.0  0.98919  3.55  0.49  13.0   \n",
              "3693   6.6  0.22  0.53  15.10  0.052  22.0  136.0  0.99860  2.94  0.35   9.4   \n",
              "5867   5.7  0.22  0.29   3.50  0.040  27.0  146.0  0.98999  3.17  0.36  12.1   \n",
              "\n",
              "      11  \n",
              "2288   7  \n",
              "1158   6  \n",
              "1949   7  \n",
              "1156   7  \n",
              "5690   6  \n",
              "...   ..  \n",
              "482    5  \n",
              "5169   6  \n",
              "4564   8  \n",
              "3693   5  \n",
              "5867   6  \n",
              "\n",
              "[1300 rows x 12 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3c63b9e5-2a06-4dc0-907a-209b87184b63\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2288</th>\n",
              "      <td>6.7</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.37</td>\n",
              "      <td>2.00</td>\n",
              "      <td>0.039</td>\n",
              "      <td>34.0</td>\n",
              "      <td>125.0</td>\n",
              "      <td>0.99220</td>\n",
              "      <td>3.26</td>\n",
              "      <td>0.60</td>\n",
              "      <td>10.8</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1158</th>\n",
              "      <td>6.7</td>\n",
              "      <td>0.41</td>\n",
              "      <td>0.43</td>\n",
              "      <td>2.80</td>\n",
              "      <td>0.076</td>\n",
              "      <td>22.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0.99572</td>\n",
              "      <td>3.42</td>\n",
              "      <td>1.16</td>\n",
              "      <td>10.6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1949</th>\n",
              "      <td>6.3</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.36</td>\n",
              "      <td>2.10</td>\n",
              "      <td>0.044</td>\n",
              "      <td>47.0</td>\n",
              "      <td>146.0</td>\n",
              "      <td>0.99140</td>\n",
              "      <td>3.27</td>\n",
              "      <td>0.74</td>\n",
              "      <td>11.4</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1156</th>\n",
              "      <td>8.5</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.51</td>\n",
              "      <td>1.75</td>\n",
              "      <td>0.071</td>\n",
              "      <td>45.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>0.99524</td>\n",
              "      <td>3.33</td>\n",
              "      <td>0.76</td>\n",
              "      <td>11.8</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5690</th>\n",
              "      <td>6.4</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.28</td>\n",
              "      <td>7.90</td>\n",
              "      <td>0.057</td>\n",
              "      <td>21.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>0.99425</td>\n",
              "      <td>3.26</td>\n",
              "      <td>0.36</td>\n",
              "      <td>10.0</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>482</th>\n",
              "      <td>10.6</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.59</td>\n",
              "      <td>2.20</td>\n",
              "      <td>0.152</td>\n",
              "      <td>6.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>0.99860</td>\n",
              "      <td>3.04</td>\n",
              "      <td>1.05</td>\n",
              "      <td>9.4</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5169</th>\n",
              "      <td>6.9</td>\n",
              "      <td>0.26</td>\n",
              "      <td>0.27</td>\n",
              "      <td>4.20</td>\n",
              "      <td>0.031</td>\n",
              "      <td>20.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>0.99089</td>\n",
              "      <td>3.12</td>\n",
              "      <td>0.39</td>\n",
              "      <td>11.5</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4564</th>\n",
              "      <td>5.5</td>\n",
              "      <td>0.34</td>\n",
              "      <td>0.26</td>\n",
              "      <td>2.20</td>\n",
              "      <td>0.021</td>\n",
              "      <td>31.0</td>\n",
              "      <td>119.0</td>\n",
              "      <td>0.98919</td>\n",
              "      <td>3.55</td>\n",
              "      <td>0.49</td>\n",
              "      <td>13.0</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3693</th>\n",
              "      <td>6.6</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.53</td>\n",
              "      <td>15.10</td>\n",
              "      <td>0.052</td>\n",
              "      <td>22.0</td>\n",
              "      <td>136.0</td>\n",
              "      <td>0.99860</td>\n",
              "      <td>2.94</td>\n",
              "      <td>0.35</td>\n",
              "      <td>9.4</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5867</th>\n",
              "      <td>5.7</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.29</td>\n",
              "      <td>3.50</td>\n",
              "      <td>0.040</td>\n",
              "      <td>27.0</td>\n",
              "      <td>146.0</td>\n",
              "      <td>0.98999</td>\n",
              "      <td>3.17</td>\n",
              "      <td>0.36</td>\n",
              "      <td>12.1</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1300 rows × 12 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3c63b9e5-2a06-4dc0-907a-209b87184b63')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3c63b9e5-2a06-4dc0-907a-209b87184b63 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3c63b9e5-2a06-4dc0-907a-209b87184b63');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXdPM_Uy72Nc",
        "outputId": "3d0f7f5c-1db8-4667-a732-7ce3ff16e038"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2248    0\n",
              "4179    0\n",
              "5675    0\n",
              "3217    0\n",
              "4338    0\n",
              "       ..\n",
              "760     1\n",
              "259     1\n",
              "5678    0\n",
              "5122    0\n",
              "28      1\n",
              "Name: 12, Length: 5197, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0UtTm5rz74Kf",
        "outputId": "b701a396-5a9a-428f-b94b-fc6a25c8bb01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2288    0\n",
              "1158    1\n",
              "1949    0\n",
              "1156    1\n",
              "5690    0\n",
              "       ..\n",
              "482     1\n",
              "5169    0\n",
              "4564    0\n",
              "3693    0\n",
              "5867    0\n",
              "Name: 12, Length: 1300, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "metadata": {
        "id": "YyQkiliC7418"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(30, input_dim=12, activation='relu'))\n",
        "model.add(Dense(12, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ei0dMPTO8G2x",
        "outputId": "7bf2e2d6-af07-4fce-f1b3-7d06098bf18e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_4 (Dense)              (None, 30)                390       \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 12)                372       \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 8)                 104       \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 875\n",
            "Trainable params: 875\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, epochs=50, batch_size=500, validation_split=0.25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M54EWrN_8K10",
        "outputId": "0b015682-7b41-49ab-aa54-60a7fcacfdc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "8/8 [==============================] - 2s 91ms/step - loss: 14.9168 - accuracy: 0.2507 - val_loss: 8.7074 - val_accuracy: 0.2438\n",
            "Epoch 2/50\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 5.7389 - accuracy: 0.1925 - val_loss: 2.6047 - val_accuracy: 0.0931\n",
            "Epoch 3/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.3282 - accuracy: 0.3859 - val_loss: 0.5622 - val_accuracy: 0.7500\n",
            "Epoch 4/50\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.6101 - accuracy: 0.7490 - val_loss: 0.6667 - val_accuracy: 0.7577\n",
            "Epoch 5/50\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.6808 - accuracy: 0.7534 - val_loss: 0.6546 - val_accuracy: 0.7638\n",
            "Epoch 6/50\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.6114 - accuracy: 0.7632 - val_loss: 0.5149 - val_accuracy: 0.7815\n",
            "Epoch 7/50\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.4457 - accuracy: 0.7957 - val_loss: 0.3622 - val_accuracy: 0.8269\n",
            "Epoch 8/50\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.3509 - accuracy: 0.8458 - val_loss: 0.3367 - val_accuracy: 0.8700\n",
            "Epoch 9/50\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.3057 - accuracy: 0.8727 - val_loss: 0.2774 - val_accuracy: 0.8785\n",
            "Epoch 10/50\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.2649 - accuracy: 0.8814 - val_loss: 0.2506 - val_accuracy: 0.8900\n",
            "Epoch 11/50\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 0.2368 - accuracy: 0.9058 - val_loss: 0.2280 - val_accuracy: 0.9085\n",
            "Epoch 12/50\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 0.2213 - accuracy: 0.9174 - val_loss: 0.2162 - val_accuracy: 0.9177\n",
            "Epoch 13/50\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.2103 - accuracy: 0.9225 - val_loss: 0.2089 - val_accuracy: 0.9208\n",
            "Epoch 14/50\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.2052 - accuracy: 0.9238 - val_loss: 0.2055 - val_accuracy: 0.9223\n",
            "Epoch 15/50\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.2024 - accuracy: 0.9261 - val_loss: 0.2032 - val_accuracy: 0.9246\n",
            "Epoch 16/50\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.2007 - accuracy: 0.9294 - val_loss: 0.2020 - val_accuracy: 0.9254\n",
            "Epoch 17/50\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.1994 - accuracy: 0.9305 - val_loss: 0.2012 - val_accuracy: 0.9277\n",
            "Epoch 18/50\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.1982 - accuracy: 0.9317 - val_loss: 0.2003 - val_accuracy: 0.9285\n",
            "Epoch 19/50\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1970 - accuracy: 0.9317 - val_loss: 0.1996 - val_accuracy: 0.9285\n",
            "Epoch 20/50\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1959 - accuracy: 0.9323 - val_loss: 0.1991 - val_accuracy: 0.9285\n",
            "Epoch 21/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1951 - accuracy: 0.9320 - val_loss: 0.1985 - val_accuracy: 0.9292\n",
            "Epoch 22/50\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1942 - accuracy: 0.9320 - val_loss: 0.1980 - val_accuracy: 0.9292\n",
            "Epoch 23/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1936 - accuracy: 0.9320 - val_loss: 0.1977 - val_accuracy: 0.9292\n",
            "Epoch 24/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1927 - accuracy: 0.9325 - val_loss: 0.1969 - val_accuracy: 0.9308\n",
            "Epoch 25/50\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1926 - accuracy: 0.9320 - val_loss: 0.1965 - val_accuracy: 0.9308\n",
            "Epoch 26/50\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1917 - accuracy: 0.9325 - val_loss: 0.1964 - val_accuracy: 0.9308\n",
            "Epoch 27/50\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.1917 - accuracy: 0.9323 - val_loss: 0.1957 - val_accuracy: 0.9308\n",
            "Epoch 28/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1906 - accuracy: 0.9333 - val_loss: 0.1957 - val_accuracy: 0.9308\n",
            "Epoch 29/50\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1904 - accuracy: 0.9330 - val_loss: 0.1951 - val_accuracy: 0.9308\n",
            "Epoch 30/50\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1898 - accuracy: 0.9338 - val_loss: 0.1947 - val_accuracy: 0.9308\n",
            "Epoch 31/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1893 - accuracy: 0.9338 - val_loss: 0.1942 - val_accuracy: 0.9323\n",
            "Epoch 32/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1889 - accuracy: 0.9341 - val_loss: 0.1940 - val_accuracy: 0.9315\n",
            "Epoch 33/50\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1886 - accuracy: 0.9343 - val_loss: 0.1935 - val_accuracy: 0.9315\n",
            "Epoch 34/50\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1880 - accuracy: 0.9351 - val_loss: 0.1931 - val_accuracy: 0.9323\n",
            "Epoch 35/50\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1876 - accuracy: 0.9353 - val_loss: 0.1928 - val_accuracy: 0.9315\n",
            "Epoch 36/50\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1873 - accuracy: 0.9353 - val_loss: 0.1928 - val_accuracy: 0.9315\n",
            "Epoch 37/50\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1870 - accuracy: 0.9361 - val_loss: 0.1918 - val_accuracy: 0.9315\n",
            "Epoch 38/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1864 - accuracy: 0.9366 - val_loss: 0.1916 - val_accuracy: 0.9323\n",
            "Epoch 39/50\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1860 - accuracy: 0.9358 - val_loss: 0.1913 - val_accuracy: 0.9323\n",
            "Epoch 40/50\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1855 - accuracy: 0.9371 - val_loss: 0.1907 - val_accuracy: 0.9323\n",
            "Epoch 41/50\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1852 - accuracy: 0.9366 - val_loss: 0.1903 - val_accuracy: 0.9323\n",
            "Epoch 42/50\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.1848 - accuracy: 0.9369 - val_loss: 0.1901 - val_accuracy: 0.9323\n",
            "Epoch 43/50\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.1845 - accuracy: 0.9364 - val_loss: 0.1897 - val_accuracy: 0.9323\n",
            "Epoch 44/50\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.1840 - accuracy: 0.9374 - val_loss: 0.1892 - val_accuracy: 0.9338\n",
            "Epoch 45/50\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.1837 - accuracy: 0.9376 - val_loss: 0.1889 - val_accuracy: 0.9338\n",
            "Epoch 46/50\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.1843 - accuracy: 0.9358 - val_loss: 0.1894 - val_accuracy: 0.9315\n",
            "Epoch 47/50\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.1828 - accuracy: 0.9379 - val_loss: 0.1882 - val_accuracy: 0.9338\n",
            "Epoch 48/50\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.1829 - accuracy: 0.9379 - val_loss: 0.1878 - val_accuracy: 0.9338\n",
            "Epoch 49/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1822 - accuracy: 0.9361 - val_loss: 0.1877 - val_accuracy: 0.9331\n",
            "Epoch 50/50\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1820 - accuracy: 0.9371 - val_loss: 0.1871 - val_accuracy: 0.9338\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f03fa1e5550>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(x_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-GCl4qh9AiZ",
        "outputId": "f6c8fcdd-a54f-406b-8bdf-08f75147174c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41/41 [==============================] - 0s 2ms/step - loss: 0.1620 - accuracy: 0.9454\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.16199426352977753, 0.9453846216201782]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"정확도 : %.2f\"%(model.evaluate(x_test,y_test)[1]*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5QVegMe9J-d",
        "outputId": "e3a9a11e-f4d0-4e91-fac8-34a4c91899e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41/41 [==============================] - 0s 1ms/step - loss: 0.1620 - accuracy: 0.9454\n",
            "정확도 : 94.54\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 1 epoch 실행-> 전체 train data르 학습 -> 하나의 Model이 생성\n",
        "- 2 epoch 실행 -> 첫번째 모델이 입력이 되고 마지막 모델만 남고 그 전의 모델은 덮어쓰기 된다.\n",
        "- 이전 모델 보다 정확도가 높을 때만 덮어쓰기 하려면"
      ],
      "metadata": {
        "id": "Yrt1k8et9iRU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 업데이트하기\n",
        "- 각각의 모델을 별도의 파일로 저장"
      ],
      "metadata": {
        "id": "M6mEPnhl9_sU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint"
      ],
      "metadata": {
        "id": "Cb3F4m9_9_Rk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. loss\n",
        "2. accuracy\n",
        "3. val_loss\n",
        "4. val_accuracy\n",
        "- validation_split 이 설정 되어야 쓸 수 있음\n"
      ],
      "metadata": {
        "id": "gas2HrdK-bB8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelpath = \"/content/gdrive/MyDrive/Colab/data/model/wine_epochs/{epoch:02d}-{val_accuracy:.4f}.hdf5\"\n",
        "modelpath"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "oGTAxczv9TTo",
        "outputId": "c583cd72-49d7-495d-cef0-7455edc9a907"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/MyDrive/Colab/data/model/wine_epochs/{epoch:02d}-{val_accuracy:.4f}.hdf5'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 문자열 서식지정\n",
        "'{}-{}'.format(23,2.12345)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ebmmyP6tElZN",
        "outputId": "63f10b9e-89fc-4ce2-d053-c0cc7f242aa8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'23-2.12345'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "L=[1,3,5,7,4,5]\n",
        "'min:{1}, max:{0}'.format(max(L), min(L))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Xx_yUqnGExYl",
        "outputId": "697a828e-451f-4515-8ceb-2191d9b13b4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'min:1, max:7'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ck = ModelCheckpoint(modelpath, verbose=1, monitor='val_loss',save_bset_only=True) # save_bset_only 없으면 파일 50개 나옴\n",
        "ck"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dN2_I7n_IhZ",
        "outputId": "208ca062-b227-41c1-b676-a9286e0a46e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.ModelCheckpoint at 0x7f03f7324c50>"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train, epochs=50, batch_size=500, \n",
        "          validation_split=0.25, verbose=1, callbacks=[ck]) \n",
        "            # verbose 기록 여부, callbacks 비동기 처리 함수"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVOASk3I_bwY",
        "outputId": "4ea35a4d-cdbe-4114-9426-dff5b55b3e8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0208 - accuracy: 0.9946 - val_loss: 0.0749 - val_accuracy: 0.9838\n",
            "\n",
            "Epoch 00001: saving model to /content/gdrive/MyDrive/Colab/data/model/wine_epochs/01-0.9838.hdf5\n",
            "Epoch 2/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0214 - accuracy: 0.9946 - val_loss: 0.0754 - val_accuracy: 0.9838\n",
            "\n",
            "Epoch 00002: saving model to /content/gdrive/MyDrive/Colab/data/model/wine_epochs/02-0.9838.hdf5\n",
            "Epoch 3/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0220 - accuracy: 0.9938 - val_loss: 0.0834 - val_accuracy: 0.9838\n",
            "\n",
            "Epoch 00003: saving model to /content/gdrive/MyDrive/Colab/data/model/wine_epochs/03-0.9838.hdf5\n",
            "Epoch 4/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0266 - accuracy: 0.9928 - val_loss: 0.0799 - val_accuracy: 0.9831\n",
            "\n",
            "Epoch 00004: saving model to /content/gdrive/MyDrive/Colab/data/model/wine_epochs/04-0.9831.hdf5\n",
            "Epoch 5/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0240 - accuracy: 0.9928 - val_loss: 0.0758 - val_accuracy: 0.9815\n",
            "\n",
            "Epoch 00005: saving model to /content/gdrive/MyDrive/Colab/data/model/wine_epochs/05-0.9815.hdf5\n",
            "Epoch 6/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0245 - accuracy: 0.9923 - val_loss: 0.0774 - val_accuracy: 0.9831\n",
            "\n",
            "Epoch 00006: saving model to /content/gdrive/MyDrive/Colab/data/model/wine_epochs/06-0.9831.hdf5\n",
            "Epoch 7/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0218 - accuracy: 0.9946 - val_loss: 0.0773 - val_accuracy: 0.9838\n",
            "\n",
            "Epoch 00007: saving model to /content/gdrive/MyDrive/Colab/data/model/wine_epochs/07-0.9838.hdf5\n",
            "Epoch 8/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0223 - accuracy: 0.9938 - val_loss: 0.0812 - val_accuracy: 0.9838\n",
            "\n",
            "Epoch 00008: saving model to /content/gdrive/MyDrive/Colab/data/model/wine_epochs/08-0.9838.hdf5\n",
            "Epoch 9/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0228 - accuracy: 0.9936 - val_loss: 0.0806 - val_accuracy: 0.9846\n",
            "\n",
            "Epoch 00009: saving model to /content/gdrive/MyDrive/Colab/data/model/wine_epochs/09-0.9846.hdf5\n",
            "Epoch 10/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0227 - accuracy: 0.9941 - val_loss: 0.0778 - val_accuracy: 0.9846\n",
            "\n",
            "Epoch 00010: saving model to /content/gdrive/MyDrive/Colab/data/model/wine_epochs/10-0.9846.hdf5\n",
            "Epoch 11/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0231 - accuracy: 0.9944 - val_loss: 0.0777 - val_accuracy: 0.9815\n",
            "\n",
            "Epoch 00011: saving model to /content/gdrive/MyDrive/Colab/data/model/wine_epochs/11-0.9815.hdf5\n",
            "Epoch 12/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0215 - accuracy: 0.9936 - val_loss: 0.0758 - val_accuracy: 0.9846\n",
            "\n",
            "Epoch 00012: saving model to /content/gdrive/MyDrive/Colab/data/model/wine_epochs/12-0.9846.hdf5\n",
            "Epoch 13/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0210 - accuracy: 0.9944 - val_loss: 0.0783 - val_accuracy: 0.9823\n",
            "\n",
            "Epoch 00013: saving model to /content/gdrive/MyDrive/Colab/data/model/wine_epochs/13-0.9823.hdf5\n",
            "Epoch 14/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0217 - accuracy: 0.9951 - val_loss: 0.0761 - val_accuracy: 0.9846\n",
            "\n",
            "Epoch 00014: saving model to /content/gdrive/MyDrive/Colab/data/model/wine_epochs/14-0.9846.hdf5\n",
            "Epoch 15/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0224 - accuracy: 0.9936 - val_loss: 0.0785 - val_accuracy: 0.9846\n",
            "\n",
            "Epoch 00015: saving model to /content/gdrive/MyDrive/Colab/data/model/wine_epochs/15-0.9846.hdf5\n",
            "Epoch 16/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0219 - accuracy: 0.9949 - val_loss: 0.0785 - val_accuracy: 0.9838\n",
            "\n",
            "Epoch 00016: saving model to /content/gdrive/MyDrive/Colab/data/model/wine_epochs/16-0.9838.hdf5\n",
            "Epoch 17/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0205 - accuracy: 0.9949 - val_loss: 0.0767 - val_accuracy: 0.9823\n",
            "\n",
            "Epoch 00017: saving model to /content/gdrive/MyDrive/Colab/data/model/wine_epochs/17-0.9823.hdf5\n",
            "Epoch 18/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0203 - accuracy: 0.9949 - val_loss: 0.0760 - val_accuracy: 0.9846\n",
            "\n",
            "Epoch 00018: saving model to /content/gdrive/MyDrive/Colab/data/model/wine_epochs/18-0.9846.hdf5\n",
            "Epoch 19/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0214 - accuracy: 0.9941 - val_loss: 0.0747 - val_accuracy: 0.9831\n",
            "\n",
            "Epoch 00019: saving model to /content/gdrive/MyDrive/Colab/data/model/wine_epochs/19-0.9831.hdf5\n",
            "Epoch 20/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0210 - accuracy: 0.9951 - val_loss: 0.0749 - val_accuracy: 0.9846\n",
            "\n",
            "Epoch 00020: saving model to /content/gdrive/MyDrive/Colab/data/model/wine_epochs/20-0.9846.hdf5\n",
            "Epoch 21/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0223 - accuracy: 0.9941 - val_loss: 0.0783 - val_accuracy: 0.9838\n",
            "\n",
            "Epoch 00021: saving model to /content/gdrive/MyDrive/Colab/data/model/wine_epochs/21-0.9838.hdf5\n",
            "Epoch 22/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0218 - accuracy: 0.9946 - val_loss: 0.0749 - val_accuracy: 0.9831\n",
            "\n",
            "Epoch 00022: saving model to /content/gdrive/MyDrive/Colab/data/model/wine_epochs/22-0.9831.hdf5\n",
            "Epoch 23/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0213 - accuracy: 0.9941 - val_loss: 0.0809 - val_accuracy: 0.9838\n",
            "\n",
            "Epoch 00023: saving model to /content/gdrive/MyDrive/Colab/data/model/wine_epochs/23-0.9838.hdf5\n",
            "Epoch 24/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0222 - accuracy: 0.9941 - val_loss: 0.0763 - val_accuracy: 0.9838\n",
            "\n",
            "Epoch 00024: saving model to /content/gdrive/MyDrive/Colab/data/model/wine_epochs/24-0.9838.hdf5\n",
            "Epoch 25/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0243 - accuracy: 0.9931 - val_loss: 0.0774 - val_accuracy: 0.9838\n",
            "\n",
            "Epoch 00025: saving model to /content/gdrive/MyDrive/Colab/data/model/wine_epochs/25-0.9838.hdf5\n",
            "Epoch 26/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0211 - accuracy: 0.9944 - val_loss: 0.0786 - val_accuracy: 0.9838\n",
            "\n",
            "Epoch 00026: saving model to /content/gdrive/MyDrive/Colab/data/model/wine_epochs/26-0.9838.hdf5\n",
            "Epoch 27/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0210 - accuracy: 0.9941 - val_loss: 0.0772 - val_accuracy: 0.9838\n",
            "\n",
            "Epoch 00027: saving model to /content/gdrive/MyDrive/Colab/data/model/wine_epochs/27-0.9838.hdf5\n",
            "Epoch 28/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0207 - accuracy: 0.9944 - val_loss: 0.0783 - val_accuracy: 0.9838\n",
            "\n",
            "Epoch 00028: saving model to /content/gdrive/MyDrive/Colab/data/model/wine_epochs/28-0.9838.hdf5\n",
            "Epoch 29/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0199 - accuracy: 0.9954 - val_loss: 0.0770 - val_accuracy: 0.9831\n",
            "\n",
            "Epoch 00029: saving model to /content/gdrive/MyDrive/Colab/data/model/wine_epochs/29-0.9831.hdf5\n",
            "Epoch 30/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0246 - accuracy: 0.9931 - val_loss: 0.0799 - val_accuracy: 0.9854\n",
            "\n",
            "Epoch 00030: saving model to /content/gdrive/MyDrive/Colab/data/model/wine_epochs/30-0.9854.hdf5\n",
            "Epoch 31/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0237 - accuracy: 0.9933 - val_loss: 0.0857 - val_accuracy: 0.9846\n",
            "\n",
            "Epoch 00031: saving model to /content/gdrive/MyDrive/Colab/data/model/wine_epochs/31-0.9846.hdf5\n",
            "Epoch 32/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0225 - accuracy: 0.9931 - val_loss: 0.0748 - val_accuracy: 0.9838\n",
            "\n",
            "Epoch 00032: saving model to /content/gdrive/MyDrive/Colab/data/model/wine_epochs/32-0.9838.hdf5\n",
            "Epoch 33/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0216 - accuracy: 0.9949 - val_loss: 0.0756 - val_accuracy: 0.9823\n",
            "\n",
            "Epoch 00033: saving model to /content/gdrive/MyDrive/Colab/data/model/wine_epochs/33-0.9823.hdf5\n",
            "Epoch 34/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0213 - accuracy: 0.9941 - val_loss: 0.0767 - val_accuracy: 0.9838\n",
            "\n",
            "Epoch 00034: saving model to /content/gdrive/MyDrive/Colab/data/model/wine_epochs/34-0.9838.hdf5\n",
            "Epoch 35/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0210 - accuracy: 0.9941 - val_loss: 0.0753 - val_accuracy: 0.9831\n",
            "\n",
            "Epoch 00035: saving model to /content/gdrive/MyDrive/Colab/data/model/wine_epochs/35-0.9831.hdf5\n",
            "Epoch 36/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0212 - accuracy: 0.9946 - val_loss: 0.0765 - val_accuracy: 0.9854\n",
            "\n",
            "Epoch 00036: saving model to /content/gdrive/MyDrive/Colab/data/model/wine_epochs/36-0.9854.hdf5\n",
            "Epoch 37/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0213 - accuracy: 0.9944 - val_loss: 0.0784 - val_accuracy: 0.9838\n",
            "\n",
            "Epoch 00037: saving model to /content/gdrive/MyDrive/Colab/data/model/wine_epochs/37-0.9838.hdf5\n",
            "Epoch 38/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0215 - accuracy: 0.9941 - val_loss: 0.0795 - val_accuracy: 0.9831\n",
            "\n",
            "Epoch 00038: saving model to /content/gdrive/MyDrive/Colab/data/model/wine_epochs/38-0.9831.hdf5\n",
            "Epoch 39/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0226 - accuracy: 0.9933 - val_loss: 0.0745 - val_accuracy: 0.9838\n",
            "\n",
            "Epoch 00039: saving model to /content/gdrive/MyDrive/Colab/data/model/wine_epochs/39-0.9838.hdf5\n",
            "Epoch 40/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0224 - accuracy: 0.9936 - val_loss: 0.0770 - val_accuracy: 0.9823\n",
            "\n",
            "Epoch 00040: saving model to /content/gdrive/MyDrive/Colab/data/model/wine_epochs/40-0.9823.hdf5\n",
            "Epoch 41/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0204 - accuracy: 0.9946 - val_loss: 0.0765 - val_accuracy: 0.9831\n",
            "\n",
            "Epoch 00041: saving model to /content/gdrive/MyDrive/Colab/data/model/wine_epochs/41-0.9831.hdf5\n",
            "Epoch 42/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0212 - accuracy: 0.9944 - val_loss: 0.0759 - val_accuracy: 0.9823\n",
            "\n",
            "Epoch 00042: saving model to /content/gdrive/MyDrive/Colab/data/model/wine_epochs/42-0.9823.hdf5\n",
            "Epoch 43/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0205 - accuracy: 0.9949 - val_loss: 0.0787 - val_accuracy: 0.9846\n",
            "\n",
            "Epoch 00043: saving model to /content/gdrive/MyDrive/Colab/data/model/wine_epochs/43-0.9846.hdf5\n",
            "Epoch 44/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0229 - accuracy: 0.9938 - val_loss: 0.0829 - val_accuracy: 0.9838\n",
            "\n",
            "Epoch 00044: saving model to /content/gdrive/MyDrive/Colab/data/model/wine_epochs/44-0.9838.hdf5\n",
            "Epoch 45/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0276 - accuracy: 0.9915 - val_loss: 0.0789 - val_accuracy: 0.9838\n",
            "\n",
            "Epoch 00045: saving model to /content/gdrive/MyDrive/Colab/data/model/wine_epochs/45-0.9838.hdf5\n",
            "Epoch 46/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0264 - accuracy: 0.9920 - val_loss: 0.0783 - val_accuracy: 0.9831\n",
            "\n",
            "Epoch 00046: saving model to /content/gdrive/MyDrive/Colab/data/model/wine_epochs/46-0.9831.hdf5\n",
            "Epoch 47/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0243 - accuracy: 0.9923 - val_loss: 0.0821 - val_accuracy: 0.9831\n",
            "\n",
            "Epoch 00047: saving model to /content/gdrive/MyDrive/Colab/data/model/wine_epochs/47-0.9831.hdf5\n",
            "Epoch 48/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0220 - accuracy: 0.9938 - val_loss: 0.0780 - val_accuracy: 0.9838\n",
            "\n",
            "Epoch 00048: saving model to /content/gdrive/MyDrive/Colab/data/model/wine_epochs/48-0.9838.hdf5\n",
            "Epoch 49/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0212 - accuracy: 0.9944 - val_loss: 0.0760 - val_accuracy: 0.9823\n",
            "\n",
            "Epoch 00049: saving model to /content/gdrive/MyDrive/Colab/data/model/wine_epochs/49-0.9823.hdf5\n",
            "Epoch 50/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0207 - accuracy: 0.9944 - val_loss: 0.0767 - val_accuracy: 0.9838\n",
            "\n",
            "Epoch 00050: saving model to /content/gdrive/MyDrive/Colab/data/model/wine_epochs/50-0.9838.hdf5\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f03f7393410>"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 그래프로 과적합 확인"
      ],
      "metadata": {
        "id": "_nKz5uS3A5Ws"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train, y_train, epochs=2000, batch_size=500, validation_split=0.25) # 과적합"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94s9lYWe_5iW",
        "outputId": "a17c004b-205a-44dc-e22a-faee3926a977"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0459 - accuracy: 0.9877 - val_loss: 0.0554 - val_accuracy: 0.9838\n",
            "Epoch 2/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0459 - accuracy: 0.9882 - val_loss: 0.0548 - val_accuracy: 0.9838\n",
            "Epoch 3/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0468 - accuracy: 0.9867 - val_loss: 0.0572 - val_accuracy: 0.9815\n",
            "Epoch 4/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0493 - accuracy: 0.9856 - val_loss: 0.0708 - val_accuracy: 0.9777\n",
            "Epoch 5/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0508 - accuracy: 0.9849 - val_loss: 0.0605 - val_accuracy: 0.9815\n",
            "Epoch 6/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0502 - accuracy: 0.9859 - val_loss: 0.0549 - val_accuracy: 0.9831\n",
            "Epoch 7/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0453 - accuracy: 0.9867 - val_loss: 0.0550 - val_accuracy: 0.9846\n",
            "Epoch 8/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0445 - accuracy: 0.9882 - val_loss: 0.0598 - val_accuracy: 0.9808\n",
            "Epoch 9/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0447 - accuracy: 0.9872 - val_loss: 0.0548 - val_accuracy: 0.9838\n",
            "Epoch 10/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0447 - accuracy: 0.9879 - val_loss: 0.0544 - val_accuracy: 0.9838\n",
            "Epoch 11/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0449 - accuracy: 0.9869 - val_loss: 0.0562 - val_accuracy: 0.9831\n",
            "Epoch 12/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0452 - accuracy: 0.9872 - val_loss: 0.0614 - val_accuracy: 0.9815\n",
            "Epoch 13/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0464 - accuracy: 0.9869 - val_loss: 0.0562 - val_accuracy: 0.9815\n",
            "Epoch 14/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0445 - accuracy: 0.9872 - val_loss: 0.0545 - val_accuracy: 0.9831\n",
            "Epoch 15/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0444 - accuracy: 0.9887 - val_loss: 0.0546 - val_accuracy: 0.9831\n",
            "Epoch 16/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0453 - accuracy: 0.9864 - val_loss: 0.0552 - val_accuracy: 0.9831\n",
            "Epoch 17/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0442 - accuracy: 0.9879 - val_loss: 0.0549 - val_accuracy: 0.9831\n",
            "Epoch 18/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0445 - accuracy: 0.9882 - val_loss: 0.0561 - val_accuracy: 0.9815\n",
            "Epoch 19/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0455 - accuracy: 0.9867 - val_loss: 0.0570 - val_accuracy: 0.9815\n",
            "Epoch 20/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0450 - accuracy: 0.9867 - val_loss: 0.0564 - val_accuracy: 0.9815\n",
            "Epoch 21/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0447 - accuracy: 0.9867 - val_loss: 0.0544 - val_accuracy: 0.9838\n",
            "Epoch 22/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0438 - accuracy: 0.9890 - val_loss: 0.0579 - val_accuracy: 0.9808\n",
            "Epoch 23/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0452 - accuracy: 0.9867 - val_loss: 0.0561 - val_accuracy: 0.9815\n",
            "Epoch 24/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0447 - accuracy: 0.9872 - val_loss: 0.0553 - val_accuracy: 0.9815\n",
            "Epoch 25/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0475 - accuracy: 0.9867 - val_loss: 0.0548 - val_accuracy: 0.9846\n",
            "Epoch 26/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0485 - accuracy: 0.9859 - val_loss: 0.0617 - val_accuracy: 0.9785\n",
            "Epoch 27/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0462 - accuracy: 0.9877 - val_loss: 0.0550 - val_accuracy: 0.9831\n",
            "Epoch 28/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0451 - accuracy: 0.9864 - val_loss: 0.0549 - val_accuracy: 0.9823\n",
            "Epoch 29/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0444 - accuracy: 0.9879 - val_loss: 0.0546 - val_accuracy: 0.9831\n",
            "Epoch 30/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0443 - accuracy: 0.9877 - val_loss: 0.0542 - val_accuracy: 0.9838\n",
            "Epoch 31/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0440 - accuracy: 0.9882 - val_loss: 0.0552 - val_accuracy: 0.9823\n",
            "Epoch 32/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0467 - accuracy: 0.9869 - val_loss: 0.0597 - val_accuracy: 0.9808\n",
            "Epoch 33/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0445 - accuracy: 0.9882 - val_loss: 0.0548 - val_accuracy: 0.9831\n",
            "Epoch 34/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0460 - accuracy: 0.9874 - val_loss: 0.0574 - val_accuracy: 0.9808\n",
            "Epoch 35/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0451 - accuracy: 0.9869 - val_loss: 0.0593 - val_accuracy: 0.9815\n",
            "Epoch 36/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0438 - accuracy: 0.9887 - val_loss: 0.0566 - val_accuracy: 0.9823\n",
            "Epoch 37/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0463 - accuracy: 0.9877 - val_loss: 0.0548 - val_accuracy: 0.9854\n",
            "Epoch 38/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0438 - accuracy: 0.9874 - val_loss: 0.0580 - val_accuracy: 0.9808\n",
            "Epoch 39/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0447 - accuracy: 0.9869 - val_loss: 0.0570 - val_accuracy: 0.9815\n",
            "Epoch 40/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0460 - accuracy: 0.9867 - val_loss: 0.0546 - val_accuracy: 0.9846\n",
            "Epoch 41/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0470 - accuracy: 0.9856 - val_loss: 0.0564 - val_accuracy: 0.9838\n",
            "Epoch 42/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0443 - accuracy: 0.9874 - val_loss: 0.0548 - val_accuracy: 0.9838\n",
            "Epoch 43/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0442 - accuracy: 0.9882 - val_loss: 0.0543 - val_accuracy: 0.9831\n",
            "Epoch 44/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0440 - accuracy: 0.9872 - val_loss: 0.0573 - val_accuracy: 0.9815\n",
            "Epoch 45/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0448 - accuracy: 0.9867 - val_loss: 0.0546 - val_accuracy: 0.9831\n",
            "Epoch 46/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0445 - accuracy: 0.9877 - val_loss: 0.0543 - val_accuracy: 0.9823\n",
            "Epoch 47/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0434 - accuracy: 0.9887 - val_loss: 0.0541 - val_accuracy: 0.9838\n",
            "Epoch 48/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0435 - accuracy: 0.9887 - val_loss: 0.0554 - val_accuracy: 0.9815\n",
            "Epoch 49/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0443 - accuracy: 0.9872 - val_loss: 0.0562 - val_accuracy: 0.9815\n",
            "Epoch 50/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0441 - accuracy: 0.9874 - val_loss: 0.0541 - val_accuracy: 0.9831\n",
            "Epoch 51/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0439 - accuracy: 0.9872 - val_loss: 0.0585 - val_accuracy: 0.9815\n",
            "Epoch 52/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0488 - accuracy: 0.9851 - val_loss: 0.0683 - val_accuracy: 0.9785\n",
            "Epoch 53/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0580 - accuracy: 0.9833 - val_loss: 0.0552 - val_accuracy: 0.9823\n",
            "Epoch 54/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0500 - accuracy: 0.9856 - val_loss: 0.0566 - val_accuracy: 0.9831\n",
            "Epoch 55/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0456 - accuracy: 0.9861 - val_loss: 0.0574 - val_accuracy: 0.9831\n",
            "Epoch 56/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0462 - accuracy: 0.9861 - val_loss: 0.0556 - val_accuracy: 0.9846\n",
            "Epoch 57/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0497 - accuracy: 0.9869 - val_loss: 0.0607 - val_accuracy: 0.9815\n",
            "Epoch 58/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0457 - accuracy: 0.9856 - val_loss: 0.0550 - val_accuracy: 0.9831\n",
            "Epoch 59/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0439 - accuracy: 0.9885 - val_loss: 0.0549 - val_accuracy: 0.9838\n",
            "Epoch 60/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0453 - accuracy: 0.9861 - val_loss: 0.0549 - val_accuracy: 0.9823\n",
            "Epoch 61/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0460 - accuracy: 0.9867 - val_loss: 0.0560 - val_accuracy: 0.9838\n",
            "Epoch 62/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0459 - accuracy: 0.9869 - val_loss: 0.0584 - val_accuracy: 0.9792\n",
            "Epoch 63/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0462 - accuracy: 0.9877 - val_loss: 0.0543 - val_accuracy: 0.9838\n",
            "Epoch 64/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0436 - accuracy: 0.9882 - val_loss: 0.0540 - val_accuracy: 0.9838\n",
            "Epoch 65/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0437 - accuracy: 0.9887 - val_loss: 0.0545 - val_accuracy: 0.9838\n",
            "Epoch 66/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0439 - accuracy: 0.9882 - val_loss: 0.0582 - val_accuracy: 0.9808\n",
            "Epoch 67/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0447 - accuracy: 0.9877 - val_loss: 0.0591 - val_accuracy: 0.9815\n",
            "Epoch 68/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0463 - accuracy: 0.9872 - val_loss: 0.0545 - val_accuracy: 0.9838\n",
            "Epoch 69/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0438 - accuracy: 0.9882 - val_loss: 0.0556 - val_accuracy: 0.9854\n",
            "Epoch 70/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0440 - accuracy: 0.9882 - val_loss: 0.0548 - val_accuracy: 0.9823\n",
            "Epoch 71/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0438 - accuracy: 0.9869 - val_loss: 0.0557 - val_accuracy: 0.9815\n",
            "Epoch 72/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0427 - accuracy: 0.9890 - val_loss: 0.0546 - val_accuracy: 0.9838\n",
            "Epoch 73/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0431 - accuracy: 0.9885 - val_loss: 0.0544 - val_accuracy: 0.9831\n",
            "Epoch 74/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0436 - accuracy: 0.9869 - val_loss: 0.0542 - val_accuracy: 0.9838\n",
            "Epoch 75/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0441 - accuracy: 0.9874 - val_loss: 0.0543 - val_accuracy: 0.9823\n",
            "Epoch 76/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0444 - accuracy: 0.9864 - val_loss: 0.0542 - val_accuracy: 0.9823\n",
            "Epoch 77/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0437 - accuracy: 0.9872 - val_loss: 0.0594 - val_accuracy: 0.9808\n",
            "Epoch 78/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0464 - accuracy: 0.9867 - val_loss: 0.0629 - val_accuracy: 0.9800\n",
            "Epoch 79/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0460 - accuracy: 0.9856 - val_loss: 0.0566 - val_accuracy: 0.9815\n",
            "Epoch 80/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0443 - accuracy: 0.9867 - val_loss: 0.0542 - val_accuracy: 0.9831\n",
            "Epoch 81/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0435 - accuracy: 0.9874 - val_loss: 0.0577 - val_accuracy: 0.9808\n",
            "Epoch 82/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0459 - accuracy: 0.9874 - val_loss: 0.0561 - val_accuracy: 0.9823\n",
            "Epoch 83/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0475 - accuracy: 0.9851 - val_loss: 0.0553 - val_accuracy: 0.9823\n",
            "Epoch 84/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0497 - accuracy: 0.9838 - val_loss: 0.0589 - val_accuracy: 0.9815\n",
            "Epoch 85/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0491 - accuracy: 0.9864 - val_loss: 0.0695 - val_accuracy: 0.9792\n",
            "Epoch 86/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0483 - accuracy: 0.9861 - val_loss: 0.0583 - val_accuracy: 0.9815\n",
            "Epoch 87/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0565 - accuracy: 0.9838 - val_loss: 0.0545 - val_accuracy: 0.9838\n",
            "Epoch 88/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0556 - accuracy: 0.9828 - val_loss: 0.0606 - val_accuracy: 0.9785\n",
            "Epoch 89/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0546 - accuracy: 0.9828 - val_loss: 0.0593 - val_accuracy: 0.9785\n",
            "Epoch 90/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0494 - accuracy: 0.9856 - val_loss: 0.0629 - val_accuracy: 0.9792\n",
            "Epoch 91/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0494 - accuracy: 0.9851 - val_loss: 0.0541 - val_accuracy: 0.9831\n",
            "Epoch 92/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0430 - accuracy: 0.9879 - val_loss: 0.0606 - val_accuracy: 0.9808\n",
            "Epoch 93/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0477 - accuracy: 0.9872 - val_loss: 0.0556 - val_accuracy: 0.9831\n",
            "Epoch 94/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0508 - accuracy: 0.9851 - val_loss: 0.0599 - val_accuracy: 0.9792\n",
            "Epoch 95/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0448 - accuracy: 0.9879 - val_loss: 0.0544 - val_accuracy: 0.9823\n",
            "Epoch 96/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0432 - accuracy: 0.9877 - val_loss: 0.0575 - val_accuracy: 0.9808\n",
            "Epoch 97/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0452 - accuracy: 0.9869 - val_loss: 0.0560 - val_accuracy: 0.9823\n",
            "Epoch 98/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0433 - accuracy: 0.9869 - val_loss: 0.0560 - val_accuracy: 0.9815\n",
            "Epoch 99/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0430 - accuracy: 0.9877 - val_loss: 0.0545 - val_accuracy: 0.9838\n",
            "Epoch 100/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0431 - accuracy: 0.9877 - val_loss: 0.0542 - val_accuracy: 0.9823\n",
            "Epoch 101/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0430 - accuracy: 0.9872 - val_loss: 0.0602 - val_accuracy: 0.9815\n",
            "Epoch 102/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0453 - accuracy: 0.9864 - val_loss: 0.0546 - val_accuracy: 0.9831\n",
            "Epoch 103/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0435 - accuracy: 0.9879 - val_loss: 0.0545 - val_accuracy: 0.9823\n",
            "Epoch 104/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0430 - accuracy: 0.9882 - val_loss: 0.0558 - val_accuracy: 0.9823\n",
            "Epoch 105/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0430 - accuracy: 0.9887 - val_loss: 0.0554 - val_accuracy: 0.9815\n",
            "Epoch 106/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0423 - accuracy: 0.9879 - val_loss: 0.0541 - val_accuracy: 0.9823\n",
            "Epoch 107/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0440 - accuracy: 0.9874 - val_loss: 0.0540 - val_accuracy: 0.9823\n",
            "Epoch 108/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0438 - accuracy: 0.9879 - val_loss: 0.0542 - val_accuracy: 0.9823\n",
            "Epoch 109/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0440 - accuracy: 0.9869 - val_loss: 0.0561 - val_accuracy: 0.9815\n",
            "Epoch 110/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0435 - accuracy: 0.9879 - val_loss: 0.0540 - val_accuracy: 0.9831\n",
            "Epoch 111/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0429 - accuracy: 0.9879 - val_loss: 0.0549 - val_accuracy: 0.9838\n",
            "Epoch 112/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0440 - accuracy: 0.9874 - val_loss: 0.0540 - val_accuracy: 0.9838\n",
            "Epoch 113/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0436 - accuracy: 0.9879 - val_loss: 0.0556 - val_accuracy: 0.9831\n",
            "Epoch 114/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0466 - accuracy: 0.9859 - val_loss: 0.0570 - val_accuracy: 0.9808\n",
            "Epoch 115/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0422 - accuracy: 0.9882 - val_loss: 0.0583 - val_accuracy: 0.9823\n",
            "Epoch 116/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0448 - accuracy: 0.9872 - val_loss: 0.0574 - val_accuracy: 0.9823\n",
            "Epoch 117/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0445 - accuracy: 0.9869 - val_loss: 0.0553 - val_accuracy: 0.9838\n",
            "Epoch 118/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0437 - accuracy: 0.9879 - val_loss: 0.0566 - val_accuracy: 0.9808\n",
            "Epoch 119/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0439 - accuracy: 0.9867 - val_loss: 0.0543 - val_accuracy: 0.9815\n",
            "Epoch 120/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0429 - accuracy: 0.9890 - val_loss: 0.0542 - val_accuracy: 0.9823\n",
            "Epoch 121/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0423 - accuracy: 0.9877 - val_loss: 0.0551 - val_accuracy: 0.9823\n",
            "Epoch 122/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0426 - accuracy: 0.9874 - val_loss: 0.0545 - val_accuracy: 0.9815\n",
            "Epoch 123/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0422 - accuracy: 0.9885 - val_loss: 0.0550 - val_accuracy: 0.9823\n",
            "Epoch 124/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0432 - accuracy: 0.9879 - val_loss: 0.0594 - val_accuracy: 0.9808\n",
            "Epoch 125/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0426 - accuracy: 0.9892 - val_loss: 0.0566 - val_accuracy: 0.9808\n",
            "Epoch 126/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0440 - accuracy: 0.9877 - val_loss: 0.0544 - val_accuracy: 0.9838\n",
            "Epoch 127/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0425 - accuracy: 0.9892 - val_loss: 0.0541 - val_accuracy: 0.9823\n",
            "Epoch 128/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0424 - accuracy: 0.9892 - val_loss: 0.0540 - val_accuracy: 0.9831\n",
            "Epoch 129/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0423 - accuracy: 0.9882 - val_loss: 0.0541 - val_accuracy: 0.9815\n",
            "Epoch 130/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0440 - accuracy: 0.9874 - val_loss: 0.0544 - val_accuracy: 0.9815\n",
            "Epoch 131/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0424 - accuracy: 0.9869 - val_loss: 0.0718 - val_accuracy: 0.9762\n",
            "Epoch 132/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0497 - accuracy: 0.9869 - val_loss: 0.0542 - val_accuracy: 0.9831\n",
            "Epoch 133/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0475 - accuracy: 0.9851 - val_loss: 0.0560 - val_accuracy: 0.9823\n",
            "Epoch 134/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0424 - accuracy: 0.9892 - val_loss: 0.0542 - val_accuracy: 0.9815\n",
            "Epoch 135/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0435 - accuracy: 0.9877 - val_loss: 0.0733 - val_accuracy: 0.9754\n",
            "Epoch 136/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0527 - accuracy: 0.9838 - val_loss: 0.0545 - val_accuracy: 0.9815\n",
            "Epoch 137/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0450 - accuracy: 0.9867 - val_loss: 0.0550 - val_accuracy: 0.9831\n",
            "Epoch 138/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0429 - accuracy: 0.9879 - val_loss: 0.0547 - val_accuracy: 0.9838\n",
            "Epoch 139/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0423 - accuracy: 0.9885 - val_loss: 0.0545 - val_accuracy: 0.9815\n",
            "Epoch 140/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0434 - accuracy: 0.9882 - val_loss: 0.0540 - val_accuracy: 0.9815\n",
            "Epoch 141/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0444 - accuracy: 0.9864 - val_loss: 0.0577 - val_accuracy: 0.9808\n",
            "Epoch 142/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0434 - accuracy: 0.9874 - val_loss: 0.0542 - val_accuracy: 0.9831\n",
            "Epoch 143/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0434 - accuracy: 0.9874 - val_loss: 0.0563 - val_accuracy: 0.9815\n",
            "Epoch 144/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0416 - accuracy: 0.9877 - val_loss: 0.0552 - val_accuracy: 0.9831\n",
            "Epoch 145/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0437 - accuracy: 0.9874 - val_loss: 0.0550 - val_accuracy: 0.9823\n",
            "Epoch 146/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0424 - accuracy: 0.9874 - val_loss: 0.0630 - val_accuracy: 0.9808\n",
            "Epoch 147/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0462 - accuracy: 0.9864 - val_loss: 0.0545 - val_accuracy: 0.9823\n",
            "Epoch 148/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0429 - accuracy: 0.9877 - val_loss: 0.0538 - val_accuracy: 0.9815\n",
            "Epoch 149/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0426 - accuracy: 0.9877 - val_loss: 0.0544 - val_accuracy: 0.9823\n",
            "Epoch 150/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0420 - accuracy: 0.9887 - val_loss: 0.0544 - val_accuracy: 0.9823\n",
            "Epoch 151/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0432 - accuracy: 0.9877 - val_loss: 0.0565 - val_accuracy: 0.9815\n",
            "Epoch 152/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0423 - accuracy: 0.9872 - val_loss: 0.0551 - val_accuracy: 0.9823\n",
            "Epoch 153/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0430 - accuracy: 0.9872 - val_loss: 0.0540 - val_accuracy: 0.9815\n",
            "Epoch 154/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0451 - accuracy: 0.9867 - val_loss: 0.0552 - val_accuracy: 0.9831\n",
            "Epoch 155/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0439 - accuracy: 0.9867 - val_loss: 0.0539 - val_accuracy: 0.9838\n",
            "Epoch 156/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0417 - accuracy: 0.9885 - val_loss: 0.0539 - val_accuracy: 0.9838\n",
            "Epoch 157/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0420 - accuracy: 0.9885 - val_loss: 0.0539 - val_accuracy: 0.9815\n",
            "Epoch 158/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0417 - accuracy: 0.9885 - val_loss: 0.0543 - val_accuracy: 0.9823\n",
            "Epoch 159/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0436 - accuracy: 0.9872 - val_loss: 0.0563 - val_accuracy: 0.9815\n",
            "Epoch 160/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0460 - accuracy: 0.9882 - val_loss: 0.0607 - val_accuracy: 0.9792\n",
            "Epoch 161/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0450 - accuracy: 0.9874 - val_loss: 0.0548 - val_accuracy: 0.9838\n",
            "Epoch 162/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0433 - accuracy: 0.9879 - val_loss: 0.0558 - val_accuracy: 0.9823\n",
            "Epoch 163/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0418 - accuracy: 0.9882 - val_loss: 0.0543 - val_accuracy: 0.9815\n",
            "Epoch 164/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0421 - accuracy: 0.9885 - val_loss: 0.0577 - val_accuracy: 0.9808\n",
            "Epoch 165/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0447 - accuracy: 0.9867 - val_loss: 0.0546 - val_accuracy: 0.9823\n",
            "Epoch 166/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0462 - accuracy: 0.9879 - val_loss: 0.0619 - val_accuracy: 0.9800\n",
            "Epoch 167/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0436 - accuracy: 0.9882 - val_loss: 0.0542 - val_accuracy: 0.9831\n",
            "Epoch 168/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0418 - accuracy: 0.9885 - val_loss: 0.0543 - val_accuracy: 0.9831\n",
            "Epoch 169/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0419 - accuracy: 0.9885 - val_loss: 0.0548 - val_accuracy: 0.9823\n",
            "Epoch 170/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0421 - accuracy: 0.9882 - val_loss: 0.0540 - val_accuracy: 0.9823\n",
            "Epoch 171/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0418 - accuracy: 0.9882 - val_loss: 0.0559 - val_accuracy: 0.9831\n",
            "Epoch 172/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0442 - accuracy: 0.9877 - val_loss: 0.0545 - val_accuracy: 0.9838\n",
            "Epoch 173/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0450 - accuracy: 0.9864 - val_loss: 0.0608 - val_accuracy: 0.9808\n",
            "Epoch 174/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0444 - accuracy: 0.9867 - val_loss: 0.0569 - val_accuracy: 0.9815\n",
            "Epoch 175/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0435 - accuracy: 0.9864 - val_loss: 0.0546 - val_accuracy: 0.9838\n",
            "Epoch 176/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0418 - accuracy: 0.9887 - val_loss: 0.0544 - val_accuracy: 0.9831\n",
            "Epoch 177/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0421 - accuracy: 0.9879 - val_loss: 0.0540 - val_accuracy: 0.9823\n",
            "Epoch 178/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0417 - accuracy: 0.9882 - val_loss: 0.0545 - val_accuracy: 0.9838\n",
            "Epoch 179/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0420 - accuracy: 0.9877 - val_loss: 0.0543 - val_accuracy: 0.9815\n",
            "Epoch 180/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0422 - accuracy: 0.9890 - val_loss: 0.0549 - val_accuracy: 0.9823\n",
            "Epoch 181/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0416 - accuracy: 0.9882 - val_loss: 0.0538 - val_accuracy: 0.9823\n",
            "Epoch 182/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0423 - accuracy: 0.9879 - val_loss: 0.0560 - val_accuracy: 0.9823\n",
            "Epoch 183/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0425 - accuracy: 0.9882 - val_loss: 0.0611 - val_accuracy: 0.9815\n",
            "Epoch 184/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0445 - accuracy: 0.9885 - val_loss: 0.0562 - val_accuracy: 0.9823\n",
            "Epoch 185/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0423 - accuracy: 0.9890 - val_loss: 0.0552 - val_accuracy: 0.9823\n",
            "Epoch 186/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0423 - accuracy: 0.9879 - val_loss: 0.0537 - val_accuracy: 0.9838\n",
            "Epoch 187/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0420 - accuracy: 0.9874 - val_loss: 0.0569 - val_accuracy: 0.9808\n",
            "Epoch 188/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0429 - accuracy: 0.9877 - val_loss: 0.0549 - val_accuracy: 0.9815\n",
            "Epoch 189/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0434 - accuracy: 0.9856 - val_loss: 0.0605 - val_accuracy: 0.9815\n",
            "Epoch 190/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0458 - accuracy: 0.9872 - val_loss: 0.0621 - val_accuracy: 0.9815\n",
            "Epoch 191/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0468 - accuracy: 0.9867 - val_loss: 0.0543 - val_accuracy: 0.9838\n",
            "Epoch 192/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0421 - accuracy: 0.9882 - val_loss: 0.0567 - val_accuracy: 0.9808\n",
            "Epoch 193/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0452 - accuracy: 0.9872 - val_loss: 0.0560 - val_accuracy: 0.9831\n",
            "Epoch 194/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0430 - accuracy: 0.9874 - val_loss: 0.0542 - val_accuracy: 0.9838\n",
            "Epoch 195/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0415 - accuracy: 0.9882 - val_loss: 0.0541 - val_accuracy: 0.9823\n",
            "Epoch 196/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0420 - accuracy: 0.9890 - val_loss: 0.0545 - val_accuracy: 0.9831\n",
            "Epoch 197/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0414 - accuracy: 0.9887 - val_loss: 0.0575 - val_accuracy: 0.9808\n",
            "Epoch 198/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0430 - accuracy: 0.9887 - val_loss: 0.0573 - val_accuracy: 0.9808\n",
            "Epoch 199/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0411 - accuracy: 0.9874 - val_loss: 0.0573 - val_accuracy: 0.9815\n",
            "Epoch 200/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0422 - accuracy: 0.9882 - val_loss: 0.0542 - val_accuracy: 0.9815\n",
            "Epoch 201/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0412 - accuracy: 0.9890 - val_loss: 0.0537 - val_accuracy: 0.9823\n",
            "Epoch 202/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0432 - accuracy: 0.9882 - val_loss: 0.0550 - val_accuracy: 0.9823\n",
            "Epoch 203/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0419 - accuracy: 0.9885 - val_loss: 0.0554 - val_accuracy: 0.9831\n",
            "Epoch 204/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0417 - accuracy: 0.9892 - val_loss: 0.0540 - val_accuracy: 0.9838\n",
            "Epoch 205/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0417 - accuracy: 0.9879 - val_loss: 0.0540 - val_accuracy: 0.9838\n",
            "Epoch 206/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0424 - accuracy: 0.9877 - val_loss: 0.0555 - val_accuracy: 0.9831\n",
            "Epoch 207/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0437 - accuracy: 0.9877 - val_loss: 0.0557 - val_accuracy: 0.9823\n",
            "Epoch 208/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0418 - accuracy: 0.9895 - val_loss: 0.0538 - val_accuracy: 0.9823\n",
            "Epoch 209/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0410 - accuracy: 0.9887 - val_loss: 0.0563 - val_accuracy: 0.9823\n",
            "Epoch 210/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0413 - accuracy: 0.9887 - val_loss: 0.0539 - val_accuracy: 0.9838\n",
            "Epoch 211/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0430 - accuracy: 0.9877 - val_loss: 0.0565 - val_accuracy: 0.9823\n",
            "Epoch 212/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0448 - accuracy: 0.9877 - val_loss: 0.0556 - val_accuracy: 0.9823\n",
            "Epoch 213/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0438 - accuracy: 0.9879 - val_loss: 0.0588 - val_accuracy: 0.9815\n",
            "Epoch 214/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0420 - accuracy: 0.9882 - val_loss: 0.0581 - val_accuracy: 0.9823\n",
            "Epoch 215/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0426 - accuracy: 0.9872 - val_loss: 0.0541 - val_accuracy: 0.9815\n",
            "Epoch 216/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0417 - accuracy: 0.9879 - val_loss: 0.0609 - val_accuracy: 0.9815\n",
            "Epoch 217/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0502 - accuracy: 0.9864 - val_loss: 0.0557 - val_accuracy: 0.9823\n",
            "Epoch 218/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0474 - accuracy: 0.9867 - val_loss: 0.0591 - val_accuracy: 0.9792\n",
            "Epoch 219/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0459 - accuracy: 0.9869 - val_loss: 0.0582 - val_accuracy: 0.9808\n",
            "Epoch 220/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0437 - accuracy: 0.9872 - val_loss: 0.0544 - val_accuracy: 0.9838\n",
            "Epoch 221/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0436 - accuracy: 0.9869 - val_loss: 0.0548 - val_accuracy: 0.9823\n",
            "Epoch 222/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0428 - accuracy: 0.9890 - val_loss: 0.0563 - val_accuracy: 0.9823\n",
            "Epoch 223/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0481 - accuracy: 0.9854 - val_loss: 0.0567 - val_accuracy: 0.9815\n",
            "Epoch 224/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0427 - accuracy: 0.9879 - val_loss: 0.0578 - val_accuracy: 0.9815\n",
            "Epoch 225/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0433 - accuracy: 0.9874 - val_loss: 0.0587 - val_accuracy: 0.9815\n",
            "Epoch 226/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0444 - accuracy: 0.9887 - val_loss: 0.0541 - val_accuracy: 0.9815\n",
            "Epoch 227/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0416 - accuracy: 0.9885 - val_loss: 0.0544 - val_accuracy: 0.9823\n",
            "Epoch 228/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0408 - accuracy: 0.9885 - val_loss: 0.0601 - val_accuracy: 0.9823\n",
            "Epoch 229/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0431 - accuracy: 0.9877 - val_loss: 0.0538 - val_accuracy: 0.9815\n",
            "Epoch 230/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0412 - accuracy: 0.9885 - val_loss: 0.0535 - val_accuracy: 0.9838\n",
            "Epoch 231/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0413 - accuracy: 0.9882 - val_loss: 0.0577 - val_accuracy: 0.9815\n",
            "Epoch 232/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0448 - accuracy: 0.9874 - val_loss: 0.0545 - val_accuracy: 0.9838\n",
            "Epoch 233/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0486 - accuracy: 0.9854 - val_loss: 0.0636 - val_accuracy: 0.9808\n",
            "Epoch 234/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0476 - accuracy: 0.9864 - val_loss: 0.0652 - val_accuracy: 0.9800\n",
            "Epoch 235/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0495 - accuracy: 0.9867 - val_loss: 0.0538 - val_accuracy: 0.9838\n",
            "Epoch 236/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0418 - accuracy: 0.9877 - val_loss: 0.0558 - val_accuracy: 0.9815\n",
            "Epoch 237/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0408 - accuracy: 0.9897 - val_loss: 0.0542 - val_accuracy: 0.9815\n",
            "Epoch 238/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0461 - accuracy: 0.9864 - val_loss: 0.0541 - val_accuracy: 0.9823\n",
            "Epoch 239/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0413 - accuracy: 0.9890 - val_loss: 0.0543 - val_accuracy: 0.9838\n",
            "Epoch 240/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0411 - accuracy: 0.9890 - val_loss: 0.0551 - val_accuracy: 0.9823\n",
            "Epoch 241/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0450 - accuracy: 0.9877 - val_loss: 0.0538 - val_accuracy: 0.9815\n",
            "Epoch 242/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0452 - accuracy: 0.9879 - val_loss: 0.0659 - val_accuracy: 0.9800\n",
            "Epoch 243/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0452 - accuracy: 0.9879 - val_loss: 0.0577 - val_accuracy: 0.9823\n",
            "Epoch 244/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0438 - accuracy: 0.9885 - val_loss: 0.0551 - val_accuracy: 0.9823\n",
            "Epoch 245/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0434 - accuracy: 0.9874 - val_loss: 0.0556 - val_accuracy: 0.9831\n",
            "Epoch 246/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0424 - accuracy: 0.9885 - val_loss: 0.0545 - val_accuracy: 0.9823\n",
            "Epoch 247/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0413 - accuracy: 0.9887 - val_loss: 0.0556 - val_accuracy: 0.9823\n",
            "Epoch 248/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0433 - accuracy: 0.9885 - val_loss: 0.0550 - val_accuracy: 0.9815\n",
            "Epoch 249/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0415 - accuracy: 0.9882 - val_loss: 0.0567 - val_accuracy: 0.9823\n",
            "Epoch 250/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0416 - accuracy: 0.9885 - val_loss: 0.0541 - val_accuracy: 0.9838\n",
            "Epoch 251/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0410 - accuracy: 0.9892 - val_loss: 0.0542 - val_accuracy: 0.9838\n",
            "Epoch 252/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0420 - accuracy: 0.9882 - val_loss: 0.0546 - val_accuracy: 0.9831\n",
            "Epoch 253/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0436 - accuracy: 0.9877 - val_loss: 0.0545 - val_accuracy: 0.9823\n",
            "Epoch 254/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0461 - accuracy: 0.9867 - val_loss: 0.0750 - val_accuracy: 0.9731\n",
            "Epoch 255/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0445 - accuracy: 0.9879 - val_loss: 0.0544 - val_accuracy: 0.9815\n",
            "Epoch 256/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0442 - accuracy: 0.9874 - val_loss: 0.0547 - val_accuracy: 0.9808\n",
            "Epoch 257/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0409 - accuracy: 0.9882 - val_loss: 0.0549 - val_accuracy: 0.9831\n",
            "Epoch 258/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0412 - accuracy: 0.9885 - val_loss: 0.0541 - val_accuracy: 0.9815\n",
            "Epoch 259/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0416 - accuracy: 0.9897 - val_loss: 0.0580 - val_accuracy: 0.9815\n",
            "Epoch 260/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0433 - accuracy: 0.9867 - val_loss: 0.0617 - val_accuracy: 0.9815\n",
            "Epoch 261/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0414 - accuracy: 0.9890 - val_loss: 0.0544 - val_accuracy: 0.9838\n",
            "Epoch 262/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0422 - accuracy: 0.9879 - val_loss: 0.0580 - val_accuracy: 0.9815\n",
            "Epoch 263/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0429 - accuracy: 0.9879 - val_loss: 0.0561 - val_accuracy: 0.9831\n",
            "Epoch 264/2000\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.0432 - accuracy: 0.9877 - val_loss: 0.0566 - val_accuracy: 0.9823\n",
            "Epoch 265/2000\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.0423 - accuracy: 0.9874 - val_loss: 0.0592 - val_accuracy: 0.9823\n",
            "Epoch 266/2000\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 0.0417 - accuracy: 0.9879 - val_loss: 0.0539 - val_accuracy: 0.9823\n",
            "Epoch 267/2000\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.0413 - accuracy: 0.9885 - val_loss: 0.0563 - val_accuracy: 0.9823\n",
            "Epoch 268/2000\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.0415 - accuracy: 0.9882 - val_loss: 0.0571 - val_accuracy: 0.9815\n",
            "Epoch 269/2000\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.0412 - accuracy: 0.9890 - val_loss: 0.0536 - val_accuracy: 0.9823\n",
            "Epoch 270/2000\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.0402 - accuracy: 0.9892 - val_loss: 0.0546 - val_accuracy: 0.9815\n",
            "Epoch 271/2000\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 0.0409 - accuracy: 0.9890 - val_loss: 0.0561 - val_accuracy: 0.9838\n",
            "Epoch 272/2000\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0418 - accuracy: 0.9874 - val_loss: 0.0539 - val_accuracy: 0.9838\n",
            "Epoch 273/2000\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.0403 - accuracy: 0.9892 - val_loss: 0.0536 - val_accuracy: 0.9823\n",
            "Epoch 274/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0406 - accuracy: 0.9890 - val_loss: 0.0537 - val_accuracy: 0.9838\n",
            "Epoch 275/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0413 - accuracy: 0.9895 - val_loss: 0.0544 - val_accuracy: 0.9815\n",
            "Epoch 276/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0413 - accuracy: 0.9872 - val_loss: 0.0602 - val_accuracy: 0.9823\n",
            "Epoch 277/2000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0429 - accuracy: 0.9877 - val_loss: 0.0542 - val_accuracy: 0.9815\n",
            "Epoch 278/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0403 - accuracy: 0.9890 - val_loss: 0.0538 - val_accuracy: 0.9823\n",
            "Epoch 279/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0406 - accuracy: 0.9897 - val_loss: 0.0556 - val_accuracy: 0.9823\n",
            "Epoch 280/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0429 - accuracy: 0.9872 - val_loss: 0.0548 - val_accuracy: 0.9823\n",
            "Epoch 281/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0440 - accuracy: 0.9885 - val_loss: 0.0798 - val_accuracy: 0.9723\n",
            "Epoch 282/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0532 - accuracy: 0.9854 - val_loss: 0.0555 - val_accuracy: 0.9823\n",
            "Epoch 283/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0506 - accuracy: 0.9849 - val_loss: 0.0710 - val_accuracy: 0.9800\n",
            "Epoch 284/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0529 - accuracy: 0.9851 - val_loss: 0.0626 - val_accuracy: 0.9800\n",
            "Epoch 285/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0638 - accuracy: 0.9795 - val_loss: 0.0555 - val_accuracy: 0.9838\n",
            "Epoch 286/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0502 - accuracy: 0.9846 - val_loss: 0.0662 - val_accuracy: 0.9785\n",
            "Epoch 287/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0452 - accuracy: 0.9854 - val_loss: 0.0563 - val_accuracy: 0.9831\n",
            "Epoch 288/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0426 - accuracy: 0.9890 - val_loss: 0.0542 - val_accuracy: 0.9823\n",
            "Epoch 289/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0408 - accuracy: 0.9890 - val_loss: 0.0549 - val_accuracy: 0.9823\n",
            "Epoch 290/2000\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0405 - accuracy: 0.9874 - val_loss: 0.0564 - val_accuracy: 0.9831\n",
            "Epoch 291/2000\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0423 - accuracy: 0.9887 - val_loss: 0.0622 - val_accuracy: 0.9815\n",
            "Epoch 292/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0446 - accuracy: 0.9877 - val_loss: 0.0539 - val_accuracy: 0.9846\n",
            "Epoch 293/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0420 - accuracy: 0.9885 - val_loss: 0.0553 - val_accuracy: 0.9823\n",
            "Epoch 294/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0418 - accuracy: 0.9890 - val_loss: 0.0542 - val_accuracy: 0.9846\n",
            "Epoch 295/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0404 - accuracy: 0.9892 - val_loss: 0.0546 - val_accuracy: 0.9815\n",
            "Epoch 296/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0402 - accuracy: 0.9887 - val_loss: 0.0545 - val_accuracy: 0.9831\n",
            "Epoch 297/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0415 - accuracy: 0.9892 - val_loss: 0.0558 - val_accuracy: 0.9831\n",
            "Epoch 298/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0409 - accuracy: 0.9887 - val_loss: 0.0544 - val_accuracy: 0.9815\n",
            "Epoch 299/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0409 - accuracy: 0.9890 - val_loss: 0.0572 - val_accuracy: 0.9823\n",
            "Epoch 300/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0411 - accuracy: 0.9874 - val_loss: 0.0538 - val_accuracy: 0.9823\n",
            "Epoch 301/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0402 - accuracy: 0.9897 - val_loss: 0.0587 - val_accuracy: 0.9823\n",
            "Epoch 302/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0446 - accuracy: 0.9877 - val_loss: 0.0590 - val_accuracy: 0.9815\n",
            "Epoch 303/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0419 - accuracy: 0.9872 - val_loss: 0.0545 - val_accuracy: 0.9823\n",
            "Epoch 304/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0407 - accuracy: 0.9890 - val_loss: 0.0545 - val_accuracy: 0.9823\n",
            "Epoch 305/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0405 - accuracy: 0.9890 - val_loss: 0.0540 - val_accuracy: 0.9838\n",
            "Epoch 306/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0421 - accuracy: 0.9877 - val_loss: 0.0546 - val_accuracy: 0.9831\n",
            "Epoch 307/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0411 - accuracy: 0.9882 - val_loss: 0.0543 - val_accuracy: 0.9823\n",
            "Epoch 308/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0411 - accuracy: 0.9897 - val_loss: 0.0559 - val_accuracy: 0.9838\n",
            "Epoch 309/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0433 - accuracy: 0.9877 - val_loss: 0.0592 - val_accuracy: 0.9823\n",
            "Epoch 310/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0404 - accuracy: 0.9882 - val_loss: 0.0537 - val_accuracy: 0.9823\n",
            "Epoch 311/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0408 - accuracy: 0.9895 - val_loss: 0.0543 - val_accuracy: 0.9823\n",
            "Epoch 312/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0425 - accuracy: 0.9885 - val_loss: 0.0552 - val_accuracy: 0.9831\n",
            "Epoch 313/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0408 - accuracy: 0.9895 - val_loss: 0.0537 - val_accuracy: 0.9823\n",
            "Epoch 314/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0402 - accuracy: 0.9892 - val_loss: 0.0540 - val_accuracy: 0.9838\n",
            "Epoch 315/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0407 - accuracy: 0.9885 - val_loss: 0.0538 - val_accuracy: 0.9838\n",
            "Epoch 316/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0419 - accuracy: 0.9882 - val_loss: 0.0578 - val_accuracy: 0.9823\n",
            "Epoch 317/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0428 - accuracy: 0.9882 - val_loss: 0.0540 - val_accuracy: 0.9838\n",
            "Epoch 318/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0429 - accuracy: 0.9885 - val_loss: 0.0548 - val_accuracy: 0.9823\n",
            "Epoch 319/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0414 - accuracy: 0.9882 - val_loss: 0.0537 - val_accuracy: 0.9823\n",
            "Epoch 320/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0406 - accuracy: 0.9885 - val_loss: 0.0533 - val_accuracy: 0.9823\n",
            "Epoch 321/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0400 - accuracy: 0.9895 - val_loss: 0.0541 - val_accuracy: 0.9823\n",
            "Epoch 322/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0406 - accuracy: 0.9882 - val_loss: 0.0540 - val_accuracy: 0.9823\n",
            "Epoch 323/2000\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0406 - accuracy: 0.9869 - val_loss: 0.0570 - val_accuracy: 0.9831\n",
            "Epoch 324/2000\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0405 - accuracy: 0.9900 - val_loss: 0.0538 - val_accuracy: 0.9823\n",
            "Epoch 325/2000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0415 - accuracy: 0.9877 - val_loss: 0.0563 - val_accuracy: 0.9831\n",
            "Epoch 326/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0411 - accuracy: 0.9892 - val_loss: 0.0539 - val_accuracy: 0.9838\n",
            "Epoch 327/2000\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0418 - accuracy: 0.9872 - val_loss: 0.0539 - val_accuracy: 0.9823\n",
            "Epoch 328/2000\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 0.0403 - accuracy: 0.9882 - val_loss: 0.0589 - val_accuracy: 0.9823\n",
            "Epoch 329/2000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0424 - accuracy: 0.9874 - val_loss: 0.0537 - val_accuracy: 0.9823\n",
            "Epoch 330/2000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0399 - accuracy: 0.9887 - val_loss: 0.0536 - val_accuracy: 0.9823\n",
            "Epoch 331/2000\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 0.0400 - accuracy: 0.9887 - val_loss: 0.0539 - val_accuracy: 0.9846\n",
            "Epoch 332/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0411 - accuracy: 0.9885 - val_loss: 0.0538 - val_accuracy: 0.9823\n",
            "Epoch 333/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0447 - accuracy: 0.9874 - val_loss: 0.0539 - val_accuracy: 0.9823\n",
            "Epoch 334/2000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0403 - accuracy: 0.9887 - val_loss: 0.0579 - val_accuracy: 0.9823\n",
            "Epoch 335/2000\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0409 - accuracy: 0.9882 - val_loss: 0.0561 - val_accuracy: 0.9823\n",
            "Epoch 336/2000\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0410 - accuracy: 0.9897 - val_loss: 0.0587 - val_accuracy: 0.9823\n",
            "Epoch 337/2000\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0439 - accuracy: 0.9887 - val_loss: 0.0540 - val_accuracy: 0.9823\n",
            "Epoch 338/2000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0433 - accuracy: 0.9874 - val_loss: 0.0563 - val_accuracy: 0.9831\n",
            "Epoch 339/2000\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0420 - accuracy: 0.9887 - val_loss: 0.0538 - val_accuracy: 0.9838\n",
            "Epoch 340/2000\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 0.0399 - accuracy: 0.9897 - val_loss: 0.0539 - val_accuracy: 0.9823\n",
            "Epoch 341/2000\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.0400 - accuracy: 0.9900 - val_loss: 0.0564 - val_accuracy: 0.9831\n",
            "Epoch 342/2000\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0439 - accuracy: 0.9872 - val_loss: 0.0545 - val_accuracy: 0.9831\n",
            "Epoch 343/2000\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0424 - accuracy: 0.9885 - val_loss: 0.0573 - val_accuracy: 0.9831\n",
            "Epoch 344/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0430 - accuracy: 0.9877 - val_loss: 0.0548 - val_accuracy: 0.9823\n",
            "Epoch 345/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0415 - accuracy: 0.9887 - val_loss: 0.0543 - val_accuracy: 0.9823\n",
            "Epoch 346/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0406 - accuracy: 0.9895 - val_loss: 0.0560 - val_accuracy: 0.9846\n",
            "Epoch 347/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0414 - accuracy: 0.9890 - val_loss: 0.0541 - val_accuracy: 0.9823\n",
            "Epoch 348/2000\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 0.0402 - accuracy: 0.9895 - val_loss: 0.0538 - val_accuracy: 0.9823\n",
            "Epoch 349/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0400 - accuracy: 0.9900 - val_loss: 0.0538 - val_accuracy: 0.9831\n",
            "Epoch 350/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0427 - accuracy: 0.9877 - val_loss: 0.0540 - val_accuracy: 0.9838\n",
            "Epoch 351/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0398 - accuracy: 0.9890 - val_loss: 0.0539 - val_accuracy: 0.9831\n",
            "Epoch 352/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0395 - accuracy: 0.9897 - val_loss: 0.0539 - val_accuracy: 0.9823\n",
            "Epoch 353/2000\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0400 - accuracy: 0.9890 - val_loss: 0.0600 - val_accuracy: 0.9831\n",
            "Epoch 354/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0490 - accuracy: 0.9861 - val_loss: 0.0552 - val_accuracy: 0.9823\n",
            "Epoch 355/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0477 - accuracy: 0.9854 - val_loss: 0.0650 - val_accuracy: 0.9792\n",
            "Epoch 356/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0492 - accuracy: 0.9849 - val_loss: 0.0739 - val_accuracy: 0.9746\n",
            "Epoch 357/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0456 - accuracy: 0.9864 - val_loss: 0.0563 - val_accuracy: 0.9831\n",
            "Epoch 358/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0404 - accuracy: 0.9887 - val_loss: 0.0548 - val_accuracy: 0.9831\n",
            "Epoch 359/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0445 - accuracy: 0.9877 - val_loss: 0.0572 - val_accuracy: 0.9815\n",
            "Epoch 360/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0424 - accuracy: 0.9877 - val_loss: 0.0612 - val_accuracy: 0.9808\n",
            "Epoch 361/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0430 - accuracy: 0.9874 - val_loss: 0.0560 - val_accuracy: 0.9831\n",
            "Epoch 362/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0402 - accuracy: 0.9890 - val_loss: 0.0549 - val_accuracy: 0.9823\n",
            "Epoch 363/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0405 - accuracy: 0.9900 - val_loss: 0.0537 - val_accuracy: 0.9823\n",
            "Epoch 364/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0395 - accuracy: 0.9897 - val_loss: 0.0538 - val_accuracy: 0.9838\n",
            "Epoch 365/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0401 - accuracy: 0.9890 - val_loss: 0.0546 - val_accuracy: 0.9831\n",
            "Epoch 366/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0435 - accuracy: 0.9872 - val_loss: 0.0614 - val_accuracy: 0.9815\n",
            "Epoch 367/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0457 - accuracy: 0.9867 - val_loss: 0.0654 - val_accuracy: 0.9808\n",
            "Epoch 368/2000\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0426 - accuracy: 0.9897 - val_loss: 0.0539 - val_accuracy: 0.9838\n",
            "Epoch 369/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0401 - accuracy: 0.9887 - val_loss: 0.0541 - val_accuracy: 0.9838\n",
            "Epoch 370/2000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0407 - accuracy: 0.9887 - val_loss: 0.0564 - val_accuracy: 0.9846\n",
            "Epoch 371/2000\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.0424 - accuracy: 0.9879 - val_loss: 0.0561 - val_accuracy: 0.9831\n",
            "Epoch 372/2000\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0418 - accuracy: 0.9874 - val_loss: 0.0537 - val_accuracy: 0.9831\n",
            "Epoch 373/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0396 - accuracy: 0.9900 - val_loss: 0.0542 - val_accuracy: 0.9846\n",
            "Epoch 374/2000\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0406 - accuracy: 0.9892 - val_loss: 0.0567 - val_accuracy: 0.9838\n",
            "Epoch 375/2000\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.0409 - accuracy: 0.9895 - val_loss: 0.0546 - val_accuracy: 0.9838\n",
            "Epoch 376/2000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0427 - accuracy: 0.9877 - val_loss: 0.0632 - val_accuracy: 0.9808\n",
            "Epoch 377/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0422 - accuracy: 0.9882 - val_loss: 0.0555 - val_accuracy: 0.9831\n",
            "Epoch 378/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0419 - accuracy: 0.9887 - val_loss: 0.0541 - val_accuracy: 0.9823\n",
            "Epoch 379/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0400 - accuracy: 0.9897 - val_loss: 0.0546 - val_accuracy: 0.9831\n",
            "Epoch 380/2000\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0400 - accuracy: 0.9892 - val_loss: 0.0540 - val_accuracy: 0.9823\n",
            "Epoch 381/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0406 - accuracy: 0.9895 - val_loss: 0.0551 - val_accuracy: 0.9823\n",
            "Epoch 382/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0405 - accuracy: 0.9879 - val_loss: 0.0562 - val_accuracy: 0.9846\n",
            "Epoch 383/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0408 - accuracy: 0.9887 - val_loss: 0.0537 - val_accuracy: 0.9823\n",
            "Epoch 384/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0449 - accuracy: 0.9872 - val_loss: 0.0573 - val_accuracy: 0.9831\n",
            "Epoch 385/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0399 - accuracy: 0.9892 - val_loss: 0.0543 - val_accuracy: 0.9838\n",
            "Epoch 386/2000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0420 - accuracy: 0.9895 - val_loss: 0.0551 - val_accuracy: 0.9823\n",
            "Epoch 387/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0409 - accuracy: 0.9877 - val_loss: 0.0563 - val_accuracy: 0.9838\n",
            "Epoch 388/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0414 - accuracy: 0.9882 - val_loss: 0.0568 - val_accuracy: 0.9831\n",
            "Epoch 389/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0414 - accuracy: 0.9882 - val_loss: 0.0539 - val_accuracy: 0.9838\n",
            "Epoch 390/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0399 - accuracy: 0.9887 - val_loss: 0.0600 - val_accuracy: 0.9831\n",
            "Epoch 391/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0441 - accuracy: 0.9874 - val_loss: 0.0538 - val_accuracy: 0.9838\n",
            "Epoch 392/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0399 - accuracy: 0.9885 - val_loss: 0.0535 - val_accuracy: 0.9823\n",
            "Epoch 393/2000\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0401 - accuracy: 0.9890 - val_loss: 0.0545 - val_accuracy: 0.9838\n",
            "Epoch 394/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0417 - accuracy: 0.9885 - val_loss: 0.0543 - val_accuracy: 0.9838\n",
            "Epoch 395/2000\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0425 - accuracy: 0.9877 - val_loss: 0.0537 - val_accuracy: 0.9831\n",
            "Epoch 396/2000\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0407 - accuracy: 0.9887 - val_loss: 0.0546 - val_accuracy: 0.9838\n",
            "Epoch 397/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0396 - accuracy: 0.9900 - val_loss: 0.0535 - val_accuracy: 0.9823\n",
            "Epoch 398/2000\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 0.0408 - accuracy: 0.9882 - val_loss: 0.0628 - val_accuracy: 0.9815\n",
            "Epoch 399/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0403 - accuracy: 0.9900 - val_loss: 0.0542 - val_accuracy: 0.9838\n",
            "Epoch 400/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0396 - accuracy: 0.9879 - val_loss: 0.0539 - val_accuracy: 0.9846\n",
            "Epoch 401/2000\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.0394 - accuracy: 0.9895 - val_loss: 0.0559 - val_accuracy: 0.9838\n",
            "Epoch 402/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0401 - accuracy: 0.9900 - val_loss: 0.0537 - val_accuracy: 0.9823\n",
            "Epoch 403/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0408 - accuracy: 0.9897 - val_loss: 0.0542 - val_accuracy: 0.9831\n",
            "Epoch 404/2000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0412 - accuracy: 0.9897 - val_loss: 0.0554 - val_accuracy: 0.9831\n",
            "Epoch 405/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0406 - accuracy: 0.9885 - val_loss: 0.0543 - val_accuracy: 0.9831\n",
            "Epoch 406/2000\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0393 - accuracy: 0.9895 - val_loss: 0.0535 - val_accuracy: 0.9823\n",
            "Epoch 407/2000\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.0394 - accuracy: 0.9902 - val_loss: 0.0557 - val_accuracy: 0.9831\n",
            "Epoch 408/2000\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 0.0399 - accuracy: 0.9890 - val_loss: 0.0542 - val_accuracy: 0.9838\n",
            "Epoch 409/2000\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.0405 - accuracy: 0.9877 - val_loss: 0.0615 - val_accuracy: 0.9808\n",
            "Epoch 410/2000\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.0401 - accuracy: 0.9890 - val_loss: 0.0540 - val_accuracy: 0.9838\n",
            "Epoch 411/2000\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 0.0394 - accuracy: 0.9908 - val_loss: 0.0537 - val_accuracy: 0.9838\n",
            "Epoch 412/2000\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 0.0414 - accuracy: 0.9877 - val_loss: 0.0541 - val_accuracy: 0.9823\n",
            "Epoch 413/2000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0410 - accuracy: 0.9885 - val_loss: 0.0616 - val_accuracy: 0.9808\n",
            "Epoch 414/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0413 - accuracy: 0.9882 - val_loss: 0.0537 - val_accuracy: 0.9823\n",
            "Epoch 415/2000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0392 - accuracy: 0.9897 - val_loss: 0.0592 - val_accuracy: 0.9823\n",
            "Epoch 416/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0413 - accuracy: 0.9885 - val_loss: 0.0540 - val_accuracy: 0.9823\n",
            "Epoch 417/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0395 - accuracy: 0.9887 - val_loss: 0.0555 - val_accuracy: 0.9846\n",
            "Epoch 418/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0407 - accuracy: 0.9887 - val_loss: 0.0558 - val_accuracy: 0.9831\n",
            "Epoch 419/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0408 - accuracy: 0.9890 - val_loss: 0.0535 - val_accuracy: 0.9846\n",
            "Epoch 420/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0403 - accuracy: 0.9902 - val_loss: 0.0566 - val_accuracy: 0.9831\n",
            "Epoch 421/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0417 - accuracy: 0.9882 - val_loss: 0.0546 - val_accuracy: 0.9838\n",
            "Epoch 422/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0413 - accuracy: 0.9887 - val_loss: 0.0543 - val_accuracy: 0.9831\n",
            "Epoch 423/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0409 - accuracy: 0.9885 - val_loss: 0.0672 - val_accuracy: 0.9815\n",
            "Epoch 424/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0446 - accuracy: 0.9864 - val_loss: 0.0574 - val_accuracy: 0.9823\n",
            "Epoch 425/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0449 - accuracy: 0.9864 - val_loss: 0.0549 - val_accuracy: 0.9838\n",
            "Epoch 426/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0512 - accuracy: 0.9859 - val_loss: 0.0536 - val_accuracy: 0.9846\n",
            "Epoch 427/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0468 - accuracy: 0.9864 - val_loss: 0.0634 - val_accuracy: 0.9808\n",
            "Epoch 428/2000\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0462 - accuracy: 0.9864 - val_loss: 0.0584 - val_accuracy: 0.9831\n",
            "Epoch 429/2000\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0452 - accuracy: 0.9872 - val_loss: 0.0563 - val_accuracy: 0.9838\n",
            "Epoch 430/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0399 - accuracy: 0.9890 - val_loss: 0.0542 - val_accuracy: 0.9831\n",
            "Epoch 431/2000\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0395 - accuracy: 0.9895 - val_loss: 0.0564 - val_accuracy: 0.9823\n",
            "Epoch 432/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0398 - accuracy: 0.9892 - val_loss: 0.0562 - val_accuracy: 0.9838\n",
            "Epoch 433/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0402 - accuracy: 0.9890 - val_loss: 0.0541 - val_accuracy: 0.9838\n",
            "Epoch 434/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0406 - accuracy: 0.9897 - val_loss: 0.0552 - val_accuracy: 0.9846\n",
            "Epoch 435/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0403 - accuracy: 0.9887 - val_loss: 0.0537 - val_accuracy: 0.9831\n",
            "Epoch 436/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0397 - accuracy: 0.9895 - val_loss: 0.0544 - val_accuracy: 0.9838\n",
            "Epoch 437/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0400 - accuracy: 0.9882 - val_loss: 0.0537 - val_accuracy: 0.9846\n",
            "Epoch 438/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0392 - accuracy: 0.9885 - val_loss: 0.0634 - val_accuracy: 0.9815\n",
            "Epoch 439/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0454 - accuracy: 0.9885 - val_loss: 0.0549 - val_accuracy: 0.9831\n",
            "Epoch 440/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0418 - accuracy: 0.9882 - val_loss: 0.0536 - val_accuracy: 0.9831\n",
            "Epoch 441/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0418 - accuracy: 0.9877 - val_loss: 0.0606 - val_accuracy: 0.9823\n",
            "Epoch 442/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0445 - accuracy: 0.9869 - val_loss: 0.0554 - val_accuracy: 0.9846\n",
            "Epoch 443/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0418 - accuracy: 0.9892 - val_loss: 0.0543 - val_accuracy: 0.9831\n",
            "Epoch 444/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0404 - accuracy: 0.9890 - val_loss: 0.0535 - val_accuracy: 0.9831\n",
            "Epoch 445/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0402 - accuracy: 0.9892 - val_loss: 0.0541 - val_accuracy: 0.9831\n",
            "Epoch 446/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0417 - accuracy: 0.9885 - val_loss: 0.0680 - val_accuracy: 0.9792\n",
            "Epoch 447/2000\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0459 - accuracy: 0.9879 - val_loss: 0.0570 - val_accuracy: 0.9831\n",
            "Epoch 448/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0394 - accuracy: 0.9895 - val_loss: 0.0542 - val_accuracy: 0.9838\n",
            "Epoch 449/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0404 - accuracy: 0.9885 - val_loss: 0.0548 - val_accuracy: 0.9838\n",
            "Epoch 450/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0404 - accuracy: 0.9895 - val_loss: 0.0545 - val_accuracy: 0.9831\n",
            "Epoch 451/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0399 - accuracy: 0.9885 - val_loss: 0.0538 - val_accuracy: 0.9838\n",
            "Epoch 452/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0418 - accuracy: 0.9877 - val_loss: 0.0541 - val_accuracy: 0.9838\n",
            "Epoch 453/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0390 - accuracy: 0.9897 - val_loss: 0.0534 - val_accuracy: 0.9831\n",
            "Epoch 454/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0424 - accuracy: 0.9874 - val_loss: 0.0566 - val_accuracy: 0.9831\n",
            "Epoch 455/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0405 - accuracy: 0.9892 - val_loss: 0.0538 - val_accuracy: 0.9846\n",
            "Epoch 456/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0391 - accuracy: 0.9908 - val_loss: 0.0532 - val_accuracy: 0.9846\n",
            "Epoch 457/2000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0387 - accuracy: 0.9900 - val_loss: 0.0547 - val_accuracy: 0.9838\n",
            "Epoch 458/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0391 - accuracy: 0.9890 - val_loss: 0.0544 - val_accuracy: 0.9838\n",
            "Epoch 459/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0393 - accuracy: 0.9887 - val_loss: 0.0558 - val_accuracy: 0.9838\n",
            "Epoch 460/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0394 - accuracy: 0.9892 - val_loss: 0.0545 - val_accuracy: 0.9854\n",
            "Epoch 461/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0403 - accuracy: 0.9900 - val_loss: 0.0556 - val_accuracy: 0.9831\n",
            "Epoch 462/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0389 - accuracy: 0.9897 - val_loss: 0.0532 - val_accuracy: 0.9831\n",
            "Epoch 463/2000\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0388 - accuracy: 0.9902 - val_loss: 0.0539 - val_accuracy: 0.9846\n",
            "Epoch 464/2000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0389 - accuracy: 0.9902 - val_loss: 0.0545 - val_accuracy: 0.9838\n",
            "Epoch 465/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0388 - accuracy: 0.9900 - val_loss: 0.0537 - val_accuracy: 0.9831\n",
            "Epoch 466/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0390 - accuracy: 0.9895 - val_loss: 0.0549 - val_accuracy: 0.9838\n",
            "Epoch 467/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0400 - accuracy: 0.9885 - val_loss: 0.0539 - val_accuracy: 0.9854\n",
            "Epoch 468/2000\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0389 - accuracy: 0.9887 - val_loss: 0.0537 - val_accuracy: 0.9846\n",
            "Epoch 469/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0402 - accuracy: 0.9885 - val_loss: 0.0532 - val_accuracy: 0.9838\n",
            "Epoch 470/2000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0406 - accuracy: 0.9890 - val_loss: 0.0554 - val_accuracy: 0.9838\n",
            "Epoch 471/2000\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0397 - accuracy: 0.9897 - val_loss: 0.0541 - val_accuracy: 0.9838\n",
            "Epoch 472/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0396 - accuracy: 0.9892 - val_loss: 0.0532 - val_accuracy: 0.9831\n",
            "Epoch 473/2000\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0384 - accuracy: 0.9908 - val_loss: 0.0557 - val_accuracy: 0.9846\n",
            "Epoch 474/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0387 - accuracy: 0.9882 - val_loss: 0.0533 - val_accuracy: 0.9838\n",
            "Epoch 475/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0386 - accuracy: 0.9890 - val_loss: 0.0570 - val_accuracy: 0.9831\n",
            "Epoch 476/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0398 - accuracy: 0.9892 - val_loss: 0.0532 - val_accuracy: 0.9831\n",
            "Epoch 477/2000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0385 - accuracy: 0.9892 - val_loss: 0.0543 - val_accuracy: 0.9831\n",
            "Epoch 478/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0386 - accuracy: 0.9900 - val_loss: 0.0550 - val_accuracy: 0.9846\n",
            "Epoch 479/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0392 - accuracy: 0.9885 - val_loss: 0.0547 - val_accuracy: 0.9854\n",
            "Epoch 480/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0392 - accuracy: 0.9885 - val_loss: 0.0546 - val_accuracy: 0.9846\n",
            "Epoch 481/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0403 - accuracy: 0.9890 - val_loss: 0.0531 - val_accuracy: 0.9831\n",
            "Epoch 482/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0388 - accuracy: 0.9902 - val_loss: 0.0538 - val_accuracy: 0.9854\n",
            "Epoch 483/2000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0391 - accuracy: 0.9900 - val_loss: 0.0537 - val_accuracy: 0.9846\n",
            "Epoch 484/2000\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0392 - accuracy: 0.9897 - val_loss: 0.0558 - val_accuracy: 0.9831\n",
            "Epoch 485/2000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0400 - accuracy: 0.9897 - val_loss: 0.0586 - val_accuracy: 0.9823\n",
            "Epoch 486/2000\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.0414 - accuracy: 0.9872 - val_loss: 0.0542 - val_accuracy: 0.9846\n",
            "Epoch 487/2000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0393 - accuracy: 0.9892 - val_loss: 0.0536 - val_accuracy: 0.9838\n",
            "Epoch 488/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0400 - accuracy: 0.9900 - val_loss: 0.0583 - val_accuracy: 0.9823\n",
            "Epoch 489/2000\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0428 - accuracy: 0.9869 - val_loss: 0.0548 - val_accuracy: 0.9838\n",
            "Epoch 490/2000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0458 - accuracy: 0.9864 - val_loss: 0.0559 - val_accuracy: 0.9846\n",
            "Epoch 491/2000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0407 - accuracy: 0.9872 - val_loss: 0.0577 - val_accuracy: 0.9808\n",
            "Epoch 492/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0401 - accuracy: 0.9897 - val_loss: 0.0542 - val_accuracy: 0.9838\n",
            "Epoch 493/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0396 - accuracy: 0.9895 - val_loss: 0.0573 - val_accuracy: 0.9838\n",
            "Epoch 494/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0443 - accuracy: 0.9872 - val_loss: 0.0542 - val_accuracy: 0.9831\n",
            "Epoch 495/2000\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0490 - accuracy: 0.9833 - val_loss: 0.0628 - val_accuracy: 0.9800\n",
            "Epoch 496/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0465 - accuracy: 0.9861 - val_loss: 0.0659 - val_accuracy: 0.9800\n",
            "Epoch 497/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0425 - accuracy: 0.9874 - val_loss: 0.0534 - val_accuracy: 0.9831\n",
            "Epoch 498/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0418 - accuracy: 0.9887 - val_loss: 0.0547 - val_accuracy: 0.9831\n",
            "Epoch 499/2000\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0392 - accuracy: 0.9895 - val_loss: 0.0538 - val_accuracy: 0.9838\n",
            "Epoch 500/2000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0390 - accuracy: 0.9890 - val_loss: 0.0537 - val_accuracy: 0.9831\n",
            "Epoch 501/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0392 - accuracy: 0.9892 - val_loss: 0.0533 - val_accuracy: 0.9846\n",
            "Epoch 502/2000\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0399 - accuracy: 0.9895 - val_loss: 0.0557 - val_accuracy: 0.9831\n",
            "Epoch 503/2000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0403 - accuracy: 0.9879 - val_loss: 0.0546 - val_accuracy: 0.9838\n",
            "Epoch 504/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0389 - accuracy: 0.9900 - val_loss: 0.0534 - val_accuracy: 0.9838\n",
            "Epoch 505/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0399 - accuracy: 0.9895 - val_loss: 0.0535 - val_accuracy: 0.9846\n",
            "Epoch 506/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0402 - accuracy: 0.9895 - val_loss: 0.0599 - val_accuracy: 0.9831\n",
            "Epoch 507/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0407 - accuracy: 0.9887 - val_loss: 0.0538 - val_accuracy: 0.9838\n",
            "Epoch 508/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0405 - accuracy: 0.9890 - val_loss: 0.0559 - val_accuracy: 0.9823\n",
            "Epoch 509/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0426 - accuracy: 0.9882 - val_loss: 0.0616 - val_accuracy: 0.9792\n",
            "Epoch 510/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0420 - accuracy: 0.9882 - val_loss: 0.0559 - val_accuracy: 0.9823\n",
            "Epoch 511/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0406 - accuracy: 0.9887 - val_loss: 0.0542 - val_accuracy: 0.9846\n",
            "Epoch 512/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0384 - accuracy: 0.9885 - val_loss: 0.0539 - val_accuracy: 0.9831\n",
            "Epoch 513/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0385 - accuracy: 0.9905 - val_loss: 0.0533 - val_accuracy: 0.9846\n",
            "Epoch 514/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0382 - accuracy: 0.9902 - val_loss: 0.0534 - val_accuracy: 0.9831\n",
            "Epoch 515/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0390 - accuracy: 0.9887 - val_loss: 0.0539 - val_accuracy: 0.9838\n",
            "Epoch 516/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0397 - accuracy: 0.9900 - val_loss: 0.0586 - val_accuracy: 0.9831\n",
            "Epoch 517/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0406 - accuracy: 0.9890 - val_loss: 0.0537 - val_accuracy: 0.9838\n",
            "Epoch 518/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0412 - accuracy: 0.9885 - val_loss: 0.0566 - val_accuracy: 0.9831\n",
            "Epoch 519/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0401 - accuracy: 0.9890 - val_loss: 0.0537 - val_accuracy: 0.9846\n",
            "Epoch 520/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0384 - accuracy: 0.9900 - val_loss: 0.0537 - val_accuracy: 0.9838\n",
            "Epoch 521/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0380 - accuracy: 0.9902 - val_loss: 0.0537 - val_accuracy: 0.9838\n",
            "Epoch 522/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0379 - accuracy: 0.9897 - val_loss: 0.0561 - val_accuracy: 0.9831\n",
            "Epoch 523/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0415 - accuracy: 0.9887 - val_loss: 0.0562 - val_accuracy: 0.9823\n",
            "Epoch 524/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0414 - accuracy: 0.9902 - val_loss: 0.0564 - val_accuracy: 0.9831\n",
            "Epoch 525/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0420 - accuracy: 0.9897 - val_loss: 0.0592 - val_accuracy: 0.9823\n",
            "Epoch 526/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0384 - accuracy: 0.9887 - val_loss: 0.0603 - val_accuracy: 0.9815\n",
            "Epoch 527/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0414 - accuracy: 0.9887 - val_loss: 0.0564 - val_accuracy: 0.9838\n",
            "Epoch 528/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0430 - accuracy: 0.9879 - val_loss: 0.0536 - val_accuracy: 0.9838\n",
            "Epoch 529/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0405 - accuracy: 0.9887 - val_loss: 0.0543 - val_accuracy: 0.9846\n",
            "Epoch 530/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0386 - accuracy: 0.9895 - val_loss: 0.0549 - val_accuracy: 0.9831\n",
            "Epoch 531/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0389 - accuracy: 0.9890 - val_loss: 0.0537 - val_accuracy: 0.9831\n",
            "Epoch 532/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0390 - accuracy: 0.9887 - val_loss: 0.0542 - val_accuracy: 0.9838\n",
            "Epoch 533/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0379 - accuracy: 0.9902 - val_loss: 0.0541 - val_accuracy: 0.9838\n",
            "Epoch 534/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0386 - accuracy: 0.9900 - val_loss: 0.0540 - val_accuracy: 0.9838\n",
            "Epoch 535/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0377 - accuracy: 0.9902 - val_loss: 0.0552 - val_accuracy: 0.9846\n",
            "Epoch 536/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0383 - accuracy: 0.9892 - val_loss: 0.0536 - val_accuracy: 0.9838\n",
            "Epoch 537/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0379 - accuracy: 0.9897 - val_loss: 0.0531 - val_accuracy: 0.9831\n",
            "Epoch 538/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0382 - accuracy: 0.9902 - val_loss: 0.0534 - val_accuracy: 0.9838\n",
            "Epoch 539/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0413 - accuracy: 0.9887 - val_loss: 0.0541 - val_accuracy: 0.9854\n",
            "Epoch 540/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0388 - accuracy: 0.9879 - val_loss: 0.0537 - val_accuracy: 0.9846\n",
            "Epoch 541/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0387 - accuracy: 0.9902 - val_loss: 0.0606 - val_accuracy: 0.9792\n",
            "Epoch 542/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0404 - accuracy: 0.9895 - val_loss: 0.0537 - val_accuracy: 0.9838\n",
            "Epoch 543/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0385 - accuracy: 0.9895 - val_loss: 0.0537 - val_accuracy: 0.9846\n",
            "Epoch 544/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0407 - accuracy: 0.9885 - val_loss: 0.0543 - val_accuracy: 0.9838\n",
            "Epoch 545/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0391 - accuracy: 0.9895 - val_loss: 0.0533 - val_accuracy: 0.9838\n",
            "Epoch 546/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0381 - accuracy: 0.9900 - val_loss: 0.0536 - val_accuracy: 0.9838\n",
            "Epoch 547/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0381 - accuracy: 0.9895 - val_loss: 0.0537 - val_accuracy: 0.9838\n",
            "Epoch 548/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0377 - accuracy: 0.9900 - val_loss: 0.0539 - val_accuracy: 0.9846\n",
            "Epoch 549/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0381 - accuracy: 0.9902 - val_loss: 0.0538 - val_accuracy: 0.9846\n",
            "Epoch 550/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0409 - accuracy: 0.9872 - val_loss: 0.0541 - val_accuracy: 0.9854\n",
            "Epoch 551/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0381 - accuracy: 0.9897 - val_loss: 0.0538 - val_accuracy: 0.9838\n",
            "Epoch 552/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0383 - accuracy: 0.9895 - val_loss: 0.0539 - val_accuracy: 0.9838\n",
            "Epoch 553/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0386 - accuracy: 0.9895 - val_loss: 0.0553 - val_accuracy: 0.9838\n",
            "Epoch 554/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0388 - accuracy: 0.9895 - val_loss: 0.0533 - val_accuracy: 0.9846\n",
            "Epoch 555/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0392 - accuracy: 0.9890 - val_loss: 0.0548 - val_accuracy: 0.9854\n",
            "Epoch 556/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0378 - accuracy: 0.9897 - val_loss: 0.0534 - val_accuracy: 0.9846\n",
            "Epoch 557/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0390 - accuracy: 0.9895 - val_loss: 0.0532 - val_accuracy: 0.9838\n",
            "Epoch 558/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0403 - accuracy: 0.9887 - val_loss: 0.0534 - val_accuracy: 0.9838\n",
            "Epoch 559/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0395 - accuracy: 0.9892 - val_loss: 0.0570 - val_accuracy: 0.9815\n",
            "Epoch 560/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0399 - accuracy: 0.9885 - val_loss: 0.0587 - val_accuracy: 0.9808\n",
            "Epoch 561/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0426 - accuracy: 0.9872 - val_loss: 0.0534 - val_accuracy: 0.9838\n",
            "Epoch 562/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0398 - accuracy: 0.9890 - val_loss: 0.0540 - val_accuracy: 0.9831\n",
            "Epoch 563/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0390 - accuracy: 0.9892 - val_loss: 0.0550 - val_accuracy: 0.9831\n",
            "Epoch 564/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0376 - accuracy: 0.9910 - val_loss: 0.0539 - val_accuracy: 0.9846\n",
            "Epoch 565/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0377 - accuracy: 0.9902 - val_loss: 0.0541 - val_accuracy: 0.9854\n",
            "Epoch 566/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0379 - accuracy: 0.9895 - val_loss: 0.0539 - val_accuracy: 0.9846\n",
            "Epoch 567/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0388 - accuracy: 0.9900 - val_loss: 0.0563 - val_accuracy: 0.9838\n",
            "Epoch 568/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0386 - accuracy: 0.9895 - val_loss: 0.0542 - val_accuracy: 0.9854\n",
            "Epoch 569/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0398 - accuracy: 0.9895 - val_loss: 0.0544 - val_accuracy: 0.9854\n",
            "Epoch 570/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0395 - accuracy: 0.9892 - val_loss: 0.0557 - val_accuracy: 0.9846\n",
            "Epoch 571/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0393 - accuracy: 0.9890 - val_loss: 0.0552 - val_accuracy: 0.9846\n",
            "Epoch 572/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0424 - accuracy: 0.9897 - val_loss: 0.0537 - val_accuracy: 0.9838\n",
            "Epoch 573/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0389 - accuracy: 0.9895 - val_loss: 0.0532 - val_accuracy: 0.9846\n",
            "Epoch 574/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0377 - accuracy: 0.9902 - val_loss: 0.0533 - val_accuracy: 0.9838\n",
            "Epoch 575/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0373 - accuracy: 0.9905 - val_loss: 0.0537 - val_accuracy: 0.9846\n",
            "Epoch 576/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0387 - accuracy: 0.9908 - val_loss: 0.0548 - val_accuracy: 0.9838\n",
            "Epoch 577/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0392 - accuracy: 0.9890 - val_loss: 0.0545 - val_accuracy: 0.9838\n",
            "Epoch 578/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0373 - accuracy: 0.9905 - val_loss: 0.0542 - val_accuracy: 0.9846\n",
            "Epoch 579/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0372 - accuracy: 0.9902 - val_loss: 0.0542 - val_accuracy: 0.9831\n",
            "Epoch 580/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0415 - accuracy: 0.9885 - val_loss: 0.0540 - val_accuracy: 0.9831\n",
            "Epoch 581/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0395 - accuracy: 0.9892 - val_loss: 0.0556 - val_accuracy: 0.9831\n",
            "Epoch 582/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0404 - accuracy: 0.9879 - val_loss: 0.0552 - val_accuracy: 0.9862\n",
            "Epoch 583/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0393 - accuracy: 0.9900 - val_loss: 0.0567 - val_accuracy: 0.9854\n",
            "Epoch 584/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0379 - accuracy: 0.9882 - val_loss: 0.0540 - val_accuracy: 0.9823\n",
            "Epoch 585/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0371 - accuracy: 0.9897 - val_loss: 0.0539 - val_accuracy: 0.9831\n",
            "Epoch 586/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0380 - accuracy: 0.9902 - val_loss: 0.0538 - val_accuracy: 0.9846\n",
            "Epoch 587/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0395 - accuracy: 0.9882 - val_loss: 0.0531 - val_accuracy: 0.9846\n",
            "Epoch 588/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0377 - accuracy: 0.9892 - val_loss: 0.0537 - val_accuracy: 0.9846\n",
            "Epoch 589/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0374 - accuracy: 0.9900 - val_loss: 0.0540 - val_accuracy: 0.9831\n",
            "Epoch 590/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0380 - accuracy: 0.9879 - val_loss: 0.0567 - val_accuracy: 0.9838\n",
            "Epoch 591/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0398 - accuracy: 0.9892 - val_loss: 0.0534 - val_accuracy: 0.9831\n",
            "Epoch 592/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0387 - accuracy: 0.9887 - val_loss: 0.0541 - val_accuracy: 0.9862\n",
            "Epoch 593/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0377 - accuracy: 0.9908 - val_loss: 0.0545 - val_accuracy: 0.9846\n",
            "Epoch 594/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0377 - accuracy: 0.9910 - val_loss: 0.0541 - val_accuracy: 0.9823\n",
            "Epoch 595/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0411 - accuracy: 0.9877 - val_loss: 0.0543 - val_accuracy: 0.9831\n",
            "Epoch 596/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0396 - accuracy: 0.9892 - val_loss: 0.0586 - val_accuracy: 0.9808\n",
            "Epoch 597/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0392 - accuracy: 0.9882 - val_loss: 0.0534 - val_accuracy: 0.9838\n",
            "Epoch 598/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0424 - accuracy: 0.9885 - val_loss: 0.0550 - val_accuracy: 0.9838\n",
            "Epoch 599/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0369 - accuracy: 0.9910 - val_loss: 0.0536 - val_accuracy: 0.9838\n",
            "Epoch 600/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0376 - accuracy: 0.9905 - val_loss: 0.0570 - val_accuracy: 0.9846\n",
            "Epoch 601/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0376 - accuracy: 0.9897 - val_loss: 0.0532 - val_accuracy: 0.9838\n",
            "Epoch 602/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0371 - accuracy: 0.9913 - val_loss: 0.0532 - val_accuracy: 0.9854\n",
            "Epoch 603/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0379 - accuracy: 0.9908 - val_loss: 0.0531 - val_accuracy: 0.9838\n",
            "Epoch 604/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0375 - accuracy: 0.9915 - val_loss: 0.0545 - val_accuracy: 0.9846\n",
            "Epoch 605/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0372 - accuracy: 0.9908 - val_loss: 0.0532 - val_accuracy: 0.9838\n",
            "Epoch 606/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0377 - accuracy: 0.9908 - val_loss: 0.0531 - val_accuracy: 0.9854\n",
            "Epoch 607/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0377 - accuracy: 0.9895 - val_loss: 0.0544 - val_accuracy: 0.9838\n",
            "Epoch 608/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0384 - accuracy: 0.9895 - val_loss: 0.0537 - val_accuracy: 0.9846\n",
            "Epoch 609/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0386 - accuracy: 0.9882 - val_loss: 0.0534 - val_accuracy: 0.9846\n",
            "Epoch 610/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0402 - accuracy: 0.9892 - val_loss: 0.0542 - val_accuracy: 0.9862\n",
            "Epoch 611/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0391 - accuracy: 0.9895 - val_loss: 0.0547 - val_accuracy: 0.9838\n",
            "Epoch 612/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0392 - accuracy: 0.9892 - val_loss: 0.0537 - val_accuracy: 0.9846\n",
            "Epoch 613/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0367 - accuracy: 0.9910 - val_loss: 0.0537 - val_accuracy: 0.9846\n",
            "Epoch 614/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0390 - accuracy: 0.9892 - val_loss: 0.0552 - val_accuracy: 0.9846\n",
            "Epoch 615/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0396 - accuracy: 0.9887 - val_loss: 0.0529 - val_accuracy: 0.9854\n",
            "Epoch 616/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0366 - accuracy: 0.9908 - val_loss: 0.0535 - val_accuracy: 0.9846\n",
            "Epoch 617/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0374 - accuracy: 0.9892 - val_loss: 0.0530 - val_accuracy: 0.9846\n",
            "Epoch 618/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0355 - accuracy: 0.9918 - val_loss: 0.0591 - val_accuracy: 0.9838\n",
            "Epoch 619/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0419 - accuracy: 0.9892 - val_loss: 0.0537 - val_accuracy: 0.9838\n",
            "Epoch 620/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0409 - accuracy: 0.9890 - val_loss: 0.0542 - val_accuracy: 0.9838\n",
            "Epoch 621/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0391 - accuracy: 0.9887 - val_loss: 0.0578 - val_accuracy: 0.9831\n",
            "Epoch 622/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0437 - accuracy: 0.9877 - val_loss: 0.0575 - val_accuracy: 0.9846\n",
            "Epoch 623/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0389 - accuracy: 0.9882 - val_loss: 0.0532 - val_accuracy: 0.9846\n",
            "Epoch 624/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0376 - accuracy: 0.9905 - val_loss: 0.0599 - val_accuracy: 0.9831\n",
            "Epoch 625/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0417 - accuracy: 0.9882 - val_loss: 0.0548 - val_accuracy: 0.9831\n",
            "Epoch 626/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0382 - accuracy: 0.9897 - val_loss: 0.0529 - val_accuracy: 0.9846\n",
            "Epoch 627/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0366 - accuracy: 0.9902 - val_loss: 0.0532 - val_accuracy: 0.9854\n",
            "Epoch 628/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0367 - accuracy: 0.9910 - val_loss: 0.0526 - val_accuracy: 0.9846\n",
            "Epoch 629/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0367 - accuracy: 0.9892 - val_loss: 0.0529 - val_accuracy: 0.9846\n",
            "Epoch 630/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0364 - accuracy: 0.9908 - val_loss: 0.0533 - val_accuracy: 0.9831\n",
            "Epoch 631/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0378 - accuracy: 0.9895 - val_loss: 0.0545 - val_accuracy: 0.9854\n",
            "Epoch 632/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0372 - accuracy: 0.9900 - val_loss: 0.0530 - val_accuracy: 0.9838\n",
            "Epoch 633/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0379 - accuracy: 0.9897 - val_loss: 0.0621 - val_accuracy: 0.9815\n",
            "Epoch 634/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0382 - accuracy: 0.9900 - val_loss: 0.0528 - val_accuracy: 0.9846\n",
            "Epoch 635/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0364 - accuracy: 0.9902 - val_loss: 0.0524 - val_accuracy: 0.9846\n",
            "Epoch 636/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0364 - accuracy: 0.9905 - val_loss: 0.0524 - val_accuracy: 0.9846\n",
            "Epoch 637/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0366 - accuracy: 0.9905 - val_loss: 0.0536 - val_accuracy: 0.9854\n",
            "Epoch 638/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0368 - accuracy: 0.9895 - val_loss: 0.0531 - val_accuracy: 0.9846\n",
            "Epoch 639/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0377 - accuracy: 0.9902 - val_loss: 0.0525 - val_accuracy: 0.9846\n",
            "Epoch 640/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0363 - accuracy: 0.9910 - val_loss: 0.0531 - val_accuracy: 0.9846\n",
            "Epoch 641/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0360 - accuracy: 0.9902 - val_loss: 0.0543 - val_accuracy: 0.9846\n",
            "Epoch 642/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0389 - accuracy: 0.9902 - val_loss: 0.0534 - val_accuracy: 0.9838\n",
            "Epoch 643/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0373 - accuracy: 0.9910 - val_loss: 0.0548 - val_accuracy: 0.9846\n",
            "Epoch 644/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0372 - accuracy: 0.9902 - val_loss: 0.0527 - val_accuracy: 0.9838\n",
            "Epoch 645/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0375 - accuracy: 0.9902 - val_loss: 0.0527 - val_accuracy: 0.9846\n",
            "Epoch 646/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0373 - accuracy: 0.9890 - val_loss: 0.0524 - val_accuracy: 0.9846\n",
            "Epoch 647/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0362 - accuracy: 0.9905 - val_loss: 0.0524 - val_accuracy: 0.9846\n",
            "Epoch 648/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0360 - accuracy: 0.9902 - val_loss: 0.0538 - val_accuracy: 0.9846\n",
            "Epoch 649/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0379 - accuracy: 0.9900 - val_loss: 0.0536 - val_accuracy: 0.9846\n",
            "Epoch 650/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0362 - accuracy: 0.9910 - val_loss: 0.0541 - val_accuracy: 0.9831\n",
            "Epoch 651/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0363 - accuracy: 0.9910 - val_loss: 0.0526 - val_accuracy: 0.9846\n",
            "Epoch 652/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0365 - accuracy: 0.9908 - val_loss: 0.0521 - val_accuracy: 0.9846\n",
            "Epoch 653/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0379 - accuracy: 0.9910 - val_loss: 0.0557 - val_accuracy: 0.9846\n",
            "Epoch 654/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0406 - accuracy: 0.9900 - val_loss: 0.0591 - val_accuracy: 0.9815\n",
            "Epoch 655/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0385 - accuracy: 0.9900 - val_loss: 0.0528 - val_accuracy: 0.9846\n",
            "Epoch 656/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0366 - accuracy: 0.9900 - val_loss: 0.0525 - val_accuracy: 0.9846\n",
            "Epoch 657/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0367 - accuracy: 0.9902 - val_loss: 0.0529 - val_accuracy: 0.9846\n",
            "Epoch 658/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0392 - accuracy: 0.9895 - val_loss: 0.0540 - val_accuracy: 0.9862\n",
            "Epoch 659/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0384 - accuracy: 0.9890 - val_loss: 0.0538 - val_accuracy: 0.9846\n",
            "Epoch 660/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0394 - accuracy: 0.9887 - val_loss: 0.0558 - val_accuracy: 0.9846\n",
            "Epoch 661/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0403 - accuracy: 0.9892 - val_loss: 0.0530 - val_accuracy: 0.9846\n",
            "Epoch 662/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0402 - accuracy: 0.9892 - val_loss: 0.0540 - val_accuracy: 0.9854\n",
            "Epoch 663/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0417 - accuracy: 0.9887 - val_loss: 0.0713 - val_accuracy: 0.9785\n",
            "Epoch 664/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0464 - accuracy: 0.9879 - val_loss: 0.0564 - val_accuracy: 0.9831\n",
            "Epoch 665/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0406 - accuracy: 0.9897 - val_loss: 0.0574 - val_accuracy: 0.9838\n",
            "Epoch 666/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0396 - accuracy: 0.9882 - val_loss: 0.0542 - val_accuracy: 0.9846\n",
            "Epoch 667/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0374 - accuracy: 0.9905 - val_loss: 0.0535 - val_accuracy: 0.9846\n",
            "Epoch 668/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0360 - accuracy: 0.9908 - val_loss: 0.0531 - val_accuracy: 0.9838\n",
            "Epoch 669/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0362 - accuracy: 0.9900 - val_loss: 0.0530 - val_accuracy: 0.9846\n",
            "Epoch 670/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0361 - accuracy: 0.9908 - val_loss: 0.0528 - val_accuracy: 0.9846\n",
            "Epoch 671/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0362 - accuracy: 0.9895 - val_loss: 0.0570 - val_accuracy: 0.9831\n",
            "Epoch 672/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0371 - accuracy: 0.9900 - val_loss: 0.0523 - val_accuracy: 0.9846\n",
            "Epoch 673/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0360 - accuracy: 0.9910 - val_loss: 0.0524 - val_accuracy: 0.9846\n",
            "Epoch 674/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0361 - accuracy: 0.9913 - val_loss: 0.0553 - val_accuracy: 0.9846\n",
            "Epoch 675/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0381 - accuracy: 0.9895 - val_loss: 0.0529 - val_accuracy: 0.9846\n",
            "Epoch 676/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0381 - accuracy: 0.9897 - val_loss: 0.0544 - val_accuracy: 0.9854\n",
            "Epoch 677/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0387 - accuracy: 0.9895 - val_loss: 0.0612 - val_accuracy: 0.9815\n",
            "Epoch 678/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0401 - accuracy: 0.9895 - val_loss: 0.0531 - val_accuracy: 0.9854\n",
            "Epoch 679/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0377 - accuracy: 0.9897 - val_loss: 0.0581 - val_accuracy: 0.9831\n",
            "Epoch 680/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0397 - accuracy: 0.9897 - val_loss: 0.0527 - val_accuracy: 0.9838\n",
            "Epoch 681/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0361 - accuracy: 0.9905 - val_loss: 0.0535 - val_accuracy: 0.9854\n",
            "Epoch 682/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0356 - accuracy: 0.9908 - val_loss: 0.0530 - val_accuracy: 0.9846\n",
            "Epoch 683/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0357 - accuracy: 0.9913 - val_loss: 0.0533 - val_accuracy: 0.9846\n",
            "Epoch 684/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0360 - accuracy: 0.9897 - val_loss: 0.0524 - val_accuracy: 0.9846\n",
            "Epoch 685/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0355 - accuracy: 0.9913 - val_loss: 0.0525 - val_accuracy: 0.9838\n",
            "Epoch 686/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0354 - accuracy: 0.9908 - val_loss: 0.0520 - val_accuracy: 0.9846\n",
            "Epoch 687/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0355 - accuracy: 0.9913 - val_loss: 0.0524 - val_accuracy: 0.9846\n",
            "Epoch 688/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0353 - accuracy: 0.9913 - val_loss: 0.0527 - val_accuracy: 0.9846\n",
            "Epoch 689/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0358 - accuracy: 0.9910 - val_loss: 0.0533 - val_accuracy: 0.9846\n",
            "Epoch 690/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0353 - accuracy: 0.9910 - val_loss: 0.0527 - val_accuracy: 0.9846\n",
            "Epoch 691/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0359 - accuracy: 0.9915 - val_loss: 0.0524 - val_accuracy: 0.9838\n",
            "Epoch 692/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0373 - accuracy: 0.9905 - val_loss: 0.0527 - val_accuracy: 0.9862\n",
            "Epoch 693/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0406 - accuracy: 0.9885 - val_loss: 0.0548 - val_accuracy: 0.9854\n",
            "Epoch 694/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0357 - accuracy: 0.9908 - val_loss: 0.0534 - val_accuracy: 0.9838\n",
            "Epoch 695/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0354 - accuracy: 0.9913 - val_loss: 0.0532 - val_accuracy: 0.9854\n",
            "Epoch 696/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0368 - accuracy: 0.9908 - val_loss: 0.0542 - val_accuracy: 0.9846\n",
            "Epoch 697/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0382 - accuracy: 0.9892 - val_loss: 0.0547 - val_accuracy: 0.9854\n",
            "Epoch 698/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0360 - accuracy: 0.9913 - val_loss: 0.0524 - val_accuracy: 0.9854\n",
            "Epoch 699/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0351 - accuracy: 0.9915 - val_loss: 0.0526 - val_accuracy: 0.9846\n",
            "Epoch 700/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0376 - accuracy: 0.9905 - val_loss: 0.0543 - val_accuracy: 0.9854\n",
            "Epoch 701/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0389 - accuracy: 0.9897 - val_loss: 0.0529 - val_accuracy: 0.9846\n",
            "Epoch 702/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0389 - accuracy: 0.9890 - val_loss: 0.0616 - val_accuracy: 0.9823\n",
            "Epoch 703/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0402 - accuracy: 0.9902 - val_loss: 0.0539 - val_accuracy: 0.9854\n",
            "Epoch 704/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0374 - accuracy: 0.9890 - val_loss: 0.0541 - val_accuracy: 0.9846\n",
            "Epoch 705/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0355 - accuracy: 0.9913 - val_loss: 0.0525 - val_accuracy: 0.9846\n",
            "Epoch 706/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0351 - accuracy: 0.9915 - val_loss: 0.0530 - val_accuracy: 0.9838\n",
            "Epoch 707/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0358 - accuracy: 0.9910 - val_loss: 0.0530 - val_accuracy: 0.9838\n",
            "Epoch 708/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0352 - accuracy: 0.9910 - val_loss: 0.0528 - val_accuracy: 0.9838\n",
            "Epoch 709/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0352 - accuracy: 0.9910 - val_loss: 0.0524 - val_accuracy: 0.9846\n",
            "Epoch 710/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0360 - accuracy: 0.9915 - val_loss: 0.0531 - val_accuracy: 0.9846\n",
            "Epoch 711/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0367 - accuracy: 0.9910 - val_loss: 0.0549 - val_accuracy: 0.9854\n",
            "Epoch 712/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0386 - accuracy: 0.9908 - val_loss: 0.0529 - val_accuracy: 0.9846\n",
            "Epoch 713/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0372 - accuracy: 0.9908 - val_loss: 0.0528 - val_accuracy: 0.9854\n",
            "Epoch 714/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0357 - accuracy: 0.9913 - val_loss: 0.0538 - val_accuracy: 0.9854\n",
            "Epoch 715/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0375 - accuracy: 0.9890 - val_loss: 0.0528 - val_accuracy: 0.9846\n",
            "Epoch 716/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0370 - accuracy: 0.9892 - val_loss: 0.0652 - val_accuracy: 0.9808\n",
            "Epoch 717/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0409 - accuracy: 0.9882 - val_loss: 0.0538 - val_accuracy: 0.9854\n",
            "Epoch 718/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0362 - accuracy: 0.9902 - val_loss: 0.0534 - val_accuracy: 0.9846\n",
            "Epoch 719/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0355 - accuracy: 0.9902 - val_loss: 0.0527 - val_accuracy: 0.9854\n",
            "Epoch 720/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0381 - accuracy: 0.9897 - val_loss: 0.0529 - val_accuracy: 0.9846\n",
            "Epoch 721/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0392 - accuracy: 0.9900 - val_loss: 0.0730 - val_accuracy: 0.9769\n",
            "Epoch 722/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0440 - accuracy: 0.9864 - val_loss: 0.0537 - val_accuracy: 0.9838\n",
            "Epoch 723/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0364 - accuracy: 0.9913 - val_loss: 0.0532 - val_accuracy: 0.9838\n",
            "Epoch 724/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0354 - accuracy: 0.9913 - val_loss: 0.0534 - val_accuracy: 0.9846\n",
            "Epoch 725/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0364 - accuracy: 0.9900 - val_loss: 0.0533 - val_accuracy: 0.9846\n",
            "Epoch 726/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0355 - accuracy: 0.9905 - val_loss: 0.0556 - val_accuracy: 0.9854\n",
            "Epoch 727/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0364 - accuracy: 0.9905 - val_loss: 0.0533 - val_accuracy: 0.9838\n",
            "Epoch 728/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0356 - accuracy: 0.9905 - val_loss: 0.0540 - val_accuracy: 0.9862\n",
            "Epoch 729/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0364 - accuracy: 0.9902 - val_loss: 0.0546 - val_accuracy: 0.9838\n",
            "Epoch 730/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0407 - accuracy: 0.9890 - val_loss: 0.0529 - val_accuracy: 0.9846\n",
            "Epoch 731/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0364 - accuracy: 0.9915 - val_loss: 0.0559 - val_accuracy: 0.9838\n",
            "Epoch 732/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0391 - accuracy: 0.9897 - val_loss: 0.0551 - val_accuracy: 0.9838\n",
            "Epoch 733/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0399 - accuracy: 0.9887 - val_loss: 0.0535 - val_accuracy: 0.9838\n",
            "Epoch 734/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0364 - accuracy: 0.9900 - val_loss: 0.0566 - val_accuracy: 0.9854\n",
            "Epoch 735/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0381 - accuracy: 0.9902 - val_loss: 0.0533 - val_accuracy: 0.9838\n",
            "Epoch 736/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0379 - accuracy: 0.9892 - val_loss: 0.0533 - val_accuracy: 0.9846\n",
            "Epoch 737/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0387 - accuracy: 0.9902 - val_loss: 0.0544 - val_accuracy: 0.9846\n",
            "Epoch 738/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0358 - accuracy: 0.9908 - val_loss: 0.0527 - val_accuracy: 0.9838\n",
            "Epoch 739/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0358 - accuracy: 0.9910 - val_loss: 0.0529 - val_accuracy: 0.9838\n",
            "Epoch 740/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0352 - accuracy: 0.9908 - val_loss: 0.0528 - val_accuracy: 0.9854\n",
            "Epoch 741/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0365 - accuracy: 0.9910 - val_loss: 0.0528 - val_accuracy: 0.9846\n",
            "Epoch 742/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0351 - accuracy: 0.9908 - val_loss: 0.0530 - val_accuracy: 0.9846\n",
            "Epoch 743/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0346 - accuracy: 0.9915 - val_loss: 0.0546 - val_accuracy: 0.9854\n",
            "Epoch 744/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0352 - accuracy: 0.9915 - val_loss: 0.0528 - val_accuracy: 0.9846\n",
            "Epoch 745/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0347 - accuracy: 0.9913 - val_loss: 0.0532 - val_accuracy: 0.9854\n",
            "Epoch 746/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0348 - accuracy: 0.9913 - val_loss: 0.0532 - val_accuracy: 0.9838\n",
            "Epoch 747/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0350 - accuracy: 0.9905 - val_loss: 0.0530 - val_accuracy: 0.9838\n",
            "Epoch 748/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0351 - accuracy: 0.9913 - val_loss: 0.0526 - val_accuracy: 0.9846\n",
            "Epoch 749/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0355 - accuracy: 0.9915 - val_loss: 0.0542 - val_accuracy: 0.9838\n",
            "Epoch 750/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0351 - accuracy: 0.9913 - val_loss: 0.0528 - val_accuracy: 0.9854\n",
            "Epoch 751/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0356 - accuracy: 0.9908 - val_loss: 0.0575 - val_accuracy: 0.9854\n",
            "Epoch 752/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0367 - accuracy: 0.9913 - val_loss: 0.0556 - val_accuracy: 0.9862\n",
            "Epoch 753/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0421 - accuracy: 0.9890 - val_loss: 0.0549 - val_accuracy: 0.9831\n",
            "Epoch 754/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0370 - accuracy: 0.9902 - val_loss: 0.0575 - val_accuracy: 0.9831\n",
            "Epoch 755/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0387 - accuracy: 0.9892 - val_loss: 0.0555 - val_accuracy: 0.9854\n",
            "Epoch 756/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0379 - accuracy: 0.9900 - val_loss: 0.0575 - val_accuracy: 0.9862\n",
            "Epoch 757/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0391 - accuracy: 0.9897 - val_loss: 0.0565 - val_accuracy: 0.9862\n",
            "Epoch 758/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0368 - accuracy: 0.9905 - val_loss: 0.0539 - val_accuracy: 0.9854\n",
            "Epoch 759/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0350 - accuracy: 0.9915 - val_loss: 0.0551 - val_accuracy: 0.9846\n",
            "Epoch 760/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0381 - accuracy: 0.9900 - val_loss: 0.0537 - val_accuracy: 0.9846\n",
            "Epoch 761/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0366 - accuracy: 0.9905 - val_loss: 0.0585 - val_accuracy: 0.9862\n",
            "Epoch 762/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0373 - accuracy: 0.9905 - val_loss: 0.0541 - val_accuracy: 0.9831\n",
            "Epoch 763/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0379 - accuracy: 0.9897 - val_loss: 0.0551 - val_accuracy: 0.9838\n",
            "Epoch 764/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0358 - accuracy: 0.9910 - val_loss: 0.0537 - val_accuracy: 0.9838\n",
            "Epoch 765/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0350 - accuracy: 0.9908 - val_loss: 0.0559 - val_accuracy: 0.9854\n",
            "Epoch 766/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0357 - accuracy: 0.9895 - val_loss: 0.0534 - val_accuracy: 0.9838\n",
            "Epoch 767/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0354 - accuracy: 0.9902 - val_loss: 0.0536 - val_accuracy: 0.9838\n",
            "Epoch 768/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0350 - accuracy: 0.9913 - val_loss: 0.0551 - val_accuracy: 0.9838\n",
            "Epoch 769/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0376 - accuracy: 0.9905 - val_loss: 0.0542 - val_accuracy: 0.9823\n",
            "Epoch 770/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0348 - accuracy: 0.9905 - val_loss: 0.0574 - val_accuracy: 0.9862\n",
            "Epoch 771/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0348 - accuracy: 0.9915 - val_loss: 0.0533 - val_accuracy: 0.9846\n",
            "Epoch 772/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0339 - accuracy: 0.9910 - val_loss: 0.0534 - val_accuracy: 0.9838\n",
            "Epoch 773/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0339 - accuracy: 0.9910 - val_loss: 0.0536 - val_accuracy: 0.9846\n",
            "Epoch 774/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0349 - accuracy: 0.9913 - val_loss: 0.0541 - val_accuracy: 0.9831\n",
            "Epoch 775/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0347 - accuracy: 0.9915 - val_loss: 0.0548 - val_accuracy: 0.9854\n",
            "Epoch 776/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0342 - accuracy: 0.9915 - val_loss: 0.0533 - val_accuracy: 0.9846\n",
            "Epoch 777/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0346 - accuracy: 0.9913 - val_loss: 0.0533 - val_accuracy: 0.9846\n",
            "Epoch 778/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0348 - accuracy: 0.9910 - val_loss: 0.0527 - val_accuracy: 0.9854\n",
            "Epoch 779/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0344 - accuracy: 0.9910 - val_loss: 0.0540 - val_accuracy: 0.9838\n",
            "Epoch 780/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0342 - accuracy: 0.9923 - val_loss: 0.0550 - val_accuracy: 0.9854\n",
            "Epoch 781/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0339 - accuracy: 0.9920 - val_loss: 0.0538 - val_accuracy: 0.9854\n",
            "Epoch 782/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0340 - accuracy: 0.9918 - val_loss: 0.0533 - val_accuracy: 0.9838\n",
            "Epoch 783/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0344 - accuracy: 0.9910 - val_loss: 0.0534 - val_accuracy: 0.9838\n",
            "Epoch 784/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0337 - accuracy: 0.9910 - val_loss: 0.0537 - val_accuracy: 0.9838\n",
            "Epoch 785/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0345 - accuracy: 0.9908 - val_loss: 0.0539 - val_accuracy: 0.9838\n",
            "Epoch 786/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0343 - accuracy: 0.9913 - val_loss: 0.0534 - val_accuracy: 0.9831\n",
            "Epoch 787/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0352 - accuracy: 0.9905 - val_loss: 0.0531 - val_accuracy: 0.9831\n",
            "Epoch 788/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0375 - accuracy: 0.9887 - val_loss: 0.0534 - val_accuracy: 0.9838\n",
            "Epoch 789/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0341 - accuracy: 0.9913 - val_loss: 0.0538 - val_accuracy: 0.9846\n",
            "Epoch 790/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0344 - accuracy: 0.9913 - val_loss: 0.0537 - val_accuracy: 0.9831\n",
            "Epoch 791/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0348 - accuracy: 0.9895 - val_loss: 0.0628 - val_accuracy: 0.9846\n",
            "Epoch 792/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0379 - accuracy: 0.9913 - val_loss: 0.0540 - val_accuracy: 0.9838\n",
            "Epoch 793/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0410 - accuracy: 0.9895 - val_loss: 0.0569 - val_accuracy: 0.9831\n",
            "Epoch 794/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0349 - accuracy: 0.9910 - val_loss: 0.0535 - val_accuracy: 0.9854\n",
            "Epoch 795/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0336 - accuracy: 0.9918 - val_loss: 0.0554 - val_accuracy: 0.9869\n",
            "Epoch 796/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0346 - accuracy: 0.9908 - val_loss: 0.0537 - val_accuracy: 0.9854\n",
            "Epoch 797/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0357 - accuracy: 0.9926 - val_loss: 0.0530 - val_accuracy: 0.9854\n",
            "Epoch 798/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0359 - accuracy: 0.9905 - val_loss: 0.0574 - val_accuracy: 0.9838\n",
            "Epoch 799/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0361 - accuracy: 0.9910 - val_loss: 0.0538 - val_accuracy: 0.9838\n",
            "Epoch 800/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0339 - accuracy: 0.9910 - val_loss: 0.0531 - val_accuracy: 0.9838\n",
            "Epoch 801/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0332 - accuracy: 0.9913 - val_loss: 0.0541 - val_accuracy: 0.9846\n",
            "Epoch 802/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0338 - accuracy: 0.9910 - val_loss: 0.0536 - val_accuracy: 0.9831\n",
            "Epoch 803/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0359 - accuracy: 0.9905 - val_loss: 0.0545 - val_accuracy: 0.9838\n",
            "Epoch 804/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0345 - accuracy: 0.9908 - val_loss: 0.0532 - val_accuracy: 0.9854\n",
            "Epoch 805/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0338 - accuracy: 0.9915 - val_loss: 0.0547 - val_accuracy: 0.9823\n",
            "Epoch 806/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0350 - accuracy: 0.9913 - val_loss: 0.0569 - val_accuracy: 0.9869\n",
            "Epoch 807/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0375 - accuracy: 0.9900 - val_loss: 0.0644 - val_accuracy: 0.9831\n",
            "Epoch 808/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0368 - accuracy: 0.9902 - val_loss: 0.0548 - val_accuracy: 0.9838\n",
            "Epoch 809/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0360 - accuracy: 0.9908 - val_loss: 0.0557 - val_accuracy: 0.9823\n",
            "Epoch 810/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0349 - accuracy: 0.9908 - val_loss: 0.0535 - val_accuracy: 0.9838\n",
            "Epoch 811/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0339 - accuracy: 0.9910 - val_loss: 0.0540 - val_accuracy: 0.9831\n",
            "Epoch 812/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0341 - accuracy: 0.9915 - val_loss: 0.0534 - val_accuracy: 0.9854\n",
            "Epoch 813/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0332 - accuracy: 0.9908 - val_loss: 0.0535 - val_accuracy: 0.9831\n",
            "Epoch 814/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0333 - accuracy: 0.9908 - val_loss: 0.0543 - val_accuracy: 0.9846\n",
            "Epoch 815/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0335 - accuracy: 0.9913 - val_loss: 0.0538 - val_accuracy: 0.9831\n",
            "Epoch 816/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0332 - accuracy: 0.9913 - val_loss: 0.0537 - val_accuracy: 0.9831\n",
            "Epoch 817/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0338 - accuracy: 0.9910 - val_loss: 0.0534 - val_accuracy: 0.9854\n",
            "Epoch 818/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0341 - accuracy: 0.9913 - val_loss: 0.0538 - val_accuracy: 0.9846\n",
            "Epoch 819/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0348 - accuracy: 0.9905 - val_loss: 0.0546 - val_accuracy: 0.9846\n",
            "Epoch 820/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0338 - accuracy: 0.9910 - val_loss: 0.0536 - val_accuracy: 0.9838\n",
            "Epoch 821/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0329 - accuracy: 0.9913 - val_loss: 0.0536 - val_accuracy: 0.9846\n",
            "Epoch 822/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0333 - accuracy: 0.9915 - val_loss: 0.0536 - val_accuracy: 0.9831\n",
            "Epoch 823/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0327 - accuracy: 0.9908 - val_loss: 0.0537 - val_accuracy: 0.9831\n",
            "Epoch 824/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0340 - accuracy: 0.9920 - val_loss: 0.0576 - val_accuracy: 0.9862\n",
            "Epoch 825/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0355 - accuracy: 0.9897 - val_loss: 0.0540 - val_accuracy: 0.9831\n",
            "Epoch 826/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0379 - accuracy: 0.9892 - val_loss: 0.0560 - val_accuracy: 0.9831\n",
            "Epoch 827/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0367 - accuracy: 0.9908 - val_loss: 0.0561 - val_accuracy: 0.9831\n",
            "Epoch 828/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0360 - accuracy: 0.9913 - val_loss: 0.0533 - val_accuracy: 0.9846\n",
            "Epoch 829/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0347 - accuracy: 0.9905 - val_loss: 0.0534 - val_accuracy: 0.9831\n",
            "Epoch 830/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0327 - accuracy: 0.9918 - val_loss: 0.0540 - val_accuracy: 0.9831\n",
            "Epoch 831/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0337 - accuracy: 0.9920 - val_loss: 0.0537 - val_accuracy: 0.9831\n",
            "Epoch 832/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0336 - accuracy: 0.9913 - val_loss: 0.0533 - val_accuracy: 0.9831\n",
            "Epoch 833/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0328 - accuracy: 0.9915 - val_loss: 0.0546 - val_accuracy: 0.9854\n",
            "Epoch 834/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0340 - accuracy: 0.9908 - val_loss: 0.0555 - val_accuracy: 0.9862\n",
            "Epoch 835/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0356 - accuracy: 0.9902 - val_loss: 0.0538 - val_accuracy: 0.9831\n",
            "Epoch 836/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0350 - accuracy: 0.9902 - val_loss: 0.0537 - val_accuracy: 0.9838\n",
            "Epoch 837/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0339 - accuracy: 0.9908 - val_loss: 0.0545 - val_accuracy: 0.9846\n",
            "Epoch 838/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0348 - accuracy: 0.9913 - val_loss: 0.0556 - val_accuracy: 0.9831\n",
            "Epoch 839/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0358 - accuracy: 0.9900 - val_loss: 0.0539 - val_accuracy: 0.9838\n",
            "Epoch 840/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0373 - accuracy: 0.9890 - val_loss: 0.0660 - val_accuracy: 0.9808\n",
            "Epoch 841/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0371 - accuracy: 0.9905 - val_loss: 0.0569 - val_accuracy: 0.9862\n",
            "Epoch 842/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0343 - accuracy: 0.9918 - val_loss: 0.0552 - val_accuracy: 0.9846\n",
            "Epoch 843/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0344 - accuracy: 0.9915 - val_loss: 0.0535 - val_accuracy: 0.9846\n",
            "Epoch 844/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0340 - accuracy: 0.9908 - val_loss: 0.0540 - val_accuracy: 0.9854\n",
            "Epoch 845/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0335 - accuracy: 0.9913 - val_loss: 0.0541 - val_accuracy: 0.9831\n",
            "Epoch 846/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0350 - accuracy: 0.9913 - val_loss: 0.0561 - val_accuracy: 0.9831\n",
            "Epoch 847/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0354 - accuracy: 0.9910 - val_loss: 0.0535 - val_accuracy: 0.9854\n",
            "Epoch 848/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0340 - accuracy: 0.9908 - val_loss: 0.0540 - val_accuracy: 0.9838\n",
            "Epoch 849/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0327 - accuracy: 0.9915 - val_loss: 0.0545 - val_accuracy: 0.9854\n",
            "Epoch 850/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0330 - accuracy: 0.9913 - val_loss: 0.0536 - val_accuracy: 0.9838\n",
            "Epoch 851/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0329 - accuracy: 0.9910 - val_loss: 0.0535 - val_accuracy: 0.9854\n",
            "Epoch 852/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0341 - accuracy: 0.9913 - val_loss: 0.0533 - val_accuracy: 0.9846\n",
            "Epoch 853/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0332 - accuracy: 0.9913 - val_loss: 0.0537 - val_accuracy: 0.9846\n",
            "Epoch 854/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0325 - accuracy: 0.9913 - val_loss: 0.0540 - val_accuracy: 0.9838\n",
            "Epoch 855/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0322 - accuracy: 0.9915 - val_loss: 0.0534 - val_accuracy: 0.9854\n",
            "Epoch 856/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0324 - accuracy: 0.9918 - val_loss: 0.0540 - val_accuracy: 0.9838\n",
            "Epoch 857/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0325 - accuracy: 0.9913 - val_loss: 0.0538 - val_accuracy: 0.9838\n",
            "Epoch 858/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0324 - accuracy: 0.9913 - val_loss: 0.0537 - val_accuracy: 0.9846\n",
            "Epoch 859/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0325 - accuracy: 0.9918 - val_loss: 0.0537 - val_accuracy: 0.9846\n",
            "Epoch 860/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0326 - accuracy: 0.9910 - val_loss: 0.0543 - val_accuracy: 0.9831\n",
            "Epoch 861/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0336 - accuracy: 0.9905 - val_loss: 0.0536 - val_accuracy: 0.9854\n",
            "Epoch 862/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0335 - accuracy: 0.9913 - val_loss: 0.0551 - val_accuracy: 0.9831\n",
            "Epoch 863/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0335 - accuracy: 0.9908 - val_loss: 0.0543 - val_accuracy: 0.9838\n",
            "Epoch 864/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0344 - accuracy: 0.9910 - val_loss: 0.0555 - val_accuracy: 0.9854\n",
            "Epoch 865/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0343 - accuracy: 0.9908 - val_loss: 0.0580 - val_accuracy: 0.9862\n",
            "Epoch 866/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0355 - accuracy: 0.9908 - val_loss: 0.0554 - val_accuracy: 0.9838\n",
            "Epoch 867/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0364 - accuracy: 0.9905 - val_loss: 0.0548 - val_accuracy: 0.9854\n",
            "Epoch 868/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0353 - accuracy: 0.9902 - val_loss: 0.0548 - val_accuracy: 0.9831\n",
            "Epoch 869/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0335 - accuracy: 0.9908 - val_loss: 0.0541 - val_accuracy: 0.9854\n",
            "Epoch 870/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0334 - accuracy: 0.9908 - val_loss: 0.0540 - val_accuracy: 0.9838\n",
            "Epoch 871/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0322 - accuracy: 0.9913 - val_loss: 0.0546 - val_accuracy: 0.9846\n",
            "Epoch 872/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0327 - accuracy: 0.9913 - val_loss: 0.0544 - val_accuracy: 0.9838\n",
            "Epoch 873/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0334 - accuracy: 0.9918 - val_loss: 0.0552 - val_accuracy: 0.9838\n",
            "Epoch 874/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0367 - accuracy: 0.9890 - val_loss: 0.0556 - val_accuracy: 0.9869\n",
            "Epoch 875/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0377 - accuracy: 0.9895 - val_loss: 0.0620 - val_accuracy: 0.9846\n",
            "Epoch 876/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0350 - accuracy: 0.9900 - val_loss: 0.0564 - val_accuracy: 0.9846\n",
            "Epoch 877/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0329 - accuracy: 0.9913 - val_loss: 0.0554 - val_accuracy: 0.9846\n",
            "Epoch 878/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0322 - accuracy: 0.9918 - val_loss: 0.0543 - val_accuracy: 0.9838\n",
            "Epoch 879/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0323 - accuracy: 0.9926 - val_loss: 0.0540 - val_accuracy: 0.9838\n",
            "Epoch 880/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0332 - accuracy: 0.9915 - val_loss: 0.0539 - val_accuracy: 0.9846\n",
            "Epoch 881/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0333 - accuracy: 0.9913 - val_loss: 0.0536 - val_accuracy: 0.9846\n",
            "Epoch 882/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0325 - accuracy: 0.9908 - val_loss: 0.0535 - val_accuracy: 0.9854\n",
            "Epoch 883/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0317 - accuracy: 0.9926 - val_loss: 0.0536 - val_accuracy: 0.9846\n",
            "Epoch 884/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0323 - accuracy: 0.9918 - val_loss: 0.0532 - val_accuracy: 0.9854\n",
            "Epoch 885/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0319 - accuracy: 0.9918 - val_loss: 0.0541 - val_accuracy: 0.9846\n",
            "Epoch 886/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0320 - accuracy: 0.9926 - val_loss: 0.0545 - val_accuracy: 0.9854\n",
            "Epoch 887/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0327 - accuracy: 0.9920 - val_loss: 0.0548 - val_accuracy: 0.9846\n",
            "Epoch 888/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0326 - accuracy: 0.9920 - val_loss: 0.0548 - val_accuracy: 0.9846\n",
            "Epoch 889/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0318 - accuracy: 0.9918 - val_loss: 0.0546 - val_accuracy: 0.9838\n",
            "Epoch 890/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0317 - accuracy: 0.9923 - val_loss: 0.0545 - val_accuracy: 0.9838\n",
            "Epoch 891/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0318 - accuracy: 0.9918 - val_loss: 0.0551 - val_accuracy: 0.9838\n",
            "Epoch 892/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0330 - accuracy: 0.9913 - val_loss: 0.0561 - val_accuracy: 0.9869\n",
            "Epoch 893/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0329 - accuracy: 0.9918 - val_loss: 0.0547 - val_accuracy: 0.9846\n",
            "Epoch 894/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0329 - accuracy: 0.9928 - val_loss: 0.0537 - val_accuracy: 0.9854\n",
            "Epoch 895/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0318 - accuracy: 0.9920 - val_loss: 0.0543 - val_accuracy: 0.9846\n",
            "Epoch 896/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0315 - accuracy: 0.9920 - val_loss: 0.0550 - val_accuracy: 0.9831\n",
            "Epoch 897/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0331 - accuracy: 0.9918 - val_loss: 0.0551 - val_accuracy: 0.9854\n",
            "Epoch 898/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0327 - accuracy: 0.9915 - val_loss: 0.0543 - val_accuracy: 0.9838\n",
            "Epoch 899/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0322 - accuracy: 0.9923 - val_loss: 0.0551 - val_accuracy: 0.9831\n",
            "Epoch 900/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0342 - accuracy: 0.9913 - val_loss: 0.0536 - val_accuracy: 0.9846\n",
            "Epoch 901/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0320 - accuracy: 0.9913 - val_loss: 0.0548 - val_accuracy: 0.9846\n",
            "Epoch 902/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0317 - accuracy: 0.9926 - val_loss: 0.0575 - val_accuracy: 0.9854\n",
            "Epoch 903/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0319 - accuracy: 0.9923 - val_loss: 0.0539 - val_accuracy: 0.9846\n",
            "Epoch 904/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0326 - accuracy: 0.9913 - val_loss: 0.0551 - val_accuracy: 0.9838\n",
            "Epoch 905/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0345 - accuracy: 0.9902 - val_loss: 0.0546 - val_accuracy: 0.9838\n",
            "Epoch 906/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0331 - accuracy: 0.9923 - val_loss: 0.0544 - val_accuracy: 0.9846\n",
            "Epoch 907/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0352 - accuracy: 0.9900 - val_loss: 0.0571 - val_accuracy: 0.9854\n",
            "Epoch 908/2000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0320 - accuracy: 0.9918 - val_loss: 0.0554 - val_accuracy: 0.9838\n",
            "Epoch 909/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0318 - accuracy: 0.9918 - val_loss: 0.0552 - val_accuracy: 0.9854\n",
            "Epoch 910/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0313 - accuracy: 0.9933 - val_loss: 0.0552 - val_accuracy: 0.9831\n",
            "Epoch 911/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0323 - accuracy: 0.9920 - val_loss: 0.0561 - val_accuracy: 0.9838\n",
            "Epoch 912/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0314 - accuracy: 0.9920 - val_loss: 0.0552 - val_accuracy: 0.9846\n",
            "Epoch 913/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0317 - accuracy: 0.9926 - val_loss: 0.0554 - val_accuracy: 0.9846\n",
            "Epoch 914/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0314 - accuracy: 0.9920 - val_loss: 0.0556 - val_accuracy: 0.9831\n",
            "Epoch 915/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0337 - accuracy: 0.9915 - val_loss: 0.0537 - val_accuracy: 0.9854\n",
            "Epoch 916/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0334 - accuracy: 0.9918 - val_loss: 0.0639 - val_accuracy: 0.9831\n",
            "Epoch 917/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0347 - accuracy: 0.9905 - val_loss: 0.0596 - val_accuracy: 0.9869\n",
            "Epoch 918/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0338 - accuracy: 0.9913 - val_loss: 0.0552 - val_accuracy: 0.9838\n",
            "Epoch 919/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0313 - accuracy: 0.9931 - val_loss: 0.0550 - val_accuracy: 0.9846\n",
            "Epoch 920/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0318 - accuracy: 0.9931 - val_loss: 0.0556 - val_accuracy: 0.9854\n",
            "Epoch 921/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0312 - accuracy: 0.9931 - val_loss: 0.0550 - val_accuracy: 0.9838\n",
            "Epoch 922/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0318 - accuracy: 0.9915 - val_loss: 0.0543 - val_accuracy: 0.9846\n",
            "Epoch 923/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0318 - accuracy: 0.9918 - val_loss: 0.0544 - val_accuracy: 0.9846\n",
            "Epoch 924/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0353 - accuracy: 0.9915 - val_loss: 0.0587 - val_accuracy: 0.9831\n",
            "Epoch 925/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0348 - accuracy: 0.9910 - val_loss: 0.0565 - val_accuracy: 0.9846\n",
            "Epoch 926/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0326 - accuracy: 0.9923 - val_loss: 0.0582 - val_accuracy: 0.9854\n",
            "Epoch 927/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0320 - accuracy: 0.9910 - val_loss: 0.0556 - val_accuracy: 0.9846\n",
            "Epoch 928/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0309 - accuracy: 0.9918 - val_loss: 0.0557 - val_accuracy: 0.9831\n",
            "Epoch 929/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0324 - accuracy: 0.9923 - val_loss: 0.0556 - val_accuracy: 0.9846\n",
            "Epoch 930/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0324 - accuracy: 0.9910 - val_loss: 0.0602 - val_accuracy: 0.9854\n",
            "Epoch 931/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0327 - accuracy: 0.9923 - val_loss: 0.0573 - val_accuracy: 0.9862\n",
            "Epoch 932/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0345 - accuracy: 0.9910 - val_loss: 0.0586 - val_accuracy: 0.9854\n",
            "Epoch 933/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0337 - accuracy: 0.9910 - val_loss: 0.0545 - val_accuracy: 0.9846\n",
            "Epoch 934/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0342 - accuracy: 0.9913 - val_loss: 0.0570 - val_accuracy: 0.9831\n",
            "Epoch 935/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0300 - accuracy: 0.9928 - val_loss: 0.0588 - val_accuracy: 0.9862\n",
            "Epoch 936/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0342 - accuracy: 0.9905 - val_loss: 0.0576 - val_accuracy: 0.9846\n",
            "Epoch 937/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0323 - accuracy: 0.9926 - val_loss: 0.0547 - val_accuracy: 0.9854\n",
            "Epoch 938/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0312 - accuracy: 0.9926 - val_loss: 0.0595 - val_accuracy: 0.9846\n",
            "Epoch 939/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0338 - accuracy: 0.9915 - val_loss: 0.0555 - val_accuracy: 0.9846\n",
            "Epoch 940/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0319 - accuracy: 0.9920 - val_loss: 0.0602 - val_accuracy: 0.9854\n",
            "Epoch 941/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0320 - accuracy: 0.9908 - val_loss: 0.0551 - val_accuracy: 0.9846\n",
            "Epoch 942/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0334 - accuracy: 0.9913 - val_loss: 0.0559 - val_accuracy: 0.9846\n",
            "Epoch 943/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0334 - accuracy: 0.9902 - val_loss: 0.0552 - val_accuracy: 0.9846\n",
            "Epoch 944/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0341 - accuracy: 0.9902 - val_loss: 0.0570 - val_accuracy: 0.9831\n",
            "Epoch 945/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0345 - accuracy: 0.9915 - val_loss: 0.0551 - val_accuracy: 0.9831\n",
            "Epoch 946/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0336 - accuracy: 0.9926 - val_loss: 0.0573 - val_accuracy: 0.9823\n",
            "Epoch 947/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0359 - accuracy: 0.9905 - val_loss: 0.0564 - val_accuracy: 0.9846\n",
            "Epoch 948/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0377 - accuracy: 0.9900 - val_loss: 0.0599 - val_accuracy: 0.9846\n",
            "Epoch 949/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0324 - accuracy: 0.9913 - val_loss: 0.0586 - val_accuracy: 0.9862\n",
            "Epoch 950/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0326 - accuracy: 0.9920 - val_loss: 0.0564 - val_accuracy: 0.9846\n",
            "Epoch 951/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0311 - accuracy: 0.9928 - val_loss: 0.0550 - val_accuracy: 0.9846\n",
            "Epoch 952/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0313 - accuracy: 0.9923 - val_loss: 0.0549 - val_accuracy: 0.9846\n",
            "Epoch 953/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0318 - accuracy: 0.9918 - val_loss: 0.0582 - val_accuracy: 0.9862\n",
            "Epoch 954/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0320 - accuracy: 0.9913 - val_loss: 0.0586 - val_accuracy: 0.9869\n",
            "Epoch 955/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0325 - accuracy: 0.9910 - val_loss: 0.0593 - val_accuracy: 0.9862\n",
            "Epoch 956/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0339 - accuracy: 0.9913 - val_loss: 0.0554 - val_accuracy: 0.9838\n",
            "Epoch 957/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0319 - accuracy: 0.9926 - val_loss: 0.0566 - val_accuracy: 0.9831\n",
            "Epoch 958/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0331 - accuracy: 0.9902 - val_loss: 0.0556 - val_accuracy: 0.9838\n",
            "Epoch 959/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0329 - accuracy: 0.9918 - val_loss: 0.0580 - val_accuracy: 0.9862\n",
            "Epoch 960/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0311 - accuracy: 0.9923 - val_loss: 0.0558 - val_accuracy: 0.9838\n",
            "Epoch 961/2000\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0321 - accuracy: 0.9920 - val_loss: 0.0561 - val_accuracy: 0.9831\n",
            "Epoch 962/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0306 - accuracy: 0.9938 - val_loss: 0.0560 - val_accuracy: 0.9854\n",
            "Epoch 963/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0317 - accuracy: 0.9926 - val_loss: 0.0566 - val_accuracy: 0.9854\n",
            "Epoch 964/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0315 - accuracy: 0.9920 - val_loss: 0.0554 - val_accuracy: 0.9854\n",
            "Epoch 965/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0312 - accuracy: 0.9931 - val_loss: 0.0601 - val_accuracy: 0.9846\n",
            "Epoch 966/2000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0312 - accuracy: 0.9910 - val_loss: 0.0557 - val_accuracy: 0.9831\n",
            "Epoch 967/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0330 - accuracy: 0.9918 - val_loss: 0.0558 - val_accuracy: 0.9846\n",
            "Epoch 968/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0313 - accuracy: 0.9923 - val_loss: 0.0558 - val_accuracy: 0.9846\n",
            "Epoch 969/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0312 - accuracy: 0.9923 - val_loss: 0.0557 - val_accuracy: 0.9831\n",
            "Epoch 970/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0385 - accuracy: 0.9897 - val_loss: 0.0600 - val_accuracy: 0.9823\n",
            "Epoch 971/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0426 - accuracy: 0.9861 - val_loss: 0.0579 - val_accuracy: 0.9838\n",
            "Epoch 972/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0442 - accuracy: 0.9861 - val_loss: 0.0816 - val_accuracy: 0.9738\n",
            "Epoch 973/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0442 - accuracy: 0.9879 - val_loss: 0.0630 - val_accuracy: 0.9846\n",
            "Epoch 974/2000\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.0357 - accuracy: 0.9910 - val_loss: 0.0564 - val_accuracy: 0.9846\n",
            "Epoch 975/2000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0305 - accuracy: 0.9928 - val_loss: 0.0564 - val_accuracy: 0.9846\n",
            "Epoch 976/2000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0317 - accuracy: 0.9918 - val_loss: 0.0555 - val_accuracy: 0.9846\n",
            "Epoch 977/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0317 - accuracy: 0.9915 - val_loss: 0.0564 - val_accuracy: 0.9846\n",
            "Epoch 978/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0310 - accuracy: 0.9920 - val_loss: 0.0568 - val_accuracy: 0.9846\n",
            "Epoch 979/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0302 - accuracy: 0.9928 - val_loss: 0.0562 - val_accuracy: 0.9831\n",
            "Epoch 980/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0326 - accuracy: 0.9913 - val_loss: 0.0575 - val_accuracy: 0.9862\n",
            "Epoch 981/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0311 - accuracy: 0.9923 - val_loss: 0.0567 - val_accuracy: 0.9846\n",
            "Epoch 982/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0322 - accuracy: 0.9926 - val_loss: 0.0566 - val_accuracy: 0.9846\n",
            "Epoch 983/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0305 - accuracy: 0.9923 - val_loss: 0.0571 - val_accuracy: 0.9854\n",
            "Epoch 984/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0300 - accuracy: 0.9920 - val_loss: 0.0557 - val_accuracy: 0.9846\n",
            "Epoch 985/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0314 - accuracy: 0.9918 - val_loss: 0.0556 - val_accuracy: 0.9846\n",
            "Epoch 986/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0320 - accuracy: 0.9913 - val_loss: 0.0571 - val_accuracy: 0.9846\n",
            "Epoch 987/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0330 - accuracy: 0.9913 - val_loss: 0.0599 - val_accuracy: 0.9846\n",
            "Epoch 988/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0321 - accuracy: 0.9923 - val_loss: 0.0580 - val_accuracy: 0.9854\n",
            "Epoch 989/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0322 - accuracy: 0.9923 - val_loss: 0.0564 - val_accuracy: 0.9838\n",
            "Epoch 990/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0308 - accuracy: 0.9920 - val_loss: 0.0571 - val_accuracy: 0.9838\n",
            "Epoch 991/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0303 - accuracy: 0.9923 - val_loss: 0.0563 - val_accuracy: 0.9846\n",
            "Epoch 992/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0315 - accuracy: 0.9923 - val_loss: 0.0563 - val_accuracy: 0.9846\n",
            "Epoch 993/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0328 - accuracy: 0.9913 - val_loss: 0.0592 - val_accuracy: 0.9869\n",
            "Epoch 994/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0301 - accuracy: 0.9926 - val_loss: 0.0564 - val_accuracy: 0.9846\n",
            "Epoch 995/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0309 - accuracy: 0.9920 - val_loss: 0.0579 - val_accuracy: 0.9854\n",
            "Epoch 996/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0310 - accuracy: 0.9926 - val_loss: 0.0570 - val_accuracy: 0.9831\n",
            "Epoch 997/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0311 - accuracy: 0.9918 - val_loss: 0.0563 - val_accuracy: 0.9846\n",
            "Epoch 998/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0303 - accuracy: 0.9931 - val_loss: 0.0575 - val_accuracy: 0.9854\n",
            "Epoch 999/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0319 - accuracy: 0.9918 - val_loss: 0.0637 - val_accuracy: 0.9846\n",
            "Epoch 1000/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0351 - accuracy: 0.9908 - val_loss: 0.0628 - val_accuracy: 0.9838\n",
            "Epoch 1001/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0332 - accuracy: 0.9920 - val_loss: 0.0570 - val_accuracy: 0.9831\n",
            "Epoch 1002/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0338 - accuracy: 0.9915 - val_loss: 0.0600 - val_accuracy: 0.9823\n",
            "Epoch 1003/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0328 - accuracy: 0.9915 - val_loss: 0.0563 - val_accuracy: 0.9846\n",
            "Epoch 1004/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0316 - accuracy: 0.9928 - val_loss: 0.0562 - val_accuracy: 0.9831\n",
            "Epoch 1005/2000\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0350 - accuracy: 0.9913 - val_loss: 0.0566 - val_accuracy: 0.9862\n",
            "Epoch 1006/2000\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0335 - accuracy: 0.9905 - val_loss: 0.0618 - val_accuracy: 0.9846\n",
            "Epoch 1007/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0346 - accuracy: 0.9908 - val_loss: 0.0658 - val_accuracy: 0.9831\n",
            "Epoch 1008/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0343 - accuracy: 0.9915 - val_loss: 0.0574 - val_accuracy: 0.9846\n",
            "Epoch 1009/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0301 - accuracy: 0.9923 - val_loss: 0.0573 - val_accuracy: 0.9838\n",
            "Epoch 1010/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0320 - accuracy: 0.9913 - val_loss: 0.0584 - val_accuracy: 0.9862\n",
            "Epoch 1011/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0314 - accuracy: 0.9926 - val_loss: 0.0586 - val_accuracy: 0.9854\n",
            "Epoch 1012/2000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0318 - accuracy: 0.9923 - val_loss: 0.0587 - val_accuracy: 0.9823\n",
            "Epoch 1013/2000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0336 - accuracy: 0.9913 - val_loss: 0.0573 - val_accuracy: 0.9823\n",
            "Epoch 1014/2000\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0328 - accuracy: 0.9915 - val_loss: 0.0565 - val_accuracy: 0.9846\n",
            "Epoch 1015/2000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0330 - accuracy: 0.9913 - val_loss: 0.0558 - val_accuracy: 0.9838\n",
            "Epoch 1016/2000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0323 - accuracy: 0.9913 - val_loss: 0.0569 - val_accuracy: 0.9846\n",
            "Epoch 1017/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0313 - accuracy: 0.9918 - val_loss: 0.0621 - val_accuracy: 0.9846\n",
            "Epoch 1018/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0312 - accuracy: 0.9918 - val_loss: 0.0566 - val_accuracy: 0.9846\n",
            "Epoch 1019/2000\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 0.0294 - accuracy: 0.9928 - val_loss: 0.0567 - val_accuracy: 0.9846\n",
            "Epoch 1020/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0295 - accuracy: 0.9933 - val_loss: 0.0571 - val_accuracy: 0.9831\n",
            "Epoch 1021/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0344 - accuracy: 0.9918 - val_loss: 0.0570 - val_accuracy: 0.9838\n",
            "Epoch 1022/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0323 - accuracy: 0.9910 - val_loss: 0.0586 - val_accuracy: 0.9846\n",
            "Epoch 1023/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0298 - accuracy: 0.9931 - val_loss: 0.0579 - val_accuracy: 0.9846\n",
            "Epoch 1024/2000\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0313 - accuracy: 0.9918 - val_loss: 0.0597 - val_accuracy: 0.9854\n",
            "Epoch 1025/2000\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 0.0334 - accuracy: 0.9923 - val_loss: 0.0609 - val_accuracy: 0.9846\n",
            "Epoch 1026/2000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0312 - accuracy: 0.9915 - val_loss: 0.0561 - val_accuracy: 0.9846\n",
            "Epoch 1027/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0295 - accuracy: 0.9923 - val_loss: 0.0572 - val_accuracy: 0.9846\n",
            "Epoch 1028/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0301 - accuracy: 0.9923 - val_loss: 0.0581 - val_accuracy: 0.9838\n",
            "Epoch 1029/2000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0316 - accuracy: 0.9913 - val_loss: 0.0569 - val_accuracy: 0.9846\n",
            "Epoch 1030/2000\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.0301 - accuracy: 0.9920 - val_loss: 0.0570 - val_accuracy: 0.9846\n",
            "Epoch 1031/2000\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0309 - accuracy: 0.9923 - val_loss: 0.0567 - val_accuracy: 0.9846\n",
            "Epoch 1032/2000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0305 - accuracy: 0.9920 - val_loss: 0.0570 - val_accuracy: 0.9823\n",
            "Epoch 1033/2000\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.0318 - accuracy: 0.9913 - val_loss: 0.0572 - val_accuracy: 0.9846\n",
            "Epoch 1034/2000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0322 - accuracy: 0.9918 - val_loss: 0.0655 - val_accuracy: 0.9838\n",
            "Epoch 1035/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0320 - accuracy: 0.9915 - val_loss: 0.0599 - val_accuracy: 0.9838\n",
            "Epoch 1036/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0301 - accuracy: 0.9928 - val_loss: 0.0581 - val_accuracy: 0.9823\n",
            "Epoch 1037/2000\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0303 - accuracy: 0.9920 - val_loss: 0.0573 - val_accuracy: 0.9846\n",
            "Epoch 1038/2000\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0325 - accuracy: 0.9915 - val_loss: 0.0603 - val_accuracy: 0.9854\n",
            "Epoch 1039/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0309 - accuracy: 0.9920 - val_loss: 0.0658 - val_accuracy: 0.9838\n",
            "Epoch 1040/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0328 - accuracy: 0.9923 - val_loss: 0.0575 - val_accuracy: 0.9854\n",
            "Epoch 1041/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0295 - accuracy: 0.9933 - val_loss: 0.0563 - val_accuracy: 0.9846\n",
            "Epoch 1042/2000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0295 - accuracy: 0.9928 - val_loss: 0.0562 - val_accuracy: 0.9862\n",
            "Epoch 1043/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0307 - accuracy: 0.9926 - val_loss: 0.0574 - val_accuracy: 0.9823\n",
            "Epoch 1044/2000\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0314 - accuracy: 0.9918 - val_loss: 0.0570 - val_accuracy: 0.9846\n",
            "Epoch 1045/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0315 - accuracy: 0.9910 - val_loss: 0.0579 - val_accuracy: 0.9854\n",
            "Epoch 1046/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0308 - accuracy: 0.9915 - val_loss: 0.0574 - val_accuracy: 0.9846\n",
            "Epoch 1047/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0296 - accuracy: 0.9931 - val_loss: 0.0609 - val_accuracy: 0.9846\n",
            "Epoch 1048/2000\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0313 - accuracy: 0.9915 - val_loss: 0.0590 - val_accuracy: 0.9862\n",
            "Epoch 1049/2000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0297 - accuracy: 0.9923 - val_loss: 0.0570 - val_accuracy: 0.9838\n",
            "Epoch 1050/2000\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0300 - accuracy: 0.9926 - val_loss: 0.0568 - val_accuracy: 0.9846\n",
            "Epoch 1051/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0293 - accuracy: 0.9931 - val_loss: 0.0579 - val_accuracy: 0.9854\n",
            "Epoch 1052/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0324 - accuracy: 0.9915 - val_loss: 0.0687 - val_accuracy: 0.9823\n",
            "Epoch 1053/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0365 - accuracy: 0.9897 - val_loss: 0.0649 - val_accuracy: 0.9838\n",
            "Epoch 1054/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0325 - accuracy: 0.9913 - val_loss: 0.0603 - val_accuracy: 0.9869\n",
            "Epoch 1055/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0306 - accuracy: 0.9926 - val_loss: 0.0582 - val_accuracy: 0.9838\n",
            "Epoch 1056/2000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0314 - accuracy: 0.9908 - val_loss: 0.0577 - val_accuracy: 0.9823\n",
            "Epoch 1057/2000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0291 - accuracy: 0.9931 - val_loss: 0.0568 - val_accuracy: 0.9846\n",
            "Epoch 1058/2000\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.0297 - accuracy: 0.9928 - val_loss: 0.0575 - val_accuracy: 0.9854\n",
            "Epoch 1059/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0291 - accuracy: 0.9926 - val_loss: 0.0577 - val_accuracy: 0.9854\n",
            "Epoch 1060/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0296 - accuracy: 0.9931 - val_loss: 0.0570 - val_accuracy: 0.9854\n",
            "Epoch 1061/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0291 - accuracy: 0.9926 - val_loss: 0.0571 - val_accuracy: 0.9846\n",
            "Epoch 1062/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0293 - accuracy: 0.9928 - val_loss: 0.0573 - val_accuracy: 0.9831\n",
            "Epoch 1063/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0292 - accuracy: 0.9926 - val_loss: 0.0590 - val_accuracy: 0.9846\n",
            "Epoch 1064/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0303 - accuracy: 0.9933 - val_loss: 0.0588 - val_accuracy: 0.9854\n",
            "Epoch 1065/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0306 - accuracy: 0.9918 - val_loss: 0.0603 - val_accuracy: 0.9838\n",
            "Epoch 1066/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0296 - accuracy: 0.9915 - val_loss: 0.0571 - val_accuracy: 0.9846\n",
            "Epoch 1067/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0310 - accuracy: 0.9926 - val_loss: 0.0592 - val_accuracy: 0.9823\n",
            "Epoch 1068/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0318 - accuracy: 0.9915 - val_loss: 0.0595 - val_accuracy: 0.9831\n",
            "Epoch 1069/2000\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0364 - accuracy: 0.9908 - val_loss: 0.0600 - val_accuracy: 0.9854\n",
            "Epoch 1070/2000\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.0300 - accuracy: 0.9926 - val_loss: 0.0594 - val_accuracy: 0.9854\n",
            "Epoch 1071/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0292 - accuracy: 0.9928 - val_loss: 0.0578 - val_accuracy: 0.9846\n",
            "Epoch 1072/2000\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0288 - accuracy: 0.9928 - val_loss: 0.0576 - val_accuracy: 0.9854\n",
            "Epoch 1073/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0288 - accuracy: 0.9933 - val_loss: 0.0572 - val_accuracy: 0.9854\n",
            "Epoch 1074/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0288 - accuracy: 0.9938 - val_loss: 0.0594 - val_accuracy: 0.9846\n",
            "Epoch 1075/2000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0304 - accuracy: 0.9920 - val_loss: 0.0577 - val_accuracy: 0.9846\n",
            "Epoch 1076/2000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0293 - accuracy: 0.9941 - val_loss: 0.0584 - val_accuracy: 0.9831\n",
            "Epoch 1077/2000\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0288 - accuracy: 0.9923 - val_loss: 0.0604 - val_accuracy: 0.9846\n",
            "Epoch 1078/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0295 - accuracy: 0.9926 - val_loss: 0.0596 - val_accuracy: 0.9862\n",
            "Epoch 1079/2000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0300 - accuracy: 0.9920 - val_loss: 0.0595 - val_accuracy: 0.9854\n",
            "Epoch 1080/2000\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0287 - accuracy: 0.9938 - val_loss: 0.0584 - val_accuracy: 0.9854\n",
            "Epoch 1081/2000\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.0289 - accuracy: 0.9933 - val_loss: 0.0575 - val_accuracy: 0.9846\n",
            "Epoch 1082/2000\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.0291 - accuracy: 0.9928 - val_loss: 0.0602 - val_accuracy: 0.9846\n",
            "Epoch 1083/2000\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0290 - accuracy: 0.9936 - val_loss: 0.0582 - val_accuracy: 0.9831\n",
            "Epoch 1084/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0299 - accuracy: 0.9926 - val_loss: 0.0582 - val_accuracy: 0.9815\n",
            "Epoch 1085/2000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0308 - accuracy: 0.9910 - val_loss: 0.0579 - val_accuracy: 0.9854\n",
            "Epoch 1086/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0299 - accuracy: 0.9920 - val_loss: 0.0605 - val_accuracy: 0.9862\n",
            "Epoch 1087/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0314 - accuracy: 0.9915 - val_loss: 0.0635 - val_accuracy: 0.9846\n",
            "Epoch 1088/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0292 - accuracy: 0.9920 - val_loss: 0.0591 - val_accuracy: 0.9838\n",
            "Epoch 1089/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0306 - accuracy: 0.9931 - val_loss: 0.0591 - val_accuracy: 0.9815\n",
            "Epoch 1090/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0312 - accuracy: 0.9926 - val_loss: 0.0646 - val_accuracy: 0.9815\n",
            "Epoch 1091/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0375 - accuracy: 0.9890 - val_loss: 0.0588 - val_accuracy: 0.9838\n",
            "Epoch 1092/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0319 - accuracy: 0.9910 - val_loss: 0.0653 - val_accuracy: 0.9838\n",
            "Epoch 1093/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0317 - accuracy: 0.9918 - val_loss: 0.0610 - val_accuracy: 0.9846\n",
            "Epoch 1094/2000\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0351 - accuracy: 0.9908 - val_loss: 0.0677 - val_accuracy: 0.9808\n",
            "Epoch 1095/2000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0342 - accuracy: 0.9918 - val_loss: 0.0610 - val_accuracy: 0.9815\n",
            "Epoch 1096/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0314 - accuracy: 0.9915 - val_loss: 0.0594 - val_accuracy: 0.9846\n",
            "Epoch 1097/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0291 - accuracy: 0.9923 - val_loss: 0.0607 - val_accuracy: 0.9854\n",
            "Epoch 1098/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0287 - accuracy: 0.9928 - val_loss: 0.0587 - val_accuracy: 0.9838\n",
            "Epoch 1099/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0286 - accuracy: 0.9938 - val_loss: 0.0585 - val_accuracy: 0.9838\n",
            "Epoch 1100/2000\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0289 - accuracy: 0.9933 - val_loss: 0.0580 - val_accuracy: 0.9862\n",
            "Epoch 1101/2000\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0315 - accuracy: 0.9910 - val_loss: 0.0600 - val_accuracy: 0.9846\n",
            "Epoch 1102/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0303 - accuracy: 0.9926 - val_loss: 0.0610 - val_accuracy: 0.9846\n",
            "Epoch 1103/2000\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0297 - accuracy: 0.9920 - val_loss: 0.0591 - val_accuracy: 0.9854\n",
            "Epoch 1104/2000\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0311 - accuracy: 0.9918 - val_loss: 0.0614 - val_accuracy: 0.9823\n",
            "Epoch 1105/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0314 - accuracy: 0.9920 - val_loss: 0.0599 - val_accuracy: 0.9831\n",
            "Epoch 1106/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0303 - accuracy: 0.9920 - val_loss: 0.0606 - val_accuracy: 0.9838\n",
            "Epoch 1107/2000\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0310 - accuracy: 0.9910 - val_loss: 0.0624 - val_accuracy: 0.9831\n",
            "Epoch 1108/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0301 - accuracy: 0.9923 - val_loss: 0.0609 - val_accuracy: 0.9862\n",
            "Epoch 1109/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0294 - accuracy: 0.9923 - val_loss: 0.0587 - val_accuracy: 0.9854\n",
            "Epoch 1110/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0279 - accuracy: 0.9931 - val_loss: 0.0581 - val_accuracy: 0.9854\n",
            "Epoch 1111/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0309 - accuracy: 0.9908 - val_loss: 0.0597 - val_accuracy: 0.9846\n",
            "Epoch 1112/2000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0307 - accuracy: 0.9928 - val_loss: 0.0604 - val_accuracy: 0.9823\n",
            "Epoch 1113/2000\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0316 - accuracy: 0.9918 - val_loss: 0.0591 - val_accuracy: 0.9846\n",
            "Epoch 1114/2000\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0306 - accuracy: 0.9918 - val_loss: 0.0660 - val_accuracy: 0.9838\n",
            "Epoch 1115/2000\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.0314 - accuracy: 0.9908 - val_loss: 0.0628 - val_accuracy: 0.9838\n",
            "Epoch 1116/2000\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0297 - accuracy: 0.9933 - val_loss: 0.0596 - val_accuracy: 0.9846\n",
            "Epoch 1117/2000\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0280 - accuracy: 0.9928 - val_loss: 0.0589 - val_accuracy: 0.9846\n",
            "Epoch 1118/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0280 - accuracy: 0.9926 - val_loss: 0.0595 - val_accuracy: 0.9854\n",
            "Epoch 1119/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0291 - accuracy: 0.9915 - val_loss: 0.0609 - val_accuracy: 0.9846\n",
            "Epoch 1120/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0305 - accuracy: 0.9915 - val_loss: 0.0600 - val_accuracy: 0.9854\n",
            "Epoch 1121/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0285 - accuracy: 0.9931 - val_loss: 0.0590 - val_accuracy: 0.9846\n",
            "Epoch 1122/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0279 - accuracy: 0.9936 - val_loss: 0.0599 - val_accuracy: 0.9838\n",
            "Epoch 1123/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0292 - accuracy: 0.9926 - val_loss: 0.0587 - val_accuracy: 0.9846\n",
            "Epoch 1124/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0295 - accuracy: 0.9926 - val_loss: 0.0597 - val_accuracy: 0.9823\n",
            "Epoch 1125/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0286 - accuracy: 0.9926 - val_loss: 0.0601 - val_accuracy: 0.9838\n",
            "Epoch 1126/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0280 - accuracy: 0.9931 - val_loss: 0.0594 - val_accuracy: 0.9846\n",
            "Epoch 1127/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0280 - accuracy: 0.9936 - val_loss: 0.0590 - val_accuracy: 0.9846\n",
            "Epoch 1128/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0281 - accuracy: 0.9933 - val_loss: 0.0604 - val_accuracy: 0.9862\n",
            "Epoch 1129/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0280 - accuracy: 0.9931 - val_loss: 0.0602 - val_accuracy: 0.9854\n",
            "Epoch 1130/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0284 - accuracy: 0.9931 - val_loss: 0.0599 - val_accuracy: 0.9846\n",
            "Epoch 1131/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0303 - accuracy: 0.9923 - val_loss: 0.0614 - val_accuracy: 0.9846\n",
            "Epoch 1132/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0280 - accuracy: 0.9936 - val_loss: 0.0593 - val_accuracy: 0.9854\n",
            "Epoch 1133/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0278 - accuracy: 0.9933 - val_loss: 0.0599 - val_accuracy: 0.9846\n",
            "Epoch 1134/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0296 - accuracy: 0.9920 - val_loss: 0.0594 - val_accuracy: 0.9846\n",
            "Epoch 1135/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0301 - accuracy: 0.9923 - val_loss: 0.0596 - val_accuracy: 0.9846\n",
            "Epoch 1136/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0283 - accuracy: 0.9931 - val_loss: 0.0613 - val_accuracy: 0.9823\n",
            "Epoch 1137/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0283 - accuracy: 0.9918 - val_loss: 0.0604 - val_accuracy: 0.9838\n",
            "Epoch 1138/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0281 - accuracy: 0.9928 - val_loss: 0.0599 - val_accuracy: 0.9846\n",
            "Epoch 1139/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0280 - accuracy: 0.9928 - val_loss: 0.0628 - val_accuracy: 0.9838\n",
            "Epoch 1140/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0298 - accuracy: 0.9915 - val_loss: 0.0609 - val_accuracy: 0.9846\n",
            "Epoch 1141/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0290 - accuracy: 0.9918 - val_loss: 0.0607 - val_accuracy: 0.9846\n",
            "Epoch 1142/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0274 - accuracy: 0.9936 - val_loss: 0.0598 - val_accuracy: 0.9854\n",
            "Epoch 1143/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0275 - accuracy: 0.9938 - val_loss: 0.0596 - val_accuracy: 0.9815\n",
            "Epoch 1144/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0285 - accuracy: 0.9931 - val_loss: 0.0604 - val_accuracy: 0.9846\n",
            "Epoch 1145/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0274 - accuracy: 0.9938 - val_loss: 0.0609 - val_accuracy: 0.9838\n",
            "Epoch 1146/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0279 - accuracy: 0.9928 - val_loss: 0.0607 - val_accuracy: 0.9831\n",
            "Epoch 1147/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0299 - accuracy: 0.9920 - val_loss: 0.0601 - val_accuracy: 0.9854\n",
            "Epoch 1148/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0279 - accuracy: 0.9928 - val_loss: 0.0591 - val_accuracy: 0.9854\n",
            "Epoch 1149/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0275 - accuracy: 0.9933 - val_loss: 0.0594 - val_accuracy: 0.9854\n",
            "Epoch 1150/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0271 - accuracy: 0.9928 - val_loss: 0.0680 - val_accuracy: 0.9838\n",
            "Epoch 1151/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0334 - accuracy: 0.9902 - val_loss: 0.0653 - val_accuracy: 0.9838\n",
            "Epoch 1152/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0384 - accuracy: 0.9895 - val_loss: 0.0590 - val_accuracy: 0.9846\n",
            "Epoch 1153/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0307 - accuracy: 0.9920 - val_loss: 0.0611 - val_accuracy: 0.9831\n",
            "Epoch 1154/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0283 - accuracy: 0.9923 - val_loss: 0.0599 - val_accuracy: 0.9846\n",
            "Epoch 1155/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0286 - accuracy: 0.9920 - val_loss: 0.0644 - val_accuracy: 0.9838\n",
            "Epoch 1156/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0284 - accuracy: 0.9928 - val_loss: 0.0601 - val_accuracy: 0.9846\n",
            "Epoch 1157/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0279 - accuracy: 0.9933 - val_loss: 0.0607 - val_accuracy: 0.9838\n",
            "Epoch 1158/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0280 - accuracy: 0.9931 - val_loss: 0.0604 - val_accuracy: 0.9823\n",
            "Epoch 1159/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0287 - accuracy: 0.9931 - val_loss: 0.0603 - val_accuracy: 0.9838\n",
            "Epoch 1160/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0276 - accuracy: 0.9926 - val_loss: 0.0602 - val_accuracy: 0.9838\n",
            "Epoch 1161/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0303 - accuracy: 0.9910 - val_loss: 0.0598 - val_accuracy: 0.9838\n",
            "Epoch 1162/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0294 - accuracy: 0.9920 - val_loss: 0.0733 - val_accuracy: 0.9823\n",
            "Epoch 1163/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0311 - accuracy: 0.9913 - val_loss: 0.0607 - val_accuracy: 0.9854\n",
            "Epoch 1164/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0289 - accuracy: 0.9920 - val_loss: 0.0601 - val_accuracy: 0.9846\n",
            "Epoch 1165/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0283 - accuracy: 0.9926 - val_loss: 0.0599 - val_accuracy: 0.9815\n",
            "Epoch 1166/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0300 - accuracy: 0.9923 - val_loss: 0.0616 - val_accuracy: 0.9815\n",
            "Epoch 1167/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0303 - accuracy: 0.9913 - val_loss: 0.0609 - val_accuracy: 0.9846\n",
            "Epoch 1168/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0290 - accuracy: 0.9918 - val_loss: 0.0647 - val_accuracy: 0.9854\n",
            "Epoch 1169/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0297 - accuracy: 0.9918 - val_loss: 0.0618 - val_accuracy: 0.9846\n",
            "Epoch 1170/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0278 - accuracy: 0.9936 - val_loss: 0.0613 - val_accuracy: 0.9838\n",
            "Epoch 1171/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0278 - accuracy: 0.9928 - val_loss: 0.0622 - val_accuracy: 0.9846\n",
            "Epoch 1172/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0286 - accuracy: 0.9931 - val_loss: 0.0598 - val_accuracy: 0.9838\n",
            "Epoch 1173/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0281 - accuracy: 0.9926 - val_loss: 0.0611 - val_accuracy: 0.9838\n",
            "Epoch 1174/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0278 - accuracy: 0.9941 - val_loss: 0.0611 - val_accuracy: 0.9838\n",
            "Epoch 1175/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0278 - accuracy: 0.9933 - val_loss: 0.0610 - val_accuracy: 0.9846\n",
            "Epoch 1176/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0273 - accuracy: 0.9936 - val_loss: 0.0614 - val_accuracy: 0.9838\n",
            "Epoch 1177/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0273 - accuracy: 0.9931 - val_loss: 0.0604 - val_accuracy: 0.9854\n",
            "Epoch 1178/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0292 - accuracy: 0.9941 - val_loss: 0.0640 - val_accuracy: 0.9823\n",
            "Epoch 1179/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0321 - accuracy: 0.9913 - val_loss: 0.0646 - val_accuracy: 0.9815\n",
            "Epoch 1180/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0385 - accuracy: 0.9882 - val_loss: 0.0605 - val_accuracy: 0.9846\n",
            "Epoch 1181/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0375 - accuracy: 0.9895 - val_loss: 0.0780 - val_accuracy: 0.9785\n",
            "Epoch 1182/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0391 - accuracy: 0.9890 - val_loss: 0.0730 - val_accuracy: 0.9815\n",
            "Epoch 1183/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0375 - accuracy: 0.9895 - val_loss: 0.0620 - val_accuracy: 0.9823\n",
            "Epoch 1184/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0322 - accuracy: 0.9913 - val_loss: 0.0637 - val_accuracy: 0.9815\n",
            "Epoch 1185/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0290 - accuracy: 0.9931 - val_loss: 0.0618 - val_accuracy: 0.9838\n",
            "Epoch 1186/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0291 - accuracy: 0.9918 - val_loss: 0.0647 - val_accuracy: 0.9846\n",
            "Epoch 1187/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0268 - accuracy: 0.9933 - val_loss: 0.0612 - val_accuracy: 0.9823\n",
            "Epoch 1188/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0279 - accuracy: 0.9936 - val_loss: 0.0608 - val_accuracy: 0.9838\n",
            "Epoch 1189/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0303 - accuracy: 0.9923 - val_loss: 0.0640 - val_accuracy: 0.9838\n",
            "Epoch 1190/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0285 - accuracy: 0.9923 - val_loss: 0.0659 - val_accuracy: 0.9838\n",
            "Epoch 1191/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0299 - accuracy: 0.9928 - val_loss: 0.0615 - val_accuracy: 0.9838\n",
            "Epoch 1192/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0299 - accuracy: 0.9923 - val_loss: 0.0623 - val_accuracy: 0.9846\n",
            "Epoch 1193/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0279 - accuracy: 0.9931 - val_loss: 0.0623 - val_accuracy: 0.9808\n",
            "Epoch 1194/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0280 - accuracy: 0.9928 - val_loss: 0.0611 - val_accuracy: 0.9854\n",
            "Epoch 1195/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0271 - accuracy: 0.9938 - val_loss: 0.0606 - val_accuracy: 0.9854\n",
            "Epoch 1196/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0274 - accuracy: 0.9933 - val_loss: 0.0626 - val_accuracy: 0.9838\n",
            "Epoch 1197/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0284 - accuracy: 0.9928 - val_loss: 0.0624 - val_accuracy: 0.9846\n",
            "Epoch 1198/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0279 - accuracy: 0.9933 - val_loss: 0.0615 - val_accuracy: 0.9838\n",
            "Epoch 1199/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0279 - accuracy: 0.9931 - val_loss: 0.0613 - val_accuracy: 0.9831\n",
            "Epoch 1200/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0269 - accuracy: 0.9938 - val_loss: 0.0640 - val_accuracy: 0.9854\n",
            "Epoch 1201/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0270 - accuracy: 0.9938 - val_loss: 0.0614 - val_accuracy: 0.9838\n",
            "Epoch 1202/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0277 - accuracy: 0.9928 - val_loss: 0.0626 - val_accuracy: 0.9823\n",
            "Epoch 1203/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0275 - accuracy: 0.9936 - val_loss: 0.0624 - val_accuracy: 0.9854\n",
            "Epoch 1204/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0284 - accuracy: 0.9923 - val_loss: 0.0635 - val_accuracy: 0.9846\n",
            "Epoch 1205/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0266 - accuracy: 0.9933 - val_loss: 0.0620 - val_accuracy: 0.9838\n",
            "Epoch 1206/2000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0272 - accuracy: 0.9936 - val_loss: 0.0617 - val_accuracy: 0.9846\n",
            "Epoch 1207/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0283 - accuracy: 0.9931 - val_loss: 0.0619 - val_accuracy: 0.9831\n",
            "Epoch 1208/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0271 - accuracy: 0.9928 - val_loss: 0.0656 - val_accuracy: 0.9831\n",
            "Epoch 1209/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0279 - accuracy: 0.9923 - val_loss: 0.0650 - val_accuracy: 0.9854\n",
            "Epoch 1210/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0284 - accuracy: 0.9923 - val_loss: 0.0614 - val_accuracy: 0.9838\n",
            "Epoch 1211/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0290 - accuracy: 0.9928 - val_loss: 0.0657 - val_accuracy: 0.9815\n",
            "Epoch 1212/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0314 - accuracy: 0.9918 - val_loss: 0.0634 - val_accuracy: 0.9831\n",
            "Epoch 1213/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0297 - accuracy: 0.9920 - val_loss: 0.0661 - val_accuracy: 0.9846\n",
            "Epoch 1214/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0310 - accuracy: 0.9905 - val_loss: 0.0710 - val_accuracy: 0.9831\n",
            "Epoch 1215/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0312 - accuracy: 0.9905 - val_loss: 0.0633 - val_accuracy: 0.9846\n",
            "Epoch 1216/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0307 - accuracy: 0.9926 - val_loss: 0.0663 - val_accuracy: 0.9815\n",
            "Epoch 1217/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0292 - accuracy: 0.9931 - val_loss: 0.0637 - val_accuracy: 0.9846\n",
            "Epoch 1218/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0287 - accuracy: 0.9928 - val_loss: 0.0639 - val_accuracy: 0.9838\n",
            "Epoch 1219/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0288 - accuracy: 0.9933 - val_loss: 0.0638 - val_accuracy: 0.9823\n",
            "Epoch 1220/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0295 - accuracy: 0.9931 - val_loss: 0.0655 - val_accuracy: 0.9815\n",
            "Epoch 1221/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0325 - accuracy: 0.9913 - val_loss: 0.0634 - val_accuracy: 0.9823\n",
            "Epoch 1222/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0285 - accuracy: 0.9910 - val_loss: 0.0635 - val_accuracy: 0.9854\n",
            "Epoch 1223/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0284 - accuracy: 0.9928 - val_loss: 0.0677 - val_accuracy: 0.9831\n",
            "Epoch 1224/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0304 - accuracy: 0.9918 - val_loss: 0.0661 - val_accuracy: 0.9838\n",
            "Epoch 1225/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0304 - accuracy: 0.9915 - val_loss: 0.0635 - val_accuracy: 0.9838\n",
            "Epoch 1226/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0285 - accuracy: 0.9926 - val_loss: 0.0639 - val_accuracy: 0.9815\n",
            "Epoch 1227/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0281 - accuracy: 0.9923 - val_loss: 0.0637 - val_accuracy: 0.9838\n",
            "Epoch 1228/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0293 - accuracy: 0.9923 - val_loss: 0.0641 - val_accuracy: 0.9846\n",
            "Epoch 1229/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0273 - accuracy: 0.9928 - val_loss: 0.0654 - val_accuracy: 0.9846\n",
            "Epoch 1230/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0291 - accuracy: 0.9923 - val_loss: 0.0641 - val_accuracy: 0.9846\n",
            "Epoch 1231/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0278 - accuracy: 0.9931 - val_loss: 0.0657 - val_accuracy: 0.9808\n",
            "Epoch 1232/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0295 - accuracy: 0.9928 - val_loss: 0.0626 - val_accuracy: 0.9831\n",
            "Epoch 1233/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0304 - accuracy: 0.9908 - val_loss: 0.0660 - val_accuracy: 0.9838\n",
            "Epoch 1234/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0302 - accuracy: 0.9931 - val_loss: 0.0673 - val_accuracy: 0.9846\n",
            "Epoch 1235/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0280 - accuracy: 0.9923 - val_loss: 0.0631 - val_accuracy: 0.9846\n",
            "Epoch 1236/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0273 - accuracy: 0.9928 - val_loss: 0.0646 - val_accuracy: 0.9838\n",
            "Epoch 1237/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0273 - accuracy: 0.9938 - val_loss: 0.0623 - val_accuracy: 0.9838\n",
            "Epoch 1238/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0278 - accuracy: 0.9933 - val_loss: 0.0626 - val_accuracy: 0.9838\n",
            "Epoch 1239/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0266 - accuracy: 0.9931 - val_loss: 0.0666 - val_accuracy: 0.9815\n",
            "Epoch 1240/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0326 - accuracy: 0.9902 - val_loss: 0.0630 - val_accuracy: 0.9838\n",
            "Epoch 1241/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0327 - accuracy: 0.9910 - val_loss: 0.0661 - val_accuracy: 0.9838\n",
            "Epoch 1242/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0304 - accuracy: 0.9926 - val_loss: 0.0672 - val_accuracy: 0.9838\n",
            "Epoch 1243/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0268 - accuracy: 0.9944 - val_loss: 0.0645 - val_accuracy: 0.9815\n",
            "Epoch 1244/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0283 - accuracy: 0.9933 - val_loss: 0.0625 - val_accuracy: 0.9846\n",
            "Epoch 1245/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0284 - accuracy: 0.9931 - val_loss: 0.0631 - val_accuracy: 0.9846\n",
            "Epoch 1246/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0268 - accuracy: 0.9936 - val_loss: 0.0627 - val_accuracy: 0.9838\n",
            "Epoch 1247/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0266 - accuracy: 0.9928 - val_loss: 0.0692 - val_accuracy: 0.9831\n",
            "Epoch 1248/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0285 - accuracy: 0.9928 - val_loss: 0.0623 - val_accuracy: 0.9838\n",
            "Epoch 1249/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0297 - accuracy: 0.9908 - val_loss: 0.0639 - val_accuracy: 0.9815\n",
            "Epoch 1250/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0313 - accuracy: 0.9918 - val_loss: 0.0657 - val_accuracy: 0.9815\n",
            "Epoch 1251/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0363 - accuracy: 0.9892 - val_loss: 0.0649 - val_accuracy: 0.9838\n",
            "Epoch 1252/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0319 - accuracy: 0.9897 - val_loss: 0.0672 - val_accuracy: 0.9838\n",
            "Epoch 1253/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0278 - accuracy: 0.9926 - val_loss: 0.0647 - val_accuracy: 0.9854\n",
            "Epoch 1254/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0287 - accuracy: 0.9920 - val_loss: 0.0627 - val_accuracy: 0.9846\n",
            "Epoch 1255/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0294 - accuracy: 0.9931 - val_loss: 0.0662 - val_accuracy: 0.9815\n",
            "Epoch 1256/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0325 - accuracy: 0.9915 - val_loss: 0.0665 - val_accuracy: 0.9815\n",
            "Epoch 1257/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0309 - accuracy: 0.9915 - val_loss: 0.0664 - val_accuracy: 0.9831\n",
            "Epoch 1258/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0277 - accuracy: 0.9926 - val_loss: 0.0662 - val_accuracy: 0.9846\n",
            "Epoch 1259/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0276 - accuracy: 0.9933 - val_loss: 0.0634 - val_accuracy: 0.9838\n",
            "Epoch 1260/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0265 - accuracy: 0.9931 - val_loss: 0.0634 - val_accuracy: 0.9831\n",
            "Epoch 1261/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0268 - accuracy: 0.9941 - val_loss: 0.0621 - val_accuracy: 0.9838\n",
            "Epoch 1262/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0266 - accuracy: 0.9933 - val_loss: 0.0626 - val_accuracy: 0.9838\n",
            "Epoch 1263/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0279 - accuracy: 0.9931 - val_loss: 0.0628 - val_accuracy: 0.9846\n",
            "Epoch 1264/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0263 - accuracy: 0.9938 - val_loss: 0.0660 - val_accuracy: 0.9838\n",
            "Epoch 1265/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0297 - accuracy: 0.9918 - val_loss: 0.0635 - val_accuracy: 0.9854\n",
            "Epoch 1266/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0315 - accuracy: 0.9918 - val_loss: 0.0636 - val_accuracy: 0.9815\n",
            "Epoch 1267/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0272 - accuracy: 0.9936 - val_loss: 0.0638 - val_accuracy: 0.9823\n",
            "Epoch 1268/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0284 - accuracy: 0.9931 - val_loss: 0.0634 - val_accuracy: 0.9838\n",
            "Epoch 1269/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0259 - accuracy: 0.9936 - val_loss: 0.0667 - val_accuracy: 0.9838\n",
            "Epoch 1270/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0289 - accuracy: 0.9918 - val_loss: 0.0674 - val_accuracy: 0.9838\n",
            "Epoch 1271/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0292 - accuracy: 0.9920 - val_loss: 0.0644 - val_accuracy: 0.9838\n",
            "Epoch 1272/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0288 - accuracy: 0.9931 - val_loss: 0.0669 - val_accuracy: 0.9815\n",
            "Epoch 1273/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0292 - accuracy: 0.9928 - val_loss: 0.0636 - val_accuracy: 0.9823\n",
            "Epoch 1274/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0284 - accuracy: 0.9936 - val_loss: 0.0635 - val_accuracy: 0.9846\n",
            "Epoch 1275/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0276 - accuracy: 0.9931 - val_loss: 0.0669 - val_accuracy: 0.9838\n",
            "Epoch 1276/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0267 - accuracy: 0.9928 - val_loss: 0.0635 - val_accuracy: 0.9838\n",
            "Epoch 1277/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0262 - accuracy: 0.9944 - val_loss: 0.0629 - val_accuracy: 0.9846\n",
            "Epoch 1278/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0268 - accuracy: 0.9933 - val_loss: 0.0657 - val_accuracy: 0.9838\n",
            "Epoch 1279/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0273 - accuracy: 0.9931 - val_loss: 0.0656 - val_accuracy: 0.9846\n",
            "Epoch 1280/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0277 - accuracy: 0.9928 - val_loss: 0.0631 - val_accuracy: 0.9831\n",
            "Epoch 1281/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0273 - accuracy: 0.9931 - val_loss: 0.0636 - val_accuracy: 0.9838\n",
            "Epoch 1282/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0268 - accuracy: 0.9931 - val_loss: 0.0634 - val_accuracy: 0.9846\n",
            "Epoch 1283/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0283 - accuracy: 0.9938 - val_loss: 0.0643 - val_accuracy: 0.9815\n",
            "Epoch 1284/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0290 - accuracy: 0.9923 - val_loss: 0.0674 - val_accuracy: 0.9815\n",
            "Epoch 1285/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0297 - accuracy: 0.9913 - val_loss: 0.0646 - val_accuracy: 0.9846\n",
            "Epoch 1286/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0321 - accuracy: 0.9910 - val_loss: 0.0663 - val_accuracy: 0.9854\n",
            "Epoch 1287/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0299 - accuracy: 0.9926 - val_loss: 0.0680 - val_accuracy: 0.9831\n",
            "Epoch 1288/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0257 - accuracy: 0.9938 - val_loss: 0.0650 - val_accuracy: 0.9815\n",
            "Epoch 1289/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0274 - accuracy: 0.9931 - val_loss: 0.0650 - val_accuracy: 0.9823\n",
            "Epoch 1290/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0271 - accuracy: 0.9918 - val_loss: 0.0671 - val_accuracy: 0.9831\n",
            "Epoch 1291/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0282 - accuracy: 0.9918 - val_loss: 0.0693 - val_accuracy: 0.9838\n",
            "Epoch 1292/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0296 - accuracy: 0.9905 - val_loss: 0.0659 - val_accuracy: 0.9838\n",
            "Epoch 1293/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0264 - accuracy: 0.9941 - val_loss: 0.0642 - val_accuracy: 0.9838\n",
            "Epoch 1294/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0263 - accuracy: 0.9933 - val_loss: 0.0638 - val_accuracy: 0.9846\n",
            "Epoch 1295/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0261 - accuracy: 0.9944 - val_loss: 0.0635 - val_accuracy: 0.9838\n",
            "Epoch 1296/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0262 - accuracy: 0.9938 - val_loss: 0.0644 - val_accuracy: 0.9838\n",
            "Epoch 1297/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0262 - accuracy: 0.9938 - val_loss: 0.0638 - val_accuracy: 0.9838\n",
            "Epoch 1298/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0260 - accuracy: 0.9936 - val_loss: 0.0654 - val_accuracy: 0.9815\n",
            "Epoch 1299/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0279 - accuracy: 0.9920 - val_loss: 0.0652 - val_accuracy: 0.9823\n",
            "Epoch 1300/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0271 - accuracy: 0.9931 - val_loss: 0.0637 - val_accuracy: 0.9846\n",
            "Epoch 1301/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0256 - accuracy: 0.9941 - val_loss: 0.0722 - val_accuracy: 0.9823\n",
            "Epoch 1302/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0288 - accuracy: 0.9918 - val_loss: 0.0644 - val_accuracy: 0.9838\n",
            "Epoch 1303/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0284 - accuracy: 0.9923 - val_loss: 0.0643 - val_accuracy: 0.9838\n",
            "Epoch 1304/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0269 - accuracy: 0.9936 - val_loss: 0.0640 - val_accuracy: 0.9838\n",
            "Epoch 1305/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0262 - accuracy: 0.9938 - val_loss: 0.0642 - val_accuracy: 0.9823\n",
            "Epoch 1306/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0279 - accuracy: 0.9920 - val_loss: 0.0635 - val_accuracy: 0.9838\n",
            "Epoch 1307/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0270 - accuracy: 0.9926 - val_loss: 0.0663 - val_accuracy: 0.9838\n",
            "Epoch 1308/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0265 - accuracy: 0.9933 - val_loss: 0.0659 - val_accuracy: 0.9854\n",
            "Epoch 1309/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0287 - accuracy: 0.9928 - val_loss: 0.0644 - val_accuracy: 0.9838\n",
            "Epoch 1310/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0271 - accuracy: 0.9933 - val_loss: 0.0646 - val_accuracy: 0.9838\n",
            "Epoch 1311/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0263 - accuracy: 0.9936 - val_loss: 0.0646 - val_accuracy: 0.9838\n",
            "Epoch 1312/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0266 - accuracy: 0.9936 - val_loss: 0.0660 - val_accuracy: 0.9846\n",
            "Epoch 1313/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0263 - accuracy: 0.9933 - val_loss: 0.0644 - val_accuracy: 0.9838\n",
            "Epoch 1314/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0290 - accuracy: 0.9933 - val_loss: 0.0641 - val_accuracy: 0.9838\n",
            "Epoch 1315/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0290 - accuracy: 0.9920 - val_loss: 0.0656 - val_accuracy: 0.9808\n",
            "Epoch 1316/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0297 - accuracy: 0.9920 - val_loss: 0.0668 - val_accuracy: 0.9808\n",
            "Epoch 1317/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0294 - accuracy: 0.9918 - val_loss: 0.0655 - val_accuracy: 0.9808\n",
            "Epoch 1318/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0347 - accuracy: 0.9890 - val_loss: 0.0655 - val_accuracy: 0.9846\n",
            "Epoch 1319/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0274 - accuracy: 0.9926 - val_loss: 0.0683 - val_accuracy: 0.9838\n",
            "Epoch 1320/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0265 - accuracy: 0.9926 - val_loss: 0.0647 - val_accuracy: 0.9838\n",
            "Epoch 1321/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0259 - accuracy: 0.9933 - val_loss: 0.0649 - val_accuracy: 0.9846\n",
            "Epoch 1322/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0253 - accuracy: 0.9931 - val_loss: 0.0651 - val_accuracy: 0.9838\n",
            "Epoch 1323/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0271 - accuracy: 0.9936 - val_loss: 0.0653 - val_accuracy: 0.9846\n",
            "Epoch 1324/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0260 - accuracy: 0.9933 - val_loss: 0.0644 - val_accuracy: 0.9846\n",
            "Epoch 1325/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0256 - accuracy: 0.9938 - val_loss: 0.0649 - val_accuracy: 0.9846\n",
            "Epoch 1326/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0257 - accuracy: 0.9936 - val_loss: 0.0644 - val_accuracy: 0.9846\n",
            "Epoch 1327/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0254 - accuracy: 0.9944 - val_loss: 0.0662 - val_accuracy: 0.9838\n",
            "Epoch 1328/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0264 - accuracy: 0.9931 - val_loss: 0.0658 - val_accuracy: 0.9838\n",
            "Epoch 1329/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0264 - accuracy: 0.9938 - val_loss: 0.0645 - val_accuracy: 0.9838\n",
            "Epoch 1330/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0254 - accuracy: 0.9936 - val_loss: 0.0656 - val_accuracy: 0.9846\n",
            "Epoch 1331/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0257 - accuracy: 0.9936 - val_loss: 0.0640 - val_accuracy: 0.9838\n",
            "Epoch 1332/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0273 - accuracy: 0.9931 - val_loss: 0.0649 - val_accuracy: 0.9831\n",
            "Epoch 1333/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0267 - accuracy: 0.9938 - val_loss: 0.0657 - val_accuracy: 0.9846\n",
            "Epoch 1334/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0269 - accuracy: 0.9936 - val_loss: 0.0643 - val_accuracy: 0.9838\n",
            "Epoch 1335/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0269 - accuracy: 0.9923 - val_loss: 0.0654 - val_accuracy: 0.9831\n",
            "Epoch 1336/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0265 - accuracy: 0.9933 - val_loss: 0.0646 - val_accuracy: 0.9846\n",
            "Epoch 1337/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0253 - accuracy: 0.9941 - val_loss: 0.0648 - val_accuracy: 0.9838\n",
            "Epoch 1338/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0267 - accuracy: 0.9931 - val_loss: 0.0656 - val_accuracy: 0.9846\n",
            "Epoch 1339/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0287 - accuracy: 0.9918 - val_loss: 0.0679 - val_accuracy: 0.9815\n",
            "Epoch 1340/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0274 - accuracy: 0.9933 - val_loss: 0.0658 - val_accuracy: 0.9815\n",
            "Epoch 1341/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0292 - accuracy: 0.9920 - val_loss: 0.0657 - val_accuracy: 0.9831\n",
            "Epoch 1342/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0277 - accuracy: 0.9931 - val_loss: 0.0653 - val_accuracy: 0.9831\n",
            "Epoch 1343/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0279 - accuracy: 0.9936 - val_loss: 0.0654 - val_accuracy: 0.9838\n",
            "Epoch 1344/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0292 - accuracy: 0.9923 - val_loss: 0.0669 - val_accuracy: 0.9838\n",
            "Epoch 1345/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0260 - accuracy: 0.9936 - val_loss: 0.0649 - val_accuracy: 0.9846\n",
            "Epoch 1346/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0255 - accuracy: 0.9936 - val_loss: 0.0659 - val_accuracy: 0.9846\n",
            "Epoch 1347/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0281 - accuracy: 0.9920 - val_loss: 0.0647 - val_accuracy: 0.9831\n",
            "Epoch 1348/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0271 - accuracy: 0.9933 - val_loss: 0.0671 - val_accuracy: 0.9831\n",
            "Epoch 1349/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0297 - accuracy: 0.9915 - val_loss: 0.0667 - val_accuracy: 0.9846\n",
            "Epoch 1350/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0305 - accuracy: 0.9918 - val_loss: 0.0685 - val_accuracy: 0.9838\n",
            "Epoch 1351/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0295 - accuracy: 0.9928 - val_loss: 0.0731 - val_accuracy: 0.9838\n",
            "Epoch 1352/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0355 - accuracy: 0.9879 - val_loss: 0.0697 - val_accuracy: 0.9838\n",
            "Epoch 1353/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0324 - accuracy: 0.9905 - val_loss: 0.0679 - val_accuracy: 0.9815\n",
            "Epoch 1354/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0277 - accuracy: 0.9928 - val_loss: 0.0662 - val_accuracy: 0.9831\n",
            "Epoch 1355/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0277 - accuracy: 0.9926 - val_loss: 0.0645 - val_accuracy: 0.9846\n",
            "Epoch 1356/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0259 - accuracy: 0.9938 - val_loss: 0.0642 - val_accuracy: 0.9846\n",
            "Epoch 1357/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0254 - accuracy: 0.9933 - val_loss: 0.0649 - val_accuracy: 0.9854\n",
            "Epoch 1358/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0260 - accuracy: 0.9941 - val_loss: 0.0646 - val_accuracy: 0.9838\n",
            "Epoch 1359/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0257 - accuracy: 0.9941 - val_loss: 0.0646 - val_accuracy: 0.9846\n",
            "Epoch 1360/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0262 - accuracy: 0.9936 - val_loss: 0.0671 - val_accuracy: 0.9838\n",
            "Epoch 1361/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0270 - accuracy: 0.9936 - val_loss: 0.0657 - val_accuracy: 0.9838\n",
            "Epoch 1362/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0281 - accuracy: 0.9918 - val_loss: 0.0645 - val_accuracy: 0.9838\n",
            "Epoch 1363/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0291 - accuracy: 0.9926 - val_loss: 0.0658 - val_accuracy: 0.9815\n",
            "Epoch 1364/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0283 - accuracy: 0.9926 - val_loss: 0.0681 - val_accuracy: 0.9815\n",
            "Epoch 1365/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0284 - accuracy: 0.9918 - val_loss: 0.0678 - val_accuracy: 0.9838\n",
            "Epoch 1366/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0257 - accuracy: 0.9928 - val_loss: 0.0683 - val_accuracy: 0.9838\n",
            "Epoch 1367/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0274 - accuracy: 0.9931 - val_loss: 0.0671 - val_accuracy: 0.9846\n",
            "Epoch 1368/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0283 - accuracy: 0.9926 - val_loss: 0.0646 - val_accuracy: 0.9838\n",
            "Epoch 1369/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0267 - accuracy: 0.9936 - val_loss: 0.0647 - val_accuracy: 0.9823\n",
            "Epoch 1370/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0251 - accuracy: 0.9941 - val_loss: 0.0658 - val_accuracy: 0.9838\n",
            "Epoch 1371/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0254 - accuracy: 0.9931 - val_loss: 0.0658 - val_accuracy: 0.9815\n",
            "Epoch 1372/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0261 - accuracy: 0.9933 - val_loss: 0.0651 - val_accuracy: 0.9846\n",
            "Epoch 1373/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0251 - accuracy: 0.9941 - val_loss: 0.0648 - val_accuracy: 0.9838\n",
            "Epoch 1374/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0256 - accuracy: 0.9928 - val_loss: 0.0647 - val_accuracy: 0.9846\n",
            "Epoch 1375/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0249 - accuracy: 0.9941 - val_loss: 0.0641 - val_accuracy: 0.9838\n",
            "Epoch 1376/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0258 - accuracy: 0.9944 - val_loss: 0.0662 - val_accuracy: 0.9815\n",
            "Epoch 1377/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0283 - accuracy: 0.9931 - val_loss: 0.0672 - val_accuracy: 0.9854\n",
            "Epoch 1378/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0252 - accuracy: 0.9938 - val_loss: 0.0648 - val_accuracy: 0.9846\n",
            "Epoch 1379/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0273 - accuracy: 0.9938 - val_loss: 0.0653 - val_accuracy: 0.9831\n",
            "Epoch 1380/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0252 - accuracy: 0.9936 - val_loss: 0.0666 - val_accuracy: 0.9838\n",
            "Epoch 1381/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0254 - accuracy: 0.9923 - val_loss: 0.0697 - val_accuracy: 0.9831\n",
            "Epoch 1382/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0288 - accuracy: 0.9931 - val_loss: 0.0660 - val_accuracy: 0.9838\n",
            "Epoch 1383/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0265 - accuracy: 0.9941 - val_loss: 0.0646 - val_accuracy: 0.9846\n",
            "Epoch 1384/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0259 - accuracy: 0.9928 - val_loss: 0.0678 - val_accuracy: 0.9823\n",
            "Epoch 1385/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0259 - accuracy: 0.9938 - val_loss: 0.0656 - val_accuracy: 0.9838\n",
            "Epoch 1386/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0255 - accuracy: 0.9936 - val_loss: 0.0657 - val_accuracy: 0.9831\n",
            "Epoch 1387/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0251 - accuracy: 0.9938 - val_loss: 0.0659 - val_accuracy: 0.9838\n",
            "Epoch 1388/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0270 - accuracy: 0.9928 - val_loss: 0.0668 - val_accuracy: 0.9808\n",
            "Epoch 1389/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0270 - accuracy: 0.9926 - val_loss: 0.0657 - val_accuracy: 0.9846\n",
            "Epoch 1390/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0261 - accuracy: 0.9928 - val_loss: 0.0665 - val_accuracy: 0.9808\n",
            "Epoch 1391/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0280 - accuracy: 0.9926 - val_loss: 0.0659 - val_accuracy: 0.9838\n",
            "Epoch 1392/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0256 - accuracy: 0.9931 - val_loss: 0.0654 - val_accuracy: 0.9846\n",
            "Epoch 1393/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0259 - accuracy: 0.9936 - val_loss: 0.0673 - val_accuracy: 0.9854\n",
            "Epoch 1394/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0262 - accuracy: 0.9938 - val_loss: 0.0660 - val_accuracy: 0.9846\n",
            "Epoch 1395/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0256 - accuracy: 0.9936 - val_loss: 0.0641 - val_accuracy: 0.9838\n",
            "Epoch 1396/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0251 - accuracy: 0.9936 - val_loss: 0.0681 - val_accuracy: 0.9831\n",
            "Epoch 1397/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0270 - accuracy: 0.9931 - val_loss: 0.0678 - val_accuracy: 0.9838\n",
            "Epoch 1398/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0271 - accuracy: 0.9928 - val_loss: 0.0680 - val_accuracy: 0.9838\n",
            "Epoch 1399/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0282 - accuracy: 0.9923 - val_loss: 0.0675 - val_accuracy: 0.9831\n",
            "Epoch 1400/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0259 - accuracy: 0.9933 - val_loss: 0.0671 - val_accuracy: 0.9831\n",
            "Epoch 1401/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0265 - accuracy: 0.9936 - val_loss: 0.0655 - val_accuracy: 0.9831\n",
            "Epoch 1402/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0258 - accuracy: 0.9941 - val_loss: 0.0652 - val_accuracy: 0.9846\n",
            "Epoch 1403/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0251 - accuracy: 0.9941 - val_loss: 0.0664 - val_accuracy: 0.9808\n",
            "Epoch 1404/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0279 - accuracy: 0.9918 - val_loss: 0.0663 - val_accuracy: 0.9838\n",
            "Epoch 1405/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0263 - accuracy: 0.9933 - val_loss: 0.0677 - val_accuracy: 0.9838\n",
            "Epoch 1406/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0267 - accuracy: 0.9928 - val_loss: 0.0673 - val_accuracy: 0.9846\n",
            "Epoch 1407/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0260 - accuracy: 0.9931 - val_loss: 0.0673 - val_accuracy: 0.9854\n",
            "Epoch 1408/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0273 - accuracy: 0.9928 - val_loss: 0.0662 - val_accuracy: 0.9846\n",
            "Epoch 1409/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0275 - accuracy: 0.9931 - val_loss: 0.0646 - val_accuracy: 0.9831\n",
            "Epoch 1410/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0259 - accuracy: 0.9936 - val_loss: 0.0667 - val_accuracy: 0.9838\n",
            "Epoch 1411/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0264 - accuracy: 0.9936 - val_loss: 0.0662 - val_accuracy: 0.9838\n",
            "Epoch 1412/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0260 - accuracy: 0.9938 - val_loss: 0.0655 - val_accuracy: 0.9838\n",
            "Epoch 1413/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0277 - accuracy: 0.9915 - val_loss: 0.0670 - val_accuracy: 0.9838\n",
            "Epoch 1414/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0262 - accuracy: 0.9918 - val_loss: 0.0708 - val_accuracy: 0.9838\n",
            "Epoch 1415/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0266 - accuracy: 0.9926 - val_loss: 0.0672 - val_accuracy: 0.9854\n",
            "Epoch 1416/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0253 - accuracy: 0.9936 - val_loss: 0.0660 - val_accuracy: 0.9846\n",
            "Epoch 1417/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0258 - accuracy: 0.9938 - val_loss: 0.0666 - val_accuracy: 0.9838\n",
            "Epoch 1418/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0261 - accuracy: 0.9923 - val_loss: 0.0663 - val_accuracy: 0.9831\n",
            "Epoch 1419/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0261 - accuracy: 0.9926 - val_loss: 0.0688 - val_accuracy: 0.9815\n",
            "Epoch 1420/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0277 - accuracy: 0.9928 - val_loss: 0.0681 - val_accuracy: 0.9846\n",
            "Epoch 1421/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0258 - accuracy: 0.9931 - val_loss: 0.0673 - val_accuracy: 0.9838\n",
            "Epoch 1422/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0257 - accuracy: 0.9938 - val_loss: 0.0695 - val_accuracy: 0.9831\n",
            "Epoch 1423/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0266 - accuracy: 0.9931 - val_loss: 0.0718 - val_accuracy: 0.9831\n",
            "Epoch 1424/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0292 - accuracy: 0.9920 - val_loss: 0.0669 - val_accuracy: 0.9838\n",
            "Epoch 1425/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0282 - accuracy: 0.9926 - val_loss: 0.0662 - val_accuracy: 0.9838\n",
            "Epoch 1426/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0260 - accuracy: 0.9936 - val_loss: 0.0663 - val_accuracy: 0.9846\n",
            "Epoch 1427/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0249 - accuracy: 0.9938 - val_loss: 0.0668 - val_accuracy: 0.9838\n",
            "Epoch 1428/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0251 - accuracy: 0.9936 - val_loss: 0.0673 - val_accuracy: 0.9854\n",
            "Epoch 1429/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0249 - accuracy: 0.9936 - val_loss: 0.0658 - val_accuracy: 0.9846\n",
            "Epoch 1430/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0259 - accuracy: 0.9944 - val_loss: 0.0645 - val_accuracy: 0.9823\n",
            "Epoch 1431/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0239 - accuracy: 0.9949 - val_loss: 0.0674 - val_accuracy: 0.9846\n",
            "Epoch 1432/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0250 - accuracy: 0.9941 - val_loss: 0.0658 - val_accuracy: 0.9838\n",
            "Epoch 1433/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0246 - accuracy: 0.9938 - val_loss: 0.0669 - val_accuracy: 0.9838\n",
            "Epoch 1434/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0253 - accuracy: 0.9936 - val_loss: 0.0649 - val_accuracy: 0.9846\n",
            "Epoch 1435/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0246 - accuracy: 0.9936 - val_loss: 0.0663 - val_accuracy: 0.9838\n",
            "Epoch 1436/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0246 - accuracy: 0.9938 - val_loss: 0.0652 - val_accuracy: 0.9831\n",
            "Epoch 1437/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0261 - accuracy: 0.9920 - val_loss: 0.0659 - val_accuracy: 0.9808\n",
            "Epoch 1438/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0281 - accuracy: 0.9923 - val_loss: 0.0649 - val_accuracy: 0.9838\n",
            "Epoch 1439/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0251 - accuracy: 0.9933 - val_loss: 0.0668 - val_accuracy: 0.9846\n",
            "Epoch 1440/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0269 - accuracy: 0.9936 - val_loss: 0.0651 - val_accuracy: 0.9854\n",
            "Epoch 1441/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0273 - accuracy: 0.9926 - val_loss: 0.0717 - val_accuracy: 0.9831\n",
            "Epoch 1442/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0288 - accuracy: 0.9918 - val_loss: 0.0747 - val_accuracy: 0.9831\n",
            "Epoch 1443/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0351 - accuracy: 0.9887 - val_loss: 0.0748 - val_accuracy: 0.9831\n",
            "Epoch 1444/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0318 - accuracy: 0.9910 - val_loss: 0.0673 - val_accuracy: 0.9846\n",
            "Epoch 1445/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0277 - accuracy: 0.9931 - val_loss: 0.0684 - val_accuracy: 0.9838\n",
            "Epoch 1446/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0259 - accuracy: 0.9933 - val_loss: 0.0680 - val_accuracy: 0.9831\n",
            "Epoch 1447/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0254 - accuracy: 0.9938 - val_loss: 0.0663 - val_accuracy: 0.9854\n",
            "Epoch 1448/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0246 - accuracy: 0.9928 - val_loss: 0.0691 - val_accuracy: 0.9854\n",
            "Epoch 1449/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0260 - accuracy: 0.9936 - val_loss: 0.0684 - val_accuracy: 0.9854\n",
            "Epoch 1450/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0261 - accuracy: 0.9933 - val_loss: 0.0671 - val_accuracy: 0.9838\n",
            "Epoch 1451/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0255 - accuracy: 0.9936 - val_loss: 0.0680 - val_accuracy: 0.9838\n",
            "Epoch 1452/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0255 - accuracy: 0.9938 - val_loss: 0.0671 - val_accuracy: 0.9838\n",
            "Epoch 1453/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0259 - accuracy: 0.9931 - val_loss: 0.0666 - val_accuracy: 0.9838\n",
            "Epoch 1454/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0246 - accuracy: 0.9938 - val_loss: 0.0677 - val_accuracy: 0.9846\n",
            "Epoch 1455/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0240 - accuracy: 0.9944 - val_loss: 0.0676 - val_accuracy: 0.9823\n",
            "Epoch 1456/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0245 - accuracy: 0.9944 - val_loss: 0.0679 - val_accuracy: 0.9846\n",
            "Epoch 1457/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0255 - accuracy: 0.9936 - val_loss: 0.0708 - val_accuracy: 0.9838\n",
            "Epoch 1458/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0247 - accuracy: 0.9936 - val_loss: 0.0665 - val_accuracy: 0.9838\n",
            "Epoch 1459/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0244 - accuracy: 0.9941 - val_loss: 0.0664 - val_accuracy: 0.9846\n",
            "Epoch 1460/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0247 - accuracy: 0.9941 - val_loss: 0.0667 - val_accuracy: 0.9838\n",
            "Epoch 1461/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0247 - accuracy: 0.9941 - val_loss: 0.0665 - val_accuracy: 0.9838\n",
            "Epoch 1462/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0267 - accuracy: 0.9941 - val_loss: 0.0671 - val_accuracy: 0.9838\n",
            "Epoch 1463/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0271 - accuracy: 0.9923 - val_loss: 0.0669 - val_accuracy: 0.9838\n",
            "Epoch 1464/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0251 - accuracy: 0.9938 - val_loss: 0.0695 - val_accuracy: 0.9846\n",
            "Epoch 1465/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0250 - accuracy: 0.9938 - val_loss: 0.0676 - val_accuracy: 0.9838\n",
            "Epoch 1466/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0261 - accuracy: 0.9931 - val_loss: 0.0684 - val_accuracy: 0.9838\n",
            "Epoch 1467/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0246 - accuracy: 0.9938 - val_loss: 0.0667 - val_accuracy: 0.9838\n",
            "Epoch 1468/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0243 - accuracy: 0.9936 - val_loss: 0.0668 - val_accuracy: 0.9838\n",
            "Epoch 1469/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0254 - accuracy: 0.9933 - val_loss: 0.0684 - val_accuracy: 0.9838\n",
            "Epoch 1470/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0240 - accuracy: 0.9946 - val_loss: 0.0671 - val_accuracy: 0.9838\n",
            "Epoch 1471/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0254 - accuracy: 0.9946 - val_loss: 0.0681 - val_accuracy: 0.9823\n",
            "Epoch 1472/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0267 - accuracy: 0.9928 - val_loss: 0.0695 - val_accuracy: 0.9831\n",
            "Epoch 1473/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0270 - accuracy: 0.9923 - val_loss: 0.0683 - val_accuracy: 0.9846\n",
            "Epoch 1474/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0263 - accuracy: 0.9926 - val_loss: 0.0724 - val_accuracy: 0.9838\n",
            "Epoch 1475/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0277 - accuracy: 0.9926 - val_loss: 0.0706 - val_accuracy: 0.9854\n",
            "Epoch 1476/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0253 - accuracy: 0.9936 - val_loss: 0.0676 - val_accuracy: 0.9846\n",
            "Epoch 1477/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0269 - accuracy: 0.9928 - val_loss: 0.0689 - val_accuracy: 0.9846\n",
            "Epoch 1478/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0268 - accuracy: 0.9938 - val_loss: 0.0684 - val_accuracy: 0.9838\n",
            "Epoch 1479/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0274 - accuracy: 0.9923 - val_loss: 0.0715 - val_accuracy: 0.9808\n",
            "Epoch 1480/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0295 - accuracy: 0.9900 - val_loss: 0.0672 - val_accuracy: 0.9838\n",
            "Epoch 1481/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0250 - accuracy: 0.9931 - val_loss: 0.0688 - val_accuracy: 0.9854\n",
            "Epoch 1482/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0248 - accuracy: 0.9933 - val_loss: 0.0675 - val_accuracy: 0.9846\n",
            "Epoch 1483/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0248 - accuracy: 0.9944 - val_loss: 0.0668 - val_accuracy: 0.9838\n",
            "Epoch 1484/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0254 - accuracy: 0.9931 - val_loss: 0.0681 - val_accuracy: 0.9831\n",
            "Epoch 1485/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0251 - accuracy: 0.9936 - val_loss: 0.0680 - val_accuracy: 0.9838\n",
            "Epoch 1486/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0242 - accuracy: 0.9936 - val_loss: 0.0671 - val_accuracy: 0.9815\n",
            "Epoch 1487/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0248 - accuracy: 0.9946 - val_loss: 0.0668 - val_accuracy: 0.9846\n",
            "Epoch 1488/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0241 - accuracy: 0.9936 - val_loss: 0.0672 - val_accuracy: 0.9846\n",
            "Epoch 1489/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0247 - accuracy: 0.9933 - val_loss: 0.0683 - val_accuracy: 0.9838\n",
            "Epoch 1490/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0258 - accuracy: 0.9936 - val_loss: 0.0693 - val_accuracy: 0.9838\n",
            "Epoch 1491/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0251 - accuracy: 0.9938 - val_loss: 0.0675 - val_accuracy: 0.9846\n",
            "Epoch 1492/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0264 - accuracy: 0.9933 - val_loss: 0.0683 - val_accuracy: 0.9808\n",
            "Epoch 1493/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0244 - accuracy: 0.9936 - val_loss: 0.0692 - val_accuracy: 0.9846\n",
            "Epoch 1494/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0248 - accuracy: 0.9931 - val_loss: 0.0683 - val_accuracy: 0.9838\n",
            "Epoch 1495/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0263 - accuracy: 0.9928 - val_loss: 0.0677 - val_accuracy: 0.9846\n",
            "Epoch 1496/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0252 - accuracy: 0.9933 - val_loss: 0.0681 - val_accuracy: 0.9831\n",
            "Epoch 1497/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0257 - accuracy: 0.9944 - val_loss: 0.0690 - val_accuracy: 0.9846\n",
            "Epoch 1498/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0255 - accuracy: 0.9936 - val_loss: 0.0695 - val_accuracy: 0.9846\n",
            "Epoch 1499/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0244 - accuracy: 0.9938 - val_loss: 0.0675 - val_accuracy: 0.9838\n",
            "Epoch 1500/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0255 - accuracy: 0.9936 - val_loss: 0.0676 - val_accuracy: 0.9846\n",
            "Epoch 1501/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0252 - accuracy: 0.9931 - val_loss: 0.0680 - val_accuracy: 0.9838\n",
            "Epoch 1502/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0256 - accuracy: 0.9931 - val_loss: 0.0677 - val_accuracy: 0.9854\n",
            "Epoch 1503/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0246 - accuracy: 0.9938 - val_loss: 0.0689 - val_accuracy: 0.9854\n",
            "Epoch 1504/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0303 - accuracy: 0.9905 - val_loss: 0.0671 - val_accuracy: 0.9846\n",
            "Epoch 1505/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0268 - accuracy: 0.9928 - val_loss: 0.0692 - val_accuracy: 0.9823\n",
            "Epoch 1506/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0263 - accuracy: 0.9933 - val_loss: 0.0674 - val_accuracy: 0.9838\n",
            "Epoch 1507/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0264 - accuracy: 0.9928 - val_loss: 0.0711 - val_accuracy: 0.9846\n",
            "Epoch 1508/2000\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.0246 - accuracy: 0.9941 - val_loss: 0.0707 - val_accuracy: 0.9831\n",
            "Epoch 1509/2000\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.0262 - accuracy: 0.9931 - val_loss: 0.0691 - val_accuracy: 0.9846\n",
            "Epoch 1510/2000\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.0282 - accuracy: 0.9915 - val_loss: 0.0683 - val_accuracy: 0.9854\n",
            "Epoch 1511/2000\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.0254 - accuracy: 0.9938 - val_loss: 0.0679 - val_accuracy: 0.9831\n",
            "Epoch 1512/2000\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.0255 - accuracy: 0.9936 - val_loss: 0.0679 - val_accuracy: 0.9838\n",
            "Epoch 1513/2000\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0235 - accuracy: 0.9941 - val_loss: 0.0712 - val_accuracy: 0.9846\n",
            "Epoch 1514/2000\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0247 - accuracy: 0.9941 - val_loss: 0.0669 - val_accuracy: 0.9838\n",
            "Epoch 1515/2000\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 0.0253 - accuracy: 0.9938 - val_loss: 0.0680 - val_accuracy: 0.9854\n",
            "Epoch 1516/2000\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.0242 - accuracy: 0.9936 - val_loss: 0.0673 - val_accuracy: 0.9831\n",
            "Epoch 1517/2000\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0273 - accuracy: 0.9920 - val_loss: 0.0717 - val_accuracy: 0.9808\n",
            "Epoch 1518/2000\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0303 - accuracy: 0.9908 - val_loss: 0.0682 - val_accuracy: 0.9838\n",
            "Epoch 1519/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0266 - accuracy: 0.9926 - val_loss: 0.0690 - val_accuracy: 0.9838\n",
            "Epoch 1520/2000\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0250 - accuracy: 0.9931 - val_loss: 0.0702 - val_accuracy: 0.9854\n",
            "Epoch 1521/2000\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0246 - accuracy: 0.9936 - val_loss: 0.0685 - val_accuracy: 0.9838\n",
            "Epoch 1522/2000\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0237 - accuracy: 0.9938 - val_loss: 0.0694 - val_accuracy: 0.9846\n",
            "Epoch 1523/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0235 - accuracy: 0.9946 - val_loss: 0.0676 - val_accuracy: 0.9846\n",
            "Epoch 1524/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0247 - accuracy: 0.9938 - val_loss: 0.0684 - val_accuracy: 0.9838\n",
            "Epoch 1525/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0259 - accuracy: 0.9944 - val_loss: 0.0681 - val_accuracy: 0.9838\n",
            "Epoch 1526/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0242 - accuracy: 0.9936 - val_loss: 0.0674 - val_accuracy: 0.9854\n",
            "Epoch 1527/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0240 - accuracy: 0.9938 - val_loss: 0.0676 - val_accuracy: 0.9846\n",
            "Epoch 1528/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0238 - accuracy: 0.9938 - val_loss: 0.0690 - val_accuracy: 0.9838\n",
            "Epoch 1529/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0251 - accuracy: 0.9923 - val_loss: 0.0692 - val_accuracy: 0.9838\n",
            "Epoch 1530/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0242 - accuracy: 0.9931 - val_loss: 0.0696 - val_accuracy: 0.9846\n",
            "Epoch 1531/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0249 - accuracy: 0.9944 - val_loss: 0.0683 - val_accuracy: 0.9846\n",
            "Epoch 1532/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0243 - accuracy: 0.9941 - val_loss: 0.0696 - val_accuracy: 0.9838\n",
            "Epoch 1533/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0236 - accuracy: 0.9946 - val_loss: 0.0702 - val_accuracy: 0.9808\n",
            "Epoch 1534/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0282 - accuracy: 0.9913 - val_loss: 0.0689 - val_accuracy: 0.9838\n",
            "Epoch 1535/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0244 - accuracy: 0.9933 - val_loss: 0.0692 - val_accuracy: 0.9846\n",
            "Epoch 1536/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0244 - accuracy: 0.9936 - val_loss: 0.0680 - val_accuracy: 0.9846\n",
            "Epoch 1537/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0250 - accuracy: 0.9931 - val_loss: 0.0698 - val_accuracy: 0.9854\n",
            "Epoch 1538/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0245 - accuracy: 0.9936 - val_loss: 0.0699 - val_accuracy: 0.9846\n",
            "Epoch 1539/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0251 - accuracy: 0.9931 - val_loss: 0.0694 - val_accuracy: 0.9846\n",
            "Epoch 1540/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0239 - accuracy: 0.9933 - val_loss: 0.0685 - val_accuracy: 0.9838\n",
            "Epoch 1541/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0244 - accuracy: 0.9941 - val_loss: 0.0685 - val_accuracy: 0.9846\n",
            "Epoch 1542/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0241 - accuracy: 0.9944 - val_loss: 0.0681 - val_accuracy: 0.9846\n",
            "Epoch 1543/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0245 - accuracy: 0.9928 - val_loss: 0.0686 - val_accuracy: 0.9838\n",
            "Epoch 1544/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0254 - accuracy: 0.9918 - val_loss: 0.0690 - val_accuracy: 0.9838\n",
            "Epoch 1545/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0253 - accuracy: 0.9931 - val_loss: 0.0683 - val_accuracy: 0.9838\n",
            "Epoch 1546/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0250 - accuracy: 0.9936 - val_loss: 0.0689 - val_accuracy: 0.9846\n",
            "Epoch 1547/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0238 - accuracy: 0.9944 - val_loss: 0.0696 - val_accuracy: 0.9854\n",
            "Epoch 1548/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0267 - accuracy: 0.9918 - val_loss: 0.0699 - val_accuracy: 0.9862\n",
            "Epoch 1549/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0244 - accuracy: 0.9938 - val_loss: 0.0688 - val_accuracy: 0.9838\n",
            "Epoch 1550/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0245 - accuracy: 0.9944 - val_loss: 0.0692 - val_accuracy: 0.9846\n",
            "Epoch 1551/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0241 - accuracy: 0.9938 - val_loss: 0.0675 - val_accuracy: 0.9846\n",
            "Epoch 1552/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0244 - accuracy: 0.9941 - val_loss: 0.0692 - val_accuracy: 0.9831\n",
            "Epoch 1553/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0240 - accuracy: 0.9941 - val_loss: 0.0705 - val_accuracy: 0.9838\n",
            "Epoch 1554/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0241 - accuracy: 0.9936 - val_loss: 0.0703 - val_accuracy: 0.9846\n",
            "Epoch 1555/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0300 - accuracy: 0.9913 - val_loss: 0.0683 - val_accuracy: 0.9838\n",
            "Epoch 1556/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0235 - accuracy: 0.9944 - val_loss: 0.0689 - val_accuracy: 0.9838\n",
            "Epoch 1557/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0237 - accuracy: 0.9936 - val_loss: 0.0701 - val_accuracy: 0.9831\n",
            "Epoch 1558/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0236 - accuracy: 0.9941 - val_loss: 0.0672 - val_accuracy: 0.9838\n",
            "Epoch 1559/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0269 - accuracy: 0.9923 - val_loss: 0.0715 - val_accuracy: 0.9815\n",
            "Epoch 1560/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0311 - accuracy: 0.9892 - val_loss: 0.0766 - val_accuracy: 0.9808\n",
            "Epoch 1561/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0288 - accuracy: 0.9895 - val_loss: 0.0716 - val_accuracy: 0.9854\n",
            "Epoch 1562/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0245 - accuracy: 0.9941 - val_loss: 0.0714 - val_accuracy: 0.9838\n",
            "Epoch 1563/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0233 - accuracy: 0.9946 - val_loss: 0.0693 - val_accuracy: 0.9846\n",
            "Epoch 1564/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0235 - accuracy: 0.9938 - val_loss: 0.0679 - val_accuracy: 0.9838\n",
            "Epoch 1565/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0238 - accuracy: 0.9941 - val_loss: 0.0693 - val_accuracy: 0.9838\n",
            "Epoch 1566/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0235 - accuracy: 0.9951 - val_loss: 0.0703 - val_accuracy: 0.9838\n",
            "Epoch 1567/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0263 - accuracy: 0.9936 - val_loss: 0.0712 - val_accuracy: 0.9808\n",
            "Epoch 1568/2000\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.0268 - accuracy: 0.9936 - val_loss: 0.0707 - val_accuracy: 0.9831\n",
            "Epoch 1569/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0247 - accuracy: 0.9941 - val_loss: 0.0682 - val_accuracy: 0.9838\n",
            "Epoch 1570/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0245 - accuracy: 0.9936 - val_loss: 0.0698 - val_accuracy: 0.9838\n",
            "Epoch 1571/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0238 - accuracy: 0.9946 - val_loss: 0.0701 - val_accuracy: 0.9838\n",
            "Epoch 1572/2000\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.0237 - accuracy: 0.9938 - val_loss: 0.0693 - val_accuracy: 0.9838\n",
            "Epoch 1573/2000\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0251 - accuracy: 0.9946 - val_loss: 0.0713 - val_accuracy: 0.9846\n",
            "Epoch 1574/2000\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.0252 - accuracy: 0.9928 - val_loss: 0.0698 - val_accuracy: 0.9846\n",
            "Epoch 1575/2000\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.0239 - accuracy: 0.9933 - val_loss: 0.0714 - val_accuracy: 0.9838\n",
            "Epoch 1576/2000\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.0227 - accuracy: 0.9949 - val_loss: 0.0699 - val_accuracy: 0.9831\n",
            "Epoch 1577/2000\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.0241 - accuracy: 0.9936 - val_loss: 0.0703 - val_accuracy: 0.9838\n",
            "Epoch 1578/2000\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0233 - accuracy: 0.9938 - val_loss: 0.0694 - val_accuracy: 0.9838\n",
            "Epoch 1579/2000\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.0242 - accuracy: 0.9938 - val_loss: 0.0789 - val_accuracy: 0.9838\n",
            "Epoch 1580/2000\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.0302 - accuracy: 0.9908 - val_loss: 0.0818 - val_accuracy: 0.9823\n",
            "Epoch 1581/2000\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.0280 - accuracy: 0.9915 - val_loss: 0.0730 - val_accuracy: 0.9846\n",
            "Epoch 1582/2000\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 0.0278 - accuracy: 0.9915 - val_loss: 0.0690 - val_accuracy: 0.9838\n",
            "Epoch 1583/2000\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.0235 - accuracy: 0.9944 - val_loss: 0.0696 - val_accuracy: 0.9808\n",
            "Epoch 1584/2000\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.0244 - accuracy: 0.9931 - val_loss: 0.0685 - val_accuracy: 0.9838\n",
            "Epoch 1585/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0255 - accuracy: 0.9931 - val_loss: 0.0722 - val_accuracy: 0.9838\n",
            "Epoch 1586/2000\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0269 - accuracy: 0.9926 - val_loss: 0.0826 - val_accuracy: 0.9823\n",
            "Epoch 1587/2000\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0302 - accuracy: 0.9905 - val_loss: 0.0734 - val_accuracy: 0.9838\n",
            "Epoch 1588/2000\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.0283 - accuracy: 0.9923 - val_loss: 0.0697 - val_accuracy: 0.9831\n",
            "Epoch 1589/2000\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.0253 - accuracy: 0.9933 - val_loss: 0.0707 - val_accuracy: 0.9838\n",
            "Epoch 1590/2000\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0247 - accuracy: 0.9926 - val_loss: 0.0719 - val_accuracy: 0.9808\n",
            "Epoch 1591/2000\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.0239 - accuracy: 0.9938 - val_loss: 0.0711 - val_accuracy: 0.9838\n",
            "Epoch 1592/2000\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.0261 - accuracy: 0.9933 - val_loss: 0.0777 - val_accuracy: 0.9831\n",
            "Epoch 1593/2000\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.0240 - accuracy: 0.9936 - val_loss: 0.0695 - val_accuracy: 0.9838\n",
            "Epoch 1594/2000\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0235 - accuracy: 0.9946 - val_loss: 0.0706 - val_accuracy: 0.9808\n",
            "Epoch 1595/2000\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 0.0261 - accuracy: 0.9931 - val_loss: 0.0711 - val_accuracy: 0.9808\n",
            "Epoch 1596/2000\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.0273 - accuracy: 0.9923 - val_loss: 0.0717 - val_accuracy: 0.9838\n",
            "Epoch 1597/2000\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 0.0248 - accuracy: 0.9938 - val_loss: 0.0717 - val_accuracy: 0.9838\n",
            "Epoch 1598/2000\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.0243 - accuracy: 0.9933 - val_loss: 0.0711 - val_accuracy: 0.9846\n",
            "Epoch 1599/2000\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.0250 - accuracy: 0.9936 - val_loss: 0.0733 - val_accuracy: 0.9838\n",
            "Epoch 1600/2000\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 0.0250 - accuracy: 0.9928 - val_loss: 0.0719 - val_accuracy: 0.9854\n",
            "Epoch 1601/2000\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.0253 - accuracy: 0.9933 - val_loss: 0.0680 - val_accuracy: 0.9838\n",
            "Epoch 1602/2000\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0231 - accuracy: 0.9941 - val_loss: 0.0709 - val_accuracy: 0.9854\n",
            "Epoch 1603/2000\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0281 - accuracy: 0.9918 - val_loss: 0.0798 - val_accuracy: 0.9831\n",
            "Epoch 1604/2000\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0266 - accuracy: 0.9926 - val_loss: 0.0742 - val_accuracy: 0.9846\n",
            "Epoch 1605/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0264 - accuracy: 0.9923 - val_loss: 0.0693 - val_accuracy: 0.9838\n",
            "Epoch 1606/2000\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.0235 - accuracy: 0.9941 - val_loss: 0.0691 - val_accuracy: 0.9838\n",
            "Epoch 1607/2000\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0236 - accuracy: 0.9938 - val_loss: 0.0724 - val_accuracy: 0.9854\n",
            "Epoch 1608/2000\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.0253 - accuracy: 0.9936 - val_loss: 0.0709 - val_accuracy: 0.9862\n",
            "Epoch 1609/2000\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.0240 - accuracy: 0.9936 - val_loss: 0.0768 - val_accuracy: 0.9838\n",
            "Epoch 1610/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0267 - accuracy: 0.9928 - val_loss: 0.0757 - val_accuracy: 0.9846\n",
            "Epoch 1611/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0249 - accuracy: 0.9941 - val_loss: 0.0697 - val_accuracy: 0.9838\n",
            "Epoch 1612/2000\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 0.0242 - accuracy: 0.9949 - val_loss: 0.0697 - val_accuracy: 0.9838\n",
            "Epoch 1613/2000\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0250 - accuracy: 0.9923 - val_loss: 0.0722 - val_accuracy: 0.9838\n",
            "Epoch 1614/2000\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 0.0245 - accuracy: 0.9933 - val_loss: 0.0701 - val_accuracy: 0.9838\n",
            "Epoch 1615/2000\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0251 - accuracy: 0.9928 - val_loss: 0.0703 - val_accuracy: 0.9838\n",
            "Epoch 1616/2000\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0232 - accuracy: 0.9938 - val_loss: 0.0718 - val_accuracy: 0.9838\n",
            "Epoch 1617/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0243 - accuracy: 0.9938 - val_loss: 0.0695 - val_accuracy: 0.9823\n",
            "Epoch 1618/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0228 - accuracy: 0.9946 - val_loss: 0.0705 - val_accuracy: 0.9854\n",
            "Epoch 1619/2000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0237 - accuracy: 0.9936 - val_loss: 0.0699 - val_accuracy: 0.9838\n",
            "Epoch 1620/2000\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.0232 - accuracy: 0.9933 - val_loss: 0.0691 - val_accuracy: 0.9838\n",
            "Epoch 1621/2000\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0232 - accuracy: 0.9928 - val_loss: 0.0704 - val_accuracy: 0.9838\n",
            "Epoch 1622/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0231 - accuracy: 0.9936 - val_loss: 0.0704 - val_accuracy: 0.9838\n",
            "Epoch 1623/2000\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0256 - accuracy: 0.9915 - val_loss: 0.0720 - val_accuracy: 0.9808\n",
            "Epoch 1624/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0279 - accuracy: 0.9923 - val_loss: 0.0709 - val_accuracy: 0.9838\n",
            "Epoch 1625/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0300 - accuracy: 0.9910 - val_loss: 0.0738 - val_accuracy: 0.9808\n",
            "Epoch 1626/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0304 - accuracy: 0.9910 - val_loss: 0.0704 - val_accuracy: 0.9838\n",
            "Epoch 1627/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0292 - accuracy: 0.9910 - val_loss: 0.0789 - val_accuracy: 0.9838\n",
            "Epoch 1628/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0247 - accuracy: 0.9928 - val_loss: 0.0737 - val_accuracy: 0.9831\n",
            "Epoch 1629/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0253 - accuracy: 0.9931 - val_loss: 0.0706 - val_accuracy: 0.9846\n",
            "Epoch 1630/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0225 - accuracy: 0.9944 - val_loss: 0.0757 - val_accuracy: 0.9838\n",
            "Epoch 1631/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0249 - accuracy: 0.9933 - val_loss: 0.0708 - val_accuracy: 0.9838\n",
            "Epoch 1632/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0239 - accuracy: 0.9938 - val_loss: 0.0704 - val_accuracy: 0.9838\n",
            "Epoch 1633/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0244 - accuracy: 0.9936 - val_loss: 0.0709 - val_accuracy: 0.9838\n",
            "Epoch 1634/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0240 - accuracy: 0.9938 - val_loss: 0.0715 - val_accuracy: 0.9846\n",
            "Epoch 1635/2000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0237 - accuracy: 0.9941 - val_loss: 0.0738 - val_accuracy: 0.9846\n",
            "Epoch 1636/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0266 - accuracy: 0.9920 - val_loss: 0.0749 - val_accuracy: 0.9846\n",
            "Epoch 1637/2000\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0243 - accuracy: 0.9931 - val_loss: 0.0725 - val_accuracy: 0.9838\n",
            "Epoch 1638/2000\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0242 - accuracy: 0.9931 - val_loss: 0.0725 - val_accuracy: 0.9846\n",
            "Epoch 1639/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0264 - accuracy: 0.9931 - val_loss: 0.0779 - val_accuracy: 0.9846\n",
            "Epoch 1640/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0249 - accuracy: 0.9931 - val_loss: 0.0708 - val_accuracy: 0.9846\n",
            "Epoch 1641/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0236 - accuracy: 0.9941 - val_loss: 0.0697 - val_accuracy: 0.9831\n",
            "Epoch 1642/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0244 - accuracy: 0.9933 - val_loss: 0.0710 - val_accuracy: 0.9823\n",
            "Epoch 1643/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0296 - accuracy: 0.9910 - val_loss: 0.0723 - val_accuracy: 0.9823\n",
            "Epoch 1644/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0267 - accuracy: 0.9920 - val_loss: 0.0718 - val_accuracy: 0.9838\n",
            "Epoch 1645/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0261 - accuracy: 0.9920 - val_loss: 0.0824 - val_accuracy: 0.9838\n",
            "Epoch 1646/2000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0278 - accuracy: 0.9918 - val_loss: 0.0732 - val_accuracy: 0.9846\n",
            "Epoch 1647/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0243 - accuracy: 0.9933 - val_loss: 0.0719 - val_accuracy: 0.9838\n",
            "Epoch 1648/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0236 - accuracy: 0.9933 - val_loss: 0.0701 - val_accuracy: 0.9846\n",
            "Epoch 1649/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0239 - accuracy: 0.9933 - val_loss: 0.0694 - val_accuracy: 0.9846\n",
            "Epoch 1650/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0228 - accuracy: 0.9944 - val_loss: 0.0702 - val_accuracy: 0.9823\n",
            "Epoch 1651/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0251 - accuracy: 0.9946 - val_loss: 0.0714 - val_accuracy: 0.9823\n",
            "Epoch 1652/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0320 - accuracy: 0.9895 - val_loss: 0.0696 - val_accuracy: 0.9846\n",
            "Epoch 1653/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0337 - accuracy: 0.9892 - val_loss: 0.0732 - val_accuracy: 0.9838\n",
            "Epoch 1654/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0343 - accuracy: 0.9905 - val_loss: 0.0805 - val_accuracy: 0.9831\n",
            "Epoch 1655/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0277 - accuracy: 0.9915 - val_loss: 0.0773 - val_accuracy: 0.9846\n",
            "Epoch 1656/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0265 - accuracy: 0.9920 - val_loss: 0.0741 - val_accuracy: 0.9838\n",
            "Epoch 1657/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0272 - accuracy: 0.9923 - val_loss: 0.0701 - val_accuracy: 0.9846\n",
            "Epoch 1658/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0284 - accuracy: 0.9920 - val_loss: 0.0709 - val_accuracy: 0.9838\n",
            "Epoch 1659/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0248 - accuracy: 0.9936 - val_loss: 0.0701 - val_accuracy: 0.9831\n",
            "Epoch 1660/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0231 - accuracy: 0.9944 - val_loss: 0.0703 - val_accuracy: 0.9838\n",
            "Epoch 1661/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0233 - accuracy: 0.9941 - val_loss: 0.0700 - val_accuracy: 0.9838\n",
            "Epoch 1662/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0240 - accuracy: 0.9936 - val_loss: 0.0690 - val_accuracy: 0.9846\n",
            "Epoch 1663/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0237 - accuracy: 0.9941 - val_loss: 0.0696 - val_accuracy: 0.9838\n",
            "Epoch 1664/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0233 - accuracy: 0.9941 - val_loss: 0.0722 - val_accuracy: 0.9838\n",
            "Epoch 1665/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0238 - accuracy: 0.9938 - val_loss: 0.0710 - val_accuracy: 0.9838\n",
            "Epoch 1666/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0249 - accuracy: 0.9946 - val_loss: 0.0705 - val_accuracy: 0.9838\n",
            "Epoch 1667/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0232 - accuracy: 0.9944 - val_loss: 0.0691 - val_accuracy: 0.9846\n",
            "Epoch 1668/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0236 - accuracy: 0.9938 - val_loss: 0.0724 - val_accuracy: 0.9838\n",
            "Epoch 1669/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0228 - accuracy: 0.9938 - val_loss: 0.0690 - val_accuracy: 0.9846\n",
            "Epoch 1670/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0238 - accuracy: 0.9936 - val_loss: 0.0687 - val_accuracy: 0.9838\n",
            "Epoch 1671/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0227 - accuracy: 0.9941 - val_loss: 0.0719 - val_accuracy: 0.9838\n",
            "Epoch 1672/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0241 - accuracy: 0.9931 - val_loss: 0.0709 - val_accuracy: 0.9831\n",
            "Epoch 1673/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0238 - accuracy: 0.9936 - val_loss: 0.0725 - val_accuracy: 0.9846\n",
            "Epoch 1674/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0252 - accuracy: 0.9931 - val_loss: 0.0737 - val_accuracy: 0.9838\n",
            "Epoch 1675/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0249 - accuracy: 0.9928 - val_loss: 0.0713 - val_accuracy: 0.9838\n",
            "Epoch 1676/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0243 - accuracy: 0.9949 - val_loss: 0.0687 - val_accuracy: 0.9838\n",
            "Epoch 1677/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0231 - accuracy: 0.9938 - val_loss: 0.0700 - val_accuracy: 0.9838\n",
            "Epoch 1678/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0240 - accuracy: 0.9941 - val_loss: 0.0698 - val_accuracy: 0.9854\n",
            "Epoch 1679/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0261 - accuracy: 0.9923 - val_loss: 0.0696 - val_accuracy: 0.9838\n",
            "Epoch 1680/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0227 - accuracy: 0.9944 - val_loss: 0.0705 - val_accuracy: 0.9838\n",
            "Epoch 1681/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0228 - accuracy: 0.9941 - val_loss: 0.0692 - val_accuracy: 0.9838\n",
            "Epoch 1682/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0235 - accuracy: 0.9941 - val_loss: 0.0800 - val_accuracy: 0.9831\n",
            "Epoch 1683/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0279 - accuracy: 0.9918 - val_loss: 0.0743 - val_accuracy: 0.9838\n",
            "Epoch 1684/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0234 - accuracy: 0.9946 - val_loss: 0.0698 - val_accuracy: 0.9846\n",
            "Epoch 1685/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0225 - accuracy: 0.9938 - val_loss: 0.0700 - val_accuracy: 0.9838\n",
            "Epoch 1686/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0227 - accuracy: 0.9944 - val_loss: 0.0706 - val_accuracy: 0.9838\n",
            "Epoch 1687/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0238 - accuracy: 0.9938 - val_loss: 0.0693 - val_accuracy: 0.9838\n",
            "Epoch 1688/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0250 - accuracy: 0.9941 - val_loss: 0.0730 - val_accuracy: 0.9854\n",
            "Epoch 1689/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0245 - accuracy: 0.9923 - val_loss: 0.0708 - val_accuracy: 0.9854\n",
            "Epoch 1690/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0263 - accuracy: 0.9928 - val_loss: 0.0704 - val_accuracy: 0.9838\n",
            "Epoch 1691/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0250 - accuracy: 0.9928 - val_loss: 0.0698 - val_accuracy: 0.9831\n",
            "Epoch 1692/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0249 - accuracy: 0.9938 - val_loss: 0.0702 - val_accuracy: 0.9823\n",
            "Epoch 1693/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0233 - accuracy: 0.9944 - val_loss: 0.0707 - val_accuracy: 0.9838\n",
            "Epoch 1694/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0241 - accuracy: 0.9926 - val_loss: 0.0720 - val_accuracy: 0.9846\n",
            "Epoch 1695/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0230 - accuracy: 0.9936 - val_loss: 0.0714 - val_accuracy: 0.9854\n",
            "Epoch 1696/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0233 - accuracy: 0.9944 - val_loss: 0.0690 - val_accuracy: 0.9846\n",
            "Epoch 1697/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0257 - accuracy: 0.9933 - val_loss: 0.0711 - val_accuracy: 0.9838\n",
            "Epoch 1698/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0238 - accuracy: 0.9931 - val_loss: 0.0698 - val_accuracy: 0.9838\n",
            "Epoch 1699/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0234 - accuracy: 0.9941 - val_loss: 0.0714 - val_accuracy: 0.9823\n",
            "Epoch 1700/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0282 - accuracy: 0.9928 - val_loss: 0.0796 - val_accuracy: 0.9792\n",
            "Epoch 1701/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0314 - accuracy: 0.9915 - val_loss: 0.0740 - val_accuracy: 0.9862\n",
            "Epoch 1702/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0318 - accuracy: 0.9895 - val_loss: 0.0886 - val_accuracy: 0.9808\n",
            "Epoch 1703/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0301 - accuracy: 0.9915 - val_loss: 0.0778 - val_accuracy: 0.9854\n",
            "Epoch 1704/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0269 - accuracy: 0.9920 - val_loss: 0.0759 - val_accuracy: 0.9800\n",
            "Epoch 1705/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0255 - accuracy: 0.9931 - val_loss: 0.0712 - val_accuracy: 0.9846\n",
            "Epoch 1706/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0266 - accuracy: 0.9931 - val_loss: 0.0725 - val_accuracy: 0.9838\n",
            "Epoch 1707/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0249 - accuracy: 0.9938 - val_loss: 0.0800 - val_accuracy: 0.9838\n",
            "Epoch 1708/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0268 - accuracy: 0.9918 - val_loss: 0.0735 - val_accuracy: 0.9838\n",
            "Epoch 1709/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0270 - accuracy: 0.9915 - val_loss: 0.0709 - val_accuracy: 0.9838\n",
            "Epoch 1710/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0249 - accuracy: 0.9928 - val_loss: 0.0706 - val_accuracy: 0.9846\n",
            "Epoch 1711/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0228 - accuracy: 0.9944 - val_loss: 0.0707 - val_accuracy: 0.9838\n",
            "Epoch 1712/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0234 - accuracy: 0.9936 - val_loss: 0.0746 - val_accuracy: 0.9800\n",
            "Epoch 1713/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0285 - accuracy: 0.9908 - val_loss: 0.0735 - val_accuracy: 0.9831\n",
            "Epoch 1714/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0258 - accuracy: 0.9926 - val_loss: 0.0746 - val_accuracy: 0.9831\n",
            "Epoch 1715/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0231 - accuracy: 0.9944 - val_loss: 0.0713 - val_accuracy: 0.9846\n",
            "Epoch 1716/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0237 - accuracy: 0.9936 - val_loss: 0.0715 - val_accuracy: 0.9838\n",
            "Epoch 1717/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0237 - accuracy: 0.9946 - val_loss: 0.0774 - val_accuracy: 0.9831\n",
            "Epoch 1718/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0266 - accuracy: 0.9918 - val_loss: 0.0726 - val_accuracy: 0.9846\n",
            "Epoch 1719/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0231 - accuracy: 0.9936 - val_loss: 0.0715 - val_accuracy: 0.9846\n",
            "Epoch 1720/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0238 - accuracy: 0.9941 - val_loss: 0.0738 - val_accuracy: 0.9846\n",
            "Epoch 1721/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0260 - accuracy: 0.9928 - val_loss: 0.0736 - val_accuracy: 0.9854\n",
            "Epoch 1722/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0249 - accuracy: 0.9933 - val_loss: 0.0701 - val_accuracy: 0.9846\n",
            "Epoch 1723/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0222 - accuracy: 0.9944 - val_loss: 0.0713 - val_accuracy: 0.9846\n",
            "Epoch 1724/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0232 - accuracy: 0.9949 - val_loss: 0.0718 - val_accuracy: 0.9846\n",
            "Epoch 1725/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0225 - accuracy: 0.9938 - val_loss: 0.0717 - val_accuracy: 0.9846\n",
            "Epoch 1726/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0223 - accuracy: 0.9941 - val_loss: 0.0713 - val_accuracy: 0.9854\n",
            "Epoch 1727/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0238 - accuracy: 0.9933 - val_loss: 0.0711 - val_accuracy: 0.9854\n",
            "Epoch 1728/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0219 - accuracy: 0.9951 - val_loss: 0.0713 - val_accuracy: 0.9846\n",
            "Epoch 1729/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0225 - accuracy: 0.9944 - val_loss: 0.0728 - val_accuracy: 0.9838\n",
            "Epoch 1730/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0227 - accuracy: 0.9936 - val_loss: 0.0701 - val_accuracy: 0.9838\n",
            "Epoch 1731/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0232 - accuracy: 0.9941 - val_loss: 0.0695 - val_accuracy: 0.9838\n",
            "Epoch 1732/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0228 - accuracy: 0.9946 - val_loss: 0.0703 - val_accuracy: 0.9846\n",
            "Epoch 1733/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0233 - accuracy: 0.9944 - val_loss: 0.0773 - val_accuracy: 0.9846\n",
            "Epoch 1734/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0291 - accuracy: 0.9908 - val_loss: 0.0702 - val_accuracy: 0.9846\n",
            "Epoch 1735/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0249 - accuracy: 0.9926 - val_loss: 0.0702 - val_accuracy: 0.9846\n",
            "Epoch 1736/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0226 - accuracy: 0.9941 - val_loss: 0.0710 - val_accuracy: 0.9831\n",
            "Epoch 1737/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0235 - accuracy: 0.9938 - val_loss: 0.0728 - val_accuracy: 0.9846\n",
            "Epoch 1738/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0225 - accuracy: 0.9944 - val_loss: 0.0724 - val_accuracy: 0.9838\n",
            "Epoch 1739/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0233 - accuracy: 0.9933 - val_loss: 0.0707 - val_accuracy: 0.9831\n",
            "Epoch 1740/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0233 - accuracy: 0.9936 - val_loss: 0.0695 - val_accuracy: 0.9846\n",
            "Epoch 1741/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0235 - accuracy: 0.9933 - val_loss: 0.0704 - val_accuracy: 0.9838\n",
            "Epoch 1742/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0229 - accuracy: 0.9946 - val_loss: 0.0697 - val_accuracy: 0.9838\n",
            "Epoch 1743/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0228 - accuracy: 0.9941 - val_loss: 0.0732 - val_accuracy: 0.9846\n",
            "Epoch 1744/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0233 - accuracy: 0.9941 - val_loss: 0.0701 - val_accuracy: 0.9846\n",
            "Epoch 1745/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0221 - accuracy: 0.9949 - val_loss: 0.0751 - val_accuracy: 0.9838\n",
            "Epoch 1746/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0243 - accuracy: 0.9926 - val_loss: 0.0716 - val_accuracy: 0.9838\n",
            "Epoch 1747/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0248 - accuracy: 0.9936 - val_loss: 0.0711 - val_accuracy: 0.9838\n",
            "Epoch 1748/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0249 - accuracy: 0.9931 - val_loss: 0.0703 - val_accuracy: 0.9838\n",
            "Epoch 1749/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0227 - accuracy: 0.9941 - val_loss: 0.0710 - val_accuracy: 0.9831\n",
            "Epoch 1750/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0223 - accuracy: 0.9946 - val_loss: 0.0713 - val_accuracy: 0.9846\n",
            "Epoch 1751/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0238 - accuracy: 0.9941 - val_loss: 0.0697 - val_accuracy: 0.9846\n",
            "Epoch 1752/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0226 - accuracy: 0.9933 - val_loss: 0.0702 - val_accuracy: 0.9838\n",
            "Epoch 1753/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0229 - accuracy: 0.9938 - val_loss: 0.0701 - val_accuracy: 0.9838\n",
            "Epoch 1754/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0227 - accuracy: 0.9938 - val_loss: 0.0720 - val_accuracy: 0.9846\n",
            "Epoch 1755/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0224 - accuracy: 0.9941 - val_loss: 0.0712 - val_accuracy: 0.9831\n",
            "Epoch 1756/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0230 - accuracy: 0.9944 - val_loss: 0.0714 - val_accuracy: 0.9846\n",
            "Epoch 1757/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0249 - accuracy: 0.9933 - val_loss: 0.0739 - val_accuracy: 0.9815\n",
            "Epoch 1758/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0264 - accuracy: 0.9920 - val_loss: 0.0744 - val_accuracy: 0.9800\n",
            "Epoch 1759/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0250 - accuracy: 0.9920 - val_loss: 0.0708 - val_accuracy: 0.9838\n",
            "Epoch 1760/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0246 - accuracy: 0.9936 - val_loss: 0.0762 - val_accuracy: 0.9846\n",
            "Epoch 1761/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0240 - accuracy: 0.9941 - val_loss: 0.0725 - val_accuracy: 0.9854\n",
            "Epoch 1762/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0230 - accuracy: 0.9941 - val_loss: 0.0703 - val_accuracy: 0.9838\n",
            "Epoch 1763/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0227 - accuracy: 0.9938 - val_loss: 0.0715 - val_accuracy: 0.9846\n",
            "Epoch 1764/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0224 - accuracy: 0.9941 - val_loss: 0.0796 - val_accuracy: 0.9838\n",
            "Epoch 1765/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0242 - accuracy: 0.9923 - val_loss: 0.0719 - val_accuracy: 0.9838\n",
            "Epoch 1766/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0227 - accuracy: 0.9941 - val_loss: 0.0713 - val_accuracy: 0.9846\n",
            "Epoch 1767/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0234 - accuracy: 0.9944 - val_loss: 0.0739 - val_accuracy: 0.9838\n",
            "Epoch 1768/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0235 - accuracy: 0.9944 - val_loss: 0.0691 - val_accuracy: 0.9838\n",
            "Epoch 1769/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0260 - accuracy: 0.9923 - val_loss: 0.0716 - val_accuracy: 0.9838\n",
            "Epoch 1770/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0234 - accuracy: 0.9933 - val_loss: 0.0725 - val_accuracy: 0.9854\n",
            "Epoch 1771/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0274 - accuracy: 0.9920 - val_loss: 0.0754 - val_accuracy: 0.9838\n",
            "Epoch 1772/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0243 - accuracy: 0.9928 - val_loss: 0.0782 - val_accuracy: 0.9838\n",
            "Epoch 1773/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0268 - accuracy: 0.9920 - val_loss: 0.0735 - val_accuracy: 0.9846\n",
            "Epoch 1774/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0250 - accuracy: 0.9923 - val_loss: 0.0716 - val_accuracy: 0.9838\n",
            "Epoch 1775/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0215 - accuracy: 0.9946 - val_loss: 0.0707 - val_accuracy: 0.9838\n",
            "Epoch 1776/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0256 - accuracy: 0.9933 - val_loss: 0.0735 - val_accuracy: 0.9846\n",
            "Epoch 1777/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0268 - accuracy: 0.9936 - val_loss: 0.0720 - val_accuracy: 0.9838\n",
            "Epoch 1778/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0230 - accuracy: 0.9938 - val_loss: 0.0707 - val_accuracy: 0.9838\n",
            "Epoch 1779/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0218 - accuracy: 0.9944 - val_loss: 0.0727 - val_accuracy: 0.9846\n",
            "Epoch 1780/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0232 - accuracy: 0.9944 - val_loss: 0.0692 - val_accuracy: 0.9846\n",
            "Epoch 1781/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0227 - accuracy: 0.9933 - val_loss: 0.0714 - val_accuracy: 0.9846\n",
            "Epoch 1782/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0224 - accuracy: 0.9946 - val_loss: 0.0727 - val_accuracy: 0.9846\n",
            "Epoch 1783/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0223 - accuracy: 0.9949 - val_loss: 0.0706 - val_accuracy: 0.9823\n",
            "Epoch 1784/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0237 - accuracy: 0.9946 - val_loss: 0.0723 - val_accuracy: 0.9846\n",
            "Epoch 1785/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0223 - accuracy: 0.9936 - val_loss: 0.0706 - val_accuracy: 0.9838\n",
            "Epoch 1786/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0225 - accuracy: 0.9944 - val_loss: 0.0734 - val_accuracy: 0.9838\n",
            "Epoch 1787/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0222 - accuracy: 0.9944 - val_loss: 0.0717 - val_accuracy: 0.9838\n",
            "Epoch 1788/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0240 - accuracy: 0.9928 - val_loss: 0.0694 - val_accuracy: 0.9846\n",
            "Epoch 1789/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0231 - accuracy: 0.9938 - val_loss: 0.0715 - val_accuracy: 0.9838\n",
            "Epoch 1790/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0230 - accuracy: 0.9941 - val_loss: 0.0740 - val_accuracy: 0.9838\n",
            "Epoch 1791/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0222 - accuracy: 0.9946 - val_loss: 0.0744 - val_accuracy: 0.9846\n",
            "Epoch 1792/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0224 - accuracy: 0.9949 - val_loss: 0.0721 - val_accuracy: 0.9846\n",
            "Epoch 1793/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0230 - accuracy: 0.9933 - val_loss: 0.0713 - val_accuracy: 0.9846\n",
            "Epoch 1794/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0242 - accuracy: 0.9933 - val_loss: 0.0735 - val_accuracy: 0.9823\n",
            "Epoch 1795/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0251 - accuracy: 0.9933 - val_loss: 0.0729 - val_accuracy: 0.9838\n",
            "Epoch 1796/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0221 - accuracy: 0.9936 - val_loss: 0.0747 - val_accuracy: 0.9846\n",
            "Epoch 1797/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0246 - accuracy: 0.9928 - val_loss: 0.0782 - val_accuracy: 0.9838\n",
            "Epoch 1798/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0241 - accuracy: 0.9926 - val_loss: 0.0749 - val_accuracy: 0.9831\n",
            "Epoch 1799/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0229 - accuracy: 0.9936 - val_loss: 0.0707 - val_accuracy: 0.9846\n",
            "Epoch 1800/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0228 - accuracy: 0.9949 - val_loss: 0.0709 - val_accuracy: 0.9846\n",
            "Epoch 1801/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0223 - accuracy: 0.9938 - val_loss: 0.0703 - val_accuracy: 0.9846\n",
            "Epoch 1802/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0242 - accuracy: 0.9931 - val_loss: 0.0729 - val_accuracy: 0.9846\n",
            "Epoch 1803/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0248 - accuracy: 0.9926 - val_loss: 0.0716 - val_accuracy: 0.9846\n",
            "Epoch 1804/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0230 - accuracy: 0.9949 - val_loss: 0.0696 - val_accuracy: 0.9846\n",
            "Epoch 1805/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0230 - accuracy: 0.9941 - val_loss: 0.0755 - val_accuracy: 0.9838\n",
            "Epoch 1806/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0224 - accuracy: 0.9938 - val_loss: 0.0730 - val_accuracy: 0.9831\n",
            "Epoch 1807/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0228 - accuracy: 0.9944 - val_loss: 0.0688 - val_accuracy: 0.9846\n",
            "Epoch 1808/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0257 - accuracy: 0.9926 - val_loss: 0.0711 - val_accuracy: 0.9831\n",
            "Epoch 1809/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0237 - accuracy: 0.9936 - val_loss: 0.0723 - val_accuracy: 0.9838\n",
            "Epoch 1810/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0231 - accuracy: 0.9944 - val_loss: 0.0737 - val_accuracy: 0.9854\n",
            "Epoch 1811/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0231 - accuracy: 0.9938 - val_loss: 0.0756 - val_accuracy: 0.9854\n",
            "Epoch 1812/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0236 - accuracy: 0.9936 - val_loss: 0.0766 - val_accuracy: 0.9846\n",
            "Epoch 1813/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0241 - accuracy: 0.9933 - val_loss: 0.0729 - val_accuracy: 0.9846\n",
            "Epoch 1814/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0245 - accuracy: 0.9926 - val_loss: 0.0717 - val_accuracy: 0.9838\n",
            "Epoch 1815/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0248 - accuracy: 0.9923 - val_loss: 0.0744 - val_accuracy: 0.9808\n",
            "Epoch 1816/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0241 - accuracy: 0.9931 - val_loss: 0.0738 - val_accuracy: 0.9815\n",
            "Epoch 1817/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0256 - accuracy: 0.9928 - val_loss: 0.0763 - val_accuracy: 0.9846\n",
            "Epoch 1818/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0251 - accuracy: 0.9926 - val_loss: 0.0816 - val_accuracy: 0.9838\n",
            "Epoch 1819/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0259 - accuracy: 0.9910 - val_loss: 0.0741 - val_accuracy: 0.9831\n",
            "Epoch 1820/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0234 - accuracy: 0.9936 - val_loss: 0.0720 - val_accuracy: 0.9838\n",
            "Epoch 1821/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0233 - accuracy: 0.9933 - val_loss: 0.0719 - val_accuracy: 0.9838\n",
            "Epoch 1822/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0226 - accuracy: 0.9936 - val_loss: 0.0718 - val_accuracy: 0.9838\n",
            "Epoch 1823/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0228 - accuracy: 0.9938 - val_loss: 0.0726 - val_accuracy: 0.9838\n",
            "Epoch 1824/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0232 - accuracy: 0.9941 - val_loss: 0.0722 - val_accuracy: 0.9838\n",
            "Epoch 1825/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0221 - accuracy: 0.9931 - val_loss: 0.0733 - val_accuracy: 0.9846\n",
            "Epoch 1826/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0222 - accuracy: 0.9946 - val_loss: 0.0713 - val_accuracy: 0.9838\n",
            "Epoch 1827/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0228 - accuracy: 0.9946 - val_loss: 0.0714 - val_accuracy: 0.9846\n",
            "Epoch 1828/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0235 - accuracy: 0.9946 - val_loss: 0.0747 - val_accuracy: 0.9808\n",
            "Epoch 1829/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0279 - accuracy: 0.9931 - val_loss: 0.0741 - val_accuracy: 0.9831\n",
            "Epoch 1830/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0290 - accuracy: 0.9910 - val_loss: 0.0918 - val_accuracy: 0.9792\n",
            "Epoch 1831/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0269 - accuracy: 0.9918 - val_loss: 0.0781 - val_accuracy: 0.9846\n",
            "Epoch 1832/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0289 - accuracy: 0.9908 - val_loss: 0.0729 - val_accuracy: 0.9838\n",
            "Epoch 1833/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0236 - accuracy: 0.9941 - val_loss: 0.0714 - val_accuracy: 0.9846\n",
            "Epoch 1834/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0222 - accuracy: 0.9936 - val_loss: 0.0737 - val_accuracy: 0.9846\n",
            "Epoch 1835/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0226 - accuracy: 0.9944 - val_loss: 0.0766 - val_accuracy: 0.9846\n",
            "Epoch 1836/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0224 - accuracy: 0.9938 - val_loss: 0.0791 - val_accuracy: 0.9838\n",
            "Epoch 1837/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0248 - accuracy: 0.9928 - val_loss: 0.0737 - val_accuracy: 0.9831\n",
            "Epoch 1838/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0220 - accuracy: 0.9938 - val_loss: 0.0722 - val_accuracy: 0.9846\n",
            "Epoch 1839/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0224 - accuracy: 0.9941 - val_loss: 0.0754 - val_accuracy: 0.9808\n",
            "Epoch 1840/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0250 - accuracy: 0.9923 - val_loss: 0.0744 - val_accuracy: 0.9838\n",
            "Epoch 1841/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0227 - accuracy: 0.9941 - val_loss: 0.0740 - val_accuracy: 0.9831\n",
            "Epoch 1842/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0230 - accuracy: 0.9941 - val_loss: 0.0793 - val_accuracy: 0.9846\n",
            "Epoch 1843/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0257 - accuracy: 0.9923 - val_loss: 0.0766 - val_accuracy: 0.9846\n",
            "Epoch 1844/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0248 - accuracy: 0.9928 - val_loss: 0.0782 - val_accuracy: 0.9823\n",
            "Epoch 1845/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0235 - accuracy: 0.9931 - val_loss: 0.0719 - val_accuracy: 0.9846\n",
            "Epoch 1846/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0249 - accuracy: 0.9931 - val_loss: 0.0749 - val_accuracy: 0.9838\n",
            "Epoch 1847/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0227 - accuracy: 0.9931 - val_loss: 0.0805 - val_accuracy: 0.9838\n",
            "Epoch 1848/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0257 - accuracy: 0.9918 - val_loss: 0.0770 - val_accuracy: 0.9838\n",
            "Epoch 1849/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0242 - accuracy: 0.9926 - val_loss: 0.0731 - val_accuracy: 0.9846\n",
            "Epoch 1850/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0226 - accuracy: 0.9946 - val_loss: 0.0723 - val_accuracy: 0.9846\n",
            "Epoch 1851/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0225 - accuracy: 0.9938 - val_loss: 0.0753 - val_accuracy: 0.9838\n",
            "Epoch 1852/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0216 - accuracy: 0.9956 - val_loss: 0.0721 - val_accuracy: 0.9838\n",
            "Epoch 1853/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0222 - accuracy: 0.9949 - val_loss: 0.0719 - val_accuracy: 0.9846\n",
            "Epoch 1854/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0227 - accuracy: 0.9936 - val_loss: 0.0739 - val_accuracy: 0.9831\n",
            "Epoch 1855/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0216 - accuracy: 0.9941 - val_loss: 0.0726 - val_accuracy: 0.9846\n",
            "Epoch 1856/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0223 - accuracy: 0.9949 - val_loss: 0.0715 - val_accuracy: 0.9838\n",
            "Epoch 1857/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0230 - accuracy: 0.9931 - val_loss: 0.0716 - val_accuracy: 0.9846\n",
            "Epoch 1858/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0219 - accuracy: 0.9944 - val_loss: 0.0732 - val_accuracy: 0.9838\n",
            "Epoch 1859/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0234 - accuracy: 0.9936 - val_loss: 0.0820 - val_accuracy: 0.9838\n",
            "Epoch 1860/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0243 - accuracy: 0.9933 - val_loss: 0.0767 - val_accuracy: 0.9838\n",
            "Epoch 1861/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0288 - accuracy: 0.9908 - val_loss: 0.0725 - val_accuracy: 0.9846\n",
            "Epoch 1862/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0266 - accuracy: 0.9923 - val_loss: 0.0739 - val_accuracy: 0.9846\n",
            "Epoch 1863/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0229 - accuracy: 0.9933 - val_loss: 0.0747 - val_accuracy: 0.9823\n",
            "Epoch 1864/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0250 - accuracy: 0.9923 - val_loss: 0.0754 - val_accuracy: 0.9838\n",
            "Epoch 1865/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0282 - accuracy: 0.9913 - val_loss: 0.0778 - val_accuracy: 0.9854\n",
            "Epoch 1866/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0247 - accuracy: 0.9918 - val_loss: 0.0829 - val_accuracy: 0.9838\n",
            "Epoch 1867/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0278 - accuracy: 0.9920 - val_loss: 0.0717 - val_accuracy: 0.9846\n",
            "Epoch 1868/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0256 - accuracy: 0.9918 - val_loss: 0.0743 - val_accuracy: 0.9808\n",
            "Epoch 1869/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0236 - accuracy: 0.9931 - val_loss: 0.0704 - val_accuracy: 0.9838\n",
            "Epoch 1870/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0234 - accuracy: 0.9933 - val_loss: 0.0806 - val_accuracy: 0.9838\n",
            "Epoch 1871/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0232 - accuracy: 0.9928 - val_loss: 0.0728 - val_accuracy: 0.9846\n",
            "Epoch 1872/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0233 - accuracy: 0.9938 - val_loss: 0.0731 - val_accuracy: 0.9815\n",
            "Epoch 1873/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0241 - accuracy: 0.9933 - val_loss: 0.0736 - val_accuracy: 0.9838\n",
            "Epoch 1874/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0239 - accuracy: 0.9926 - val_loss: 0.0740 - val_accuracy: 0.9838\n",
            "Epoch 1875/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0222 - accuracy: 0.9944 - val_loss: 0.0746 - val_accuracy: 0.9831\n",
            "Epoch 1876/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0213 - accuracy: 0.9944 - val_loss: 0.0730 - val_accuracy: 0.9838\n",
            "Epoch 1877/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0229 - accuracy: 0.9938 - val_loss: 0.0763 - val_accuracy: 0.9846\n",
            "Epoch 1878/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0247 - accuracy: 0.9931 - val_loss: 0.0732 - val_accuracy: 0.9846\n",
            "Epoch 1879/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0225 - accuracy: 0.9951 - val_loss: 0.0741 - val_accuracy: 0.9846\n",
            "Epoch 1880/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0222 - accuracy: 0.9949 - val_loss: 0.0717 - val_accuracy: 0.9831\n",
            "Epoch 1881/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0236 - accuracy: 0.9946 - val_loss: 0.0727 - val_accuracy: 0.9846\n",
            "Epoch 1882/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0220 - accuracy: 0.9938 - val_loss: 0.0764 - val_accuracy: 0.9838\n",
            "Epoch 1883/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0233 - accuracy: 0.9936 - val_loss: 0.0775 - val_accuracy: 0.9838\n",
            "Epoch 1884/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0238 - accuracy: 0.9931 - val_loss: 0.0728 - val_accuracy: 0.9838\n",
            "Epoch 1885/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0222 - accuracy: 0.9944 - val_loss: 0.0726 - val_accuracy: 0.9838\n",
            "Epoch 1886/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0239 - accuracy: 0.9936 - val_loss: 0.0725 - val_accuracy: 0.9831\n",
            "Epoch 1887/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0243 - accuracy: 0.9938 - val_loss: 0.0722 - val_accuracy: 0.9838\n",
            "Epoch 1888/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0242 - accuracy: 0.9923 - val_loss: 0.0832 - val_accuracy: 0.9838\n",
            "Epoch 1889/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0239 - accuracy: 0.9931 - val_loss: 0.0758 - val_accuracy: 0.9831\n",
            "Epoch 1890/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0221 - accuracy: 0.9951 - val_loss: 0.0727 - val_accuracy: 0.9838\n",
            "Epoch 1891/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0230 - accuracy: 0.9944 - val_loss: 0.0754 - val_accuracy: 0.9846\n",
            "Epoch 1892/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0230 - accuracy: 0.9931 - val_loss: 0.0776 - val_accuracy: 0.9838\n",
            "Epoch 1893/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0243 - accuracy: 0.9936 - val_loss: 0.0892 - val_accuracy: 0.9815\n",
            "Epoch 1894/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0312 - accuracy: 0.9902 - val_loss: 0.0806 - val_accuracy: 0.9838\n",
            "Epoch 1895/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0286 - accuracy: 0.9913 - val_loss: 0.0782 - val_accuracy: 0.9854\n",
            "Epoch 1896/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0266 - accuracy: 0.9923 - val_loss: 0.0744 - val_accuracy: 0.9846\n",
            "Epoch 1897/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0238 - accuracy: 0.9931 - val_loss: 0.0759 - val_accuracy: 0.9838\n",
            "Epoch 1898/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0223 - accuracy: 0.9944 - val_loss: 0.0744 - val_accuracy: 0.9846\n",
            "Epoch 1899/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0217 - accuracy: 0.9941 - val_loss: 0.0722 - val_accuracy: 0.9846\n",
            "Epoch 1900/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0228 - accuracy: 0.9938 - val_loss: 0.0717 - val_accuracy: 0.9846\n",
            "Epoch 1901/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0223 - accuracy: 0.9944 - val_loss: 0.0731 - val_accuracy: 0.9846\n",
            "Epoch 1902/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0216 - accuracy: 0.9944 - val_loss: 0.0721 - val_accuracy: 0.9846\n",
            "Epoch 1903/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0224 - accuracy: 0.9941 - val_loss: 0.0735 - val_accuracy: 0.9838\n",
            "Epoch 1904/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0215 - accuracy: 0.9941 - val_loss: 0.0800 - val_accuracy: 0.9846\n",
            "Epoch 1905/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0254 - accuracy: 0.9926 - val_loss: 0.0733 - val_accuracy: 0.9838\n",
            "Epoch 1906/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0270 - accuracy: 0.9910 - val_loss: 0.0718 - val_accuracy: 0.9838\n",
            "Epoch 1907/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0235 - accuracy: 0.9936 - val_loss: 0.0773 - val_accuracy: 0.9800\n",
            "Epoch 1908/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0261 - accuracy: 0.9913 - val_loss: 0.0729 - val_accuracy: 0.9846\n",
            "Epoch 1909/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0238 - accuracy: 0.9926 - val_loss: 0.0762 - val_accuracy: 0.9846\n",
            "Epoch 1910/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0229 - accuracy: 0.9938 - val_loss: 0.0771 - val_accuracy: 0.9838\n",
            "Epoch 1911/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0212 - accuracy: 0.9949 - val_loss: 0.0736 - val_accuracy: 0.9846\n",
            "Epoch 1912/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0216 - accuracy: 0.9941 - val_loss: 0.0757 - val_accuracy: 0.9838\n",
            "Epoch 1913/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0222 - accuracy: 0.9944 - val_loss: 0.0752 - val_accuracy: 0.9838\n",
            "Epoch 1914/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0220 - accuracy: 0.9949 - val_loss: 0.0736 - val_accuracy: 0.9831\n",
            "Epoch 1915/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0213 - accuracy: 0.9946 - val_loss: 0.0721 - val_accuracy: 0.9838\n",
            "Epoch 1916/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0220 - accuracy: 0.9941 - val_loss: 0.0744 - val_accuracy: 0.9838\n",
            "Epoch 1917/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0216 - accuracy: 0.9938 - val_loss: 0.0786 - val_accuracy: 0.9838\n",
            "Epoch 1918/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0236 - accuracy: 0.9933 - val_loss: 0.0727 - val_accuracy: 0.9846\n",
            "Epoch 1919/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0247 - accuracy: 0.9915 - val_loss: 0.0767 - val_accuracy: 0.9815\n",
            "Epoch 1920/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0230 - accuracy: 0.9928 - val_loss: 0.0740 - val_accuracy: 0.9846\n",
            "Epoch 1921/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0226 - accuracy: 0.9936 - val_loss: 0.0797 - val_accuracy: 0.9838\n",
            "Epoch 1922/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0248 - accuracy: 0.9926 - val_loss: 0.0763 - val_accuracy: 0.9831\n",
            "Epoch 1923/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0231 - accuracy: 0.9936 - val_loss: 0.0747 - val_accuracy: 0.9846\n",
            "Epoch 1924/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0218 - accuracy: 0.9946 - val_loss: 0.0712 - val_accuracy: 0.9838\n",
            "Epoch 1925/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0222 - accuracy: 0.9936 - val_loss: 0.0721 - val_accuracy: 0.9831\n",
            "Epoch 1926/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0229 - accuracy: 0.9946 - val_loss: 0.0727 - val_accuracy: 0.9846\n",
            "Epoch 1927/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0219 - accuracy: 0.9938 - val_loss: 0.0749 - val_accuracy: 0.9838\n",
            "Epoch 1928/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0229 - accuracy: 0.9941 - val_loss: 0.0762 - val_accuracy: 0.9846\n",
            "Epoch 1929/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0220 - accuracy: 0.9951 - val_loss: 0.0778 - val_accuracy: 0.9831\n",
            "Epoch 1930/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0251 - accuracy: 0.9926 - val_loss: 0.0744 - val_accuracy: 0.9846\n",
            "Epoch 1931/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0238 - accuracy: 0.9931 - val_loss: 0.0740 - val_accuracy: 0.9838\n",
            "Epoch 1932/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0226 - accuracy: 0.9941 - val_loss: 0.0736 - val_accuracy: 0.9831\n",
            "Epoch 1933/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0253 - accuracy: 0.9931 - val_loss: 0.0731 - val_accuracy: 0.9838\n",
            "Epoch 1934/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0252 - accuracy: 0.9920 - val_loss: 0.0718 - val_accuracy: 0.9838\n",
            "Epoch 1935/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0235 - accuracy: 0.9938 - val_loss: 0.0729 - val_accuracy: 0.9846\n",
            "Epoch 1936/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0215 - accuracy: 0.9944 - val_loss: 0.0788 - val_accuracy: 0.9838\n",
            "Epoch 1937/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0228 - accuracy: 0.9928 - val_loss: 0.0758 - val_accuracy: 0.9846\n",
            "Epoch 1938/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0221 - accuracy: 0.9941 - val_loss: 0.0716 - val_accuracy: 0.9846\n",
            "Epoch 1939/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0221 - accuracy: 0.9936 - val_loss: 0.0724 - val_accuracy: 0.9846\n",
            "Epoch 1940/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0217 - accuracy: 0.9936 - val_loss: 0.0749 - val_accuracy: 0.9854\n",
            "Epoch 1941/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0220 - accuracy: 0.9931 - val_loss: 0.0740 - val_accuracy: 0.9846\n",
            "Epoch 1942/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0231 - accuracy: 0.9926 - val_loss: 0.0731 - val_accuracy: 0.9815\n",
            "Epoch 1943/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0251 - accuracy: 0.9913 - val_loss: 0.0751 - val_accuracy: 0.9800\n",
            "Epoch 1944/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0341 - accuracy: 0.9890 - val_loss: 0.0782 - val_accuracy: 0.9838\n",
            "Epoch 1945/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0362 - accuracy: 0.9908 - val_loss: 0.1109 - val_accuracy: 0.9738\n",
            "Epoch 1946/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0317 - accuracy: 0.9902 - val_loss: 0.0760 - val_accuracy: 0.9838\n",
            "Epoch 1947/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0246 - accuracy: 0.9915 - val_loss: 0.0788 - val_accuracy: 0.9800\n",
            "Epoch 1948/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0249 - accuracy: 0.9931 - val_loss: 0.0755 - val_accuracy: 0.9846\n",
            "Epoch 1949/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0241 - accuracy: 0.9928 - val_loss: 0.0742 - val_accuracy: 0.9846\n",
            "Epoch 1950/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0230 - accuracy: 0.9931 - val_loss: 0.0780 - val_accuracy: 0.9838\n",
            "Epoch 1951/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0230 - accuracy: 0.9933 - val_loss: 0.0759 - val_accuracy: 0.9854\n",
            "Epoch 1952/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0217 - accuracy: 0.9936 - val_loss: 0.0747 - val_accuracy: 0.9846\n",
            "Epoch 1953/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0208 - accuracy: 0.9944 - val_loss: 0.0729 - val_accuracy: 0.9846\n",
            "Epoch 1954/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0210 - accuracy: 0.9949 - val_loss: 0.0746 - val_accuracy: 0.9854\n",
            "Epoch 1955/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0218 - accuracy: 0.9941 - val_loss: 0.0748 - val_accuracy: 0.9838\n",
            "Epoch 1956/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0218 - accuracy: 0.9946 - val_loss: 0.0746 - val_accuracy: 0.9846\n",
            "Epoch 1957/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0215 - accuracy: 0.9956 - val_loss: 0.0727 - val_accuracy: 0.9831\n",
            "Epoch 1958/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0223 - accuracy: 0.9938 - val_loss: 0.0733 - val_accuracy: 0.9846\n",
            "Epoch 1959/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0214 - accuracy: 0.9949 - val_loss: 0.0763 - val_accuracy: 0.9838\n",
            "Epoch 1960/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0206 - accuracy: 0.9949 - val_loss: 0.0737 - val_accuracy: 0.9838\n",
            "Epoch 1961/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0209 - accuracy: 0.9944 - val_loss: 0.0720 - val_accuracy: 0.9838\n",
            "Epoch 1962/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0233 - accuracy: 0.9938 - val_loss: 0.0784 - val_accuracy: 0.9846\n",
            "Epoch 1963/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0235 - accuracy: 0.9931 - val_loss: 0.0847 - val_accuracy: 0.9846\n",
            "Epoch 1964/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0283 - accuracy: 0.9913 - val_loss: 0.0759 - val_accuracy: 0.9838\n",
            "Epoch 1965/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0227 - accuracy: 0.9938 - val_loss: 0.0753 - val_accuracy: 0.9838\n",
            "Epoch 1966/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0217 - accuracy: 0.9938 - val_loss: 0.0730 - val_accuracy: 0.9838\n",
            "Epoch 1967/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0216 - accuracy: 0.9946 - val_loss: 0.0726 - val_accuracy: 0.9846\n",
            "Epoch 1968/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0226 - accuracy: 0.9933 - val_loss: 0.0739 - val_accuracy: 0.9846\n",
            "Epoch 1969/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0226 - accuracy: 0.9931 - val_loss: 0.0728 - val_accuracy: 0.9838\n",
            "Epoch 1970/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0220 - accuracy: 0.9946 - val_loss: 0.0745 - val_accuracy: 0.9838\n",
            "Epoch 1971/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0213 - accuracy: 0.9951 - val_loss: 0.0724 - val_accuracy: 0.9846\n",
            "Epoch 1972/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0229 - accuracy: 0.9933 - val_loss: 0.0719 - val_accuracy: 0.9838\n",
            "Epoch 1973/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0221 - accuracy: 0.9933 - val_loss: 0.0729 - val_accuracy: 0.9846\n",
            "Epoch 1974/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0230 - accuracy: 0.9933 - val_loss: 0.0750 - val_accuracy: 0.9831\n",
            "Epoch 1975/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0213 - accuracy: 0.9938 - val_loss: 0.0746 - val_accuracy: 0.9846\n",
            "Epoch 1976/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0218 - accuracy: 0.9946 - val_loss: 0.0755 - val_accuracy: 0.9838\n",
            "Epoch 1977/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0227 - accuracy: 0.9938 - val_loss: 0.0768 - val_accuracy: 0.9831\n",
            "Epoch 1978/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0222 - accuracy: 0.9941 - val_loss: 0.0750 - val_accuracy: 0.9846\n",
            "Epoch 1979/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0268 - accuracy: 0.9915 - val_loss: 0.0745 - val_accuracy: 0.9831\n",
            "Epoch 1980/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0310 - accuracy: 0.9902 - val_loss: 0.0734 - val_accuracy: 0.9846\n",
            "Epoch 1981/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0252 - accuracy: 0.9926 - val_loss: 0.0762 - val_accuracy: 0.9846\n",
            "Epoch 1982/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0213 - accuracy: 0.9949 - val_loss: 0.0719 - val_accuracy: 0.9838\n",
            "Epoch 1983/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0220 - accuracy: 0.9944 - val_loss: 0.0719 - val_accuracy: 0.9846\n",
            "Epoch 1984/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0225 - accuracy: 0.9938 - val_loss: 0.0806 - val_accuracy: 0.9838\n",
            "Epoch 1985/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0228 - accuracy: 0.9936 - val_loss: 0.0758 - val_accuracy: 0.9838\n",
            "Epoch 1986/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0211 - accuracy: 0.9954 - val_loss: 0.0749 - val_accuracy: 0.9838\n",
            "Epoch 1987/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0217 - accuracy: 0.9938 - val_loss: 0.0735 - val_accuracy: 0.9838\n",
            "Epoch 1988/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0206 - accuracy: 0.9946 - val_loss: 0.0750 - val_accuracy: 0.9838\n",
            "Epoch 1989/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0211 - accuracy: 0.9941 - val_loss: 0.0719 - val_accuracy: 0.9846\n",
            "Epoch 1990/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0222 - accuracy: 0.9936 - val_loss: 0.0779 - val_accuracy: 0.9838\n",
            "Epoch 1991/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0223 - accuracy: 0.9946 - val_loss: 0.0778 - val_accuracy: 0.9838\n",
            "Epoch 1992/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0221 - accuracy: 0.9933 - val_loss: 0.0738 - val_accuracy: 0.9838\n",
            "Epoch 1993/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0236 - accuracy: 0.9933 - val_loss: 0.0800 - val_accuracy: 0.9838\n",
            "Epoch 1994/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0237 - accuracy: 0.9931 - val_loss: 0.0859 - val_accuracy: 0.9846\n",
            "Epoch 1995/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0255 - accuracy: 0.9920 - val_loss: 0.0788 - val_accuracy: 0.9831\n",
            "Epoch 1996/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0231 - accuracy: 0.9928 - val_loss: 0.0742 - val_accuracy: 0.9831\n",
            "Epoch 1997/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0215 - accuracy: 0.9938 - val_loss: 0.0732 - val_accuracy: 0.9831\n",
            "Epoch 1998/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0205 - accuracy: 0.9949 - val_loss: 0.0751 - val_accuracy: 0.9838\n",
            "Epoch 1999/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0222 - accuracy: 0.9946 - val_loss: 0.0752 - val_accuracy: 0.9838\n",
            "Epoch 2000/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0221 - accuracy: 0.9936 - val_loss: 0.0768 - val_accuracy: 0.9846\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7oA9LiGD6Ut",
        "outputId": "ebc15d00-1344-4fcb-bafe-21e6c8860bb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "keras.callbacks.History"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(history.history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0Rnj48QEHHN",
        "outputId": "c1c3b003-f570-4795-dbd8-5ade21718919"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history.history"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIG-BLCxFuTd",
        "outputId": "4e83064d-dee7-467a-edf1-7c3668e5cba7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'loss': [0.04586596041917801,\n",
              "  0.04593214392662048,\n",
              "  0.04678725451231003,\n",
              "  0.04933018237352371,\n",
              "  0.050802942365407944,\n",
              "  0.05022408440709114,\n",
              "  0.04525724798440933,\n",
              "  0.044549405574798584,\n",
              "  0.04467582702636719,\n",
              "  0.04465862363576889,\n",
              "  0.04488714411854744,\n",
              "  0.04520538076758385,\n",
              "  0.0463637113571167,\n",
              "  0.044537536799907684,\n",
              "  0.04439716041088104,\n",
              "  0.04533035680651665,\n",
              "  0.04420927166938782,\n",
              "  0.044530995190143585,\n",
              "  0.045490700751543045,\n",
              "  0.04500162973999977,\n",
              "  0.044696539640426636,\n",
              "  0.043838098645210266,\n",
              "  0.04523202404379845,\n",
              "  0.044683054089546204,\n",
              "  0.047478560358285904,\n",
              "  0.04848482459783554,\n",
              "  0.0462162010371685,\n",
              "  0.04513702541589737,\n",
              "  0.044354964047670364,\n",
              "  0.044319309294223785,\n",
              "  0.044037602841854095,\n",
              "  0.04671639949083328,\n",
              "  0.04454914107918739,\n",
              "  0.04600914567708969,\n",
              "  0.04513731226325035,\n",
              "  0.043811455368995667,\n",
              "  0.04631218686699867,\n",
              "  0.043842069804668427,\n",
              "  0.04471017047762871,\n",
              "  0.046027157455682755,\n",
              "  0.046950582414865494,\n",
              "  0.044298622757196426,\n",
              "  0.04417071491479874,\n",
              "  0.0439862385392189,\n",
              "  0.044789087027311325,\n",
              "  0.04446680098772049,\n",
              "  0.043418120592832565,\n",
              "  0.04353263974189758,\n",
              "  0.04426044598221779,\n",
              "  0.044128403067588806,\n",
              "  0.04386090114712715,\n",
              "  0.048821501433849335,\n",
              "  0.057971976697444916,\n",
              "  0.04995705187320709,\n",
              "  0.0456327348947525,\n",
              "  0.04616272449493408,\n",
              "  0.04972456768155098,\n",
              "  0.04565294459462166,\n",
              "  0.04387801140546799,\n",
              "  0.04527107998728752,\n",
              "  0.046041082590818405,\n",
              "  0.04594196379184723,\n",
              "  0.04615573212504387,\n",
              "  0.04358859360218048,\n",
              "  0.04368623346090317,\n",
              "  0.04392587020993233,\n",
              "  0.044656217098236084,\n",
              "  0.04629819095134735,\n",
              "  0.0437723733484745,\n",
              "  0.04397617280483246,\n",
              "  0.04381808638572693,\n",
              "  0.04268442094326019,\n",
              "  0.04309196025133133,\n",
              "  0.043623197823762894,\n",
              "  0.04412451758980751,\n",
              "  0.04442897066473961,\n",
              "  0.04372661933302879,\n",
              "  0.046354539692401886,\n",
              "  0.046008896082639694,\n",
              "  0.04425272345542908,\n",
              "  0.04350186511874199,\n",
              "  0.045923370867967606,\n",
              "  0.04754526540637016,\n",
              "  0.04974319413304329,\n",
              "  0.0491487979888916,\n",
              "  0.04831196367740631,\n",
              "  0.05652911216020584,\n",
              "  0.05563761666417122,\n",
              "  0.05464006960391998,\n",
              "  0.049389783293008804,\n",
              "  0.049401458352804184,\n",
              "  0.04300566017627716,\n",
              "  0.04769918695092201,\n",
              "  0.05076516419649124,\n",
              "  0.04483320564031601,\n",
              "  0.043245937675237656,\n",
              "  0.04523821547627449,\n",
              "  0.04329681769013405,\n",
              "  0.04296094551682472,\n",
              "  0.04309999570250511,\n",
              "  0.04295594245195389,\n",
              "  0.04527955874800682,\n",
              "  0.04350770637392998,\n",
              "  0.04295838996767998,\n",
              "  0.04301101341843605,\n",
              "  0.042258840054273605,\n",
              "  0.0439511239528656,\n",
              "  0.04382628947496414,\n",
              "  0.04400484263896942,\n",
              "  0.043547261506319046,\n",
              "  0.042886387556791306,\n",
              "  0.044013481587171555,\n",
              "  0.043586887419223785,\n",
              "  0.04655507206916809,\n",
              "  0.04224797338247299,\n",
              "  0.04475647211074829,\n",
              "  0.04452940449118614,\n",
              "  0.043749917298555374,\n",
              "  0.04390431568026543,\n",
              "  0.04290888458490372,\n",
              "  0.042274992913007736,\n",
              "  0.04258282110095024,\n",
              "  0.042233653366565704,\n",
              "  0.04321346804499626,\n",
              "  0.042601872235536575,\n",
              "  0.04404418542981148,\n",
              "  0.04252550005912781,\n",
              "  0.04236392676830292,\n",
              "  0.04232938960194588,\n",
              "  0.04396211355924606,\n",
              "  0.04243646562099457,\n",
              "  0.04968666285276413,\n",
              "  0.047470685094594955,\n",
              "  0.04243939742445946,\n",
              "  0.04351787269115448,\n",
              "  0.05265666916966438,\n",
              "  0.044955577701330185,\n",
              "  0.04291926696896553,\n",
              "  0.0422864630818367,\n",
              "  0.04335152357816696,\n",
              "  0.044384073466062546,\n",
              "  0.043361276388168335,\n",
              "  0.04339111968874931,\n",
              "  0.04159972071647644,\n",
              "  0.04372819513082504,\n",
              "  0.04243920370936394,\n",
              "  0.046175334602594376,\n",
              "  0.042891547083854675,\n",
              "  0.0425749234855175,\n",
              "  0.042017869651317596,\n",
              "  0.043167874217033386,\n",
              "  0.04226303845643997,\n",
              "  0.043001241981983185,\n",
              "  0.04508841782808304,\n",
              "  0.043865084648132324,\n",
              "  0.04169512912631035,\n",
              "  0.04200820252299309,\n",
              "  0.04170020669698715,\n",
              "  0.04356779903173447,\n",
              "  0.046024490147829056,\n",
              "  0.04496792331337929,\n",
              "  0.043272241950035095,\n",
              "  0.041815515607595444,\n",
              "  0.04209033399820328,\n",
              "  0.044651731848716736,\n",
              "  0.046154506504535675,\n",
              "  0.04356031492352486,\n",
              "  0.041753921657800674,\n",
              "  0.04186319187283516,\n",
              "  0.04210476204752922,\n",
              "  0.04183964431285858,\n",
              "  0.044162556529045105,\n",
              "  0.045000623911619186,\n",
              "  0.044435251504182816,\n",
              "  0.04347216337919235,\n",
              "  0.0418376699090004,\n",
              "  0.04212448373436928,\n",
              "  0.0416550375521183,\n",
              "  0.04202154278755188,\n",
              "  0.042215798050165176,\n",
              "  0.04156968370079994,\n",
              "  0.042279571294784546,\n",
              "  0.04249182716012001,\n",
              "  0.04446804150938988,\n",
              "  0.042267631739377975,\n",
              "  0.04226786270737648,\n",
              "  0.04202740266919136,\n",
              "  0.042923152446746826,\n",
              "  0.04341675713658333,\n",
              "  0.04579010233283043,\n",
              "  0.04675325006246567,\n",
              "  0.04213975742459297,\n",
              "  0.04521702975034714,\n",
              "  0.04304422810673714,\n",
              "  0.041514843702316284,\n",
              "  0.04201473295688629,\n",
              "  0.04142541438341141,\n",
              "  0.04300084337592125,\n",
              "  0.04114995524287224,\n",
              "  0.04223048314452171,\n",
              "  0.041176311671733856,\n",
              "  0.04315228760242462,\n",
              "  0.041893552988767624,\n",
              "  0.04173361137509346,\n",
              "  0.0416596494615078,\n",
              "  0.042424410581588745,\n",
              "  0.043684713542461395,\n",
              "  0.04180869087576866,\n",
              "  0.041011128574609756,\n",
              "  0.041319865733385086,\n",
              "  0.04299985617399216,\n",
              "  0.04483918845653534,\n",
              "  0.04382368549704552,\n",
              "  0.04201376065611839,\n",
              "  0.042574550956487656,\n",
              "  0.04170345142483711,\n",
              "  0.05021079629659653,\n",
              "  0.04739455506205559,\n",
              "  0.04586486890912056,\n",
              "  0.043716318905353546,\n",
              "  0.04364187642931938,\n",
              "  0.04283149167895317,\n",
              "  0.048059482127428055,\n",
              "  0.042737506330013275,\n",
              "  0.04329686239361763,\n",
              "  0.044428929686546326,\n",
              "  0.041606444865465164,\n",
              "  0.04081370681524277,\n",
              "  0.043099239468574524,\n",
              "  0.04121871292591095,\n",
              "  0.04126354679465294,\n",
              "  0.04480062052607536,\n",
              "  0.048644356429576874,\n",
              "  0.04755978658795357,\n",
              "  0.04945987090468407,\n",
              "  0.041839350014925,\n",
              "  0.040832605212926865,\n",
              "  0.0460795983672142,\n",
              "  0.041328415274620056,\n",
              "  0.04113364592194557,\n",
              "  0.044956184923648834,\n",
              "  0.04516172036528587,\n",
              "  0.045203033834695816,\n",
              "  0.04376773163676262,\n",
              "  0.043395671993494034,\n",
              "  0.04238482937216759,\n",
              "  0.04129074513912201,\n",
              "  0.04330753907561302,\n",
              "  0.04146665334701538,\n",
              "  0.04160429909825325,\n",
              "  0.04103124514222145,\n",
              "  0.041966043412685394,\n",
              "  0.04357108101248741,\n",
              "  0.04609837010502815,\n",
              "  0.04445074871182442,\n",
              "  0.044217176735401154,\n",
              "  0.04092220216989517,\n",
              "  0.04121682420372963,\n",
              "  0.04155018925666809,\n",
              "  0.043256159871816635,\n",
              "  0.04143817350268364,\n",
              "  0.042175162583589554,\n",
              "  0.04289110004901886,\n",
              "  0.04319055378437042,\n",
              "  0.04225318506360054,\n",
              "  0.04170534387230873,\n",
              "  0.04126988351345062,\n",
              "  0.041459500789642334,\n",
              "  0.041239622980356216,\n",
              "  0.04020792990922928,\n",
              "  0.04091164842247963,\n",
              "  0.041846103966236115,\n",
              "  0.04030913487076759,\n",
              "  0.040625765919685364,\n",
              "  0.04125775396823883,\n",
              "  0.04130677506327629,\n",
              "  0.04288477078080177,\n",
              "  0.04031190276145935,\n",
              "  0.040599577128887177,\n",
              "  0.04294408857822418,\n",
              "  0.04398055374622345,\n",
              "  0.05324157699942589,\n",
              "  0.05061838775873184,\n",
              "  0.05289076641201973,\n",
              "  0.06381116807460785,\n",
              "  0.050239309668540955,\n",
              "  0.045248813927173615,\n",
              "  0.0425713025033474,\n",
              "  0.04082658886909485,\n",
              "  0.040531594306230545,\n",
              "  0.04225188121199608,\n",
              "  0.04458831623196602,\n",
              "  0.0420084111392498,\n",
              "  0.04180102422833443,\n",
              "  0.04035411775112152,\n",
              "  0.04021520912647247,\n",
              "  0.04148998111486435,\n",
              "  0.040913425385951996,\n",
              "  0.04092271625995636,\n",
              "  0.04106947407126427,\n",
              "  0.04021264240145683,\n",
              "  0.04461311548948288,\n",
              "  0.041861940175294876,\n",
              "  0.04067181795835495,\n",
              "  0.040475137531757355,\n",
              "  0.04211999848484993,\n",
              "  0.04113592952489853,\n",
              "  0.04106461629271507,\n",
              "  0.043303072452545166,\n",
              "  0.04040491208434105,\n",
              "  0.04081273078918457,\n",
              "  0.042506393045186996,\n",
              "  0.04081001877784729,\n",
              "  0.04015612602233887,\n",
              "  0.04068034514784813,\n",
              "  0.04191192239522934,\n",
              "  0.04275781288743019,\n",
              "  0.042860083281993866,\n",
              "  0.04135909304022789,\n",
              "  0.04056444391608238,\n",
              "  0.03999612480401993,\n",
              "  0.04063454642891884,\n",
              "  0.040564198046922684,\n",
              "  0.04045097529888153,\n",
              "  0.041515011340379715,\n",
              "  0.0410880371928215,\n",
              "  0.0418141670525074,\n",
              "  0.0403035432100296,\n",
              "  0.04240548983216286,\n",
              "  0.03991830721497536,\n",
              "  0.039971936494112015,\n",
              "  0.041058655828237534,\n",
              "  0.044715892523527145,\n",
              "  0.04028131440281868,\n",
              "  0.04085230454802513,\n",
              "  0.04095939174294472,\n",
              "  0.04389028623700142,\n",
              "  0.043310996145009995,\n",
              "  0.04200463742017746,\n",
              "  0.039870020002126694,\n",
              "  0.03995560109615326,\n",
              "  0.04393182694911957,\n",
              "  0.04240233451128006,\n",
              "  0.04303024336695671,\n",
              "  0.041544318199157715,\n",
              "  0.040637701749801636,\n",
              "  0.041390687227249146,\n",
              "  0.04020359367132187,\n",
              "  0.04000614583492279,\n",
              "  0.04268498718738556,\n",
              "  0.03982752934098244,\n",
              "  0.039503369480371475,\n",
              "  0.040007807314395905,\n",
              "  0.049031175673007965,\n",
              "  0.04767599701881409,\n",
              "  0.04923446848988533,\n",
              "  0.045589566230773926,\n",
              "  0.040381550788879395,\n",
              "  0.04451164975762367,\n",
              "  0.04243950918316841,\n",
              "  0.043014269322156906,\n",
              "  0.04024409130215645,\n",
              "  0.040462493896484375,\n",
              "  0.03949794918298721,\n",
              "  0.040139030665159225,\n",
              "  0.043545108288526535,\n",
              "  0.04574815556406975,\n",
              "  0.04255713149905205,\n",
              "  0.040093813091516495,\n",
              "  0.040739309042692184,\n",
              "  0.042412444949150085,\n",
              "  0.04179350286722183,\n",
              "  0.03963450342416763,\n",
              "  0.04064053297042847,\n",
              "  0.04091741517186165,\n",
              "  0.042692337185144424,\n",
              "  0.04224427416920662,\n",
              "  0.0418623611330986,\n",
              "  0.03998773545026779,\n",
              "  0.039969880133867264,\n",
              "  0.04060497134923935,\n",
              "  0.040516141802072525,\n",
              "  0.04077458754181862,\n",
              "  0.0449153371155262,\n",
              "  0.03990030288696289,\n",
              "  0.041972845792770386,\n",
              "  0.040948536247015,\n",
              "  0.04142351448535919,\n",
              "  0.041357383131980896,\n",
              "  0.039872296154499054,\n",
              "  0.04406353458762169,\n",
              "  0.039879683405160904,\n",
              "  0.04006902500987053,\n",
              "  0.04172073304653168,\n",
              "  0.04246099293231964,\n",
              "  0.04066409170627594,\n",
              "  0.03960109502077103,\n",
              "  0.040768951177597046,\n",
              "  0.04033207148313522,\n",
              "  0.039552588015794754,\n",
              "  0.039386071264743805,\n",
              "  0.04010669142007828,\n",
              "  0.04083549231290817,\n",
              "  0.04116465151309967,\n",
              "  0.0406268872320652,\n",
              "  0.03926343098282814,\n",
              "  0.03939097747206688,\n",
              "  0.03987429291009903,\n",
              "  0.04051816090941429,\n",
              "  0.0401248075067997,\n",
              "  0.039427973330020905,\n",
              "  0.041437435895204544,\n",
              "  0.041040025651454926,\n",
              "  0.0412825308740139,\n",
              "  0.039228036999702454,\n",
              "  0.041294123977422714,\n",
              "  0.03953522443771362,\n",
              "  0.040675897151231766,\n",
              "  0.04080895334482193,\n",
              "  0.04025532305240631,\n",
              "  0.04173624515533447,\n",
              "  0.04134083911776543,\n",
              "  0.040866196155548096,\n",
              "  0.0446164570748806,\n",
              "  0.04490185156464577,\n",
              "  0.051162444055080414,\n",
              "  0.0468146912753582,\n",
              "  0.04622364044189453,\n",
              "  0.04518934339284897,\n",
              "  0.03994857892394066,\n",
              "  0.03951314464211464,\n",
              "  0.03982730209827423,\n",
              "  0.040193334221839905,\n",
              "  0.04057077690958977,\n",
              "  0.040252685546875,\n",
              "  0.0397142730653286,\n",
              "  0.039977338165044785,\n",
              "  0.03915804252028465,\n",
              "  0.04543537274003029,\n",
              "  0.04179292917251587,\n",
              "  0.04181688278913498,\n",
              "  0.04450473561882973,\n",
              "  0.04182960093021393,\n",
              "  0.04044145718216896,\n",
              "  0.040242914110422134,\n",
              "  0.04169989749789238,\n",
              "  0.04593835026025772,\n",
              "  0.03943733125925064,\n",
              "  0.04039216786623001,\n",
              "  0.04043353721499443,\n",
              "  0.039920032024383545,\n",
              "  0.04179154708981514,\n",
              "  0.038992468267679214,\n",
              "  0.04235653579235077,\n",
              "  0.04053729400038719,\n",
              "  0.03911809250712395,\n",
              "  0.03867242857813835,\n",
              "  0.039078135043382645,\n",
              "  0.039335910230875015,\n",
              "  0.039402734488248825,\n",
              "  0.04033844172954559,\n",
              "  0.03888943791389465,\n",
              "  0.03877235949039459,\n",
              "  0.03889264538884163,\n",
              "  0.03883791342377663,\n",
              "  0.03899755701422691,\n",
              "  0.04003110155463219,\n",
              "  0.03894183784723282,\n",
              "  0.0402362197637558,\n",
              "  0.04061485826969147,\n",
              "  0.039734382182359695,\n",
              "  0.039609163999557495,\n",
              "  0.03844834119081497,\n",
              "  0.03871343657374382,\n",
              "  0.03856934234499931,\n",
              "  0.03982679918408394,\n",
              "  0.038501493632793427,\n",
              "  0.03855547308921814,\n",
              "  0.03920644521713257,\n",
              "  0.039183396846055984,\n",
              "  0.04026002436876297,\n",
              "  0.038792677223682404,\n",
              "  0.039083968847990036,\n",
              "  0.039201319217681885,\n",
              "  0.040031060576438904,\n",
              "  0.04137101396918297,\n",
              "  0.03932054340839386,\n",
              "  0.039995212107896805,\n",
              "  0.04275808855891228,\n",
              "  0.045822251588106155,\n",
              "  0.04067617654800415,\n",
              "  0.040145017206668854,\n",
              "  0.03959530591964722,\n",
              "  0.04425249248743057,\n",
              "  0.04897310584783554,\n",
              "  0.046482037752866745,\n",
              "  0.04254932701587677,\n",
              "  0.04179173707962036,\n",
              "  0.039229121059179306,\n",
              "  0.03896782547235489,\n",
              "  0.03922170028090477,\n",
              "  0.03987693786621094,\n",
              "  0.040327347815036774,\n",
              "  0.03893880173563957,\n",
              "  0.039876583963632584,\n",
              "  0.04022236168384552,\n",
              "  0.040682680904865265,\n",
              "  0.04054838418960571,\n",
              "  0.04260679706931114,\n",
              "  0.042039912194013596,\n",
              "  0.040614645928144455,\n",
              "  0.03840501606464386,\n",
              "  0.038456130772829056,\n",
              "  0.038210246711969376,\n",
              "  0.039017610251903534,\n",
              "  0.03966271132230759,\n",
              "  0.04060005396604538,\n",
              "  0.04116382822394371,\n",
              "  0.04014673829078674,\n",
              "  0.03836730122566223,\n",
              "  0.037995293736457825,\n",
              "  0.037884704768657684,\n",
              "  0.0415092296898365,\n",
              "  0.04143548756837845,\n",
              "  0.041968513280153275,\n",
              "  0.038441624492406845,\n",
              "  0.04144567996263504,\n",
              "  0.04301242157816887,\n",
              "  0.04052741080522537,\n",
              "  0.03857237473130226,\n",
              "  0.03888262063264847,\n",
              "  0.03902813047170639,\n",
              "  0.037925101816654205,\n",
              "  0.038602057844400406,\n",
              "  0.037747256457805634,\n",
              "  0.0382734015583992,\n",
              "  0.03788018971681595,\n",
              "  0.038164183497428894,\n",
              "  0.04125116765499115,\n",
              "  0.0388234406709671,\n",
              "  0.03874306380748749,\n",
              "  0.04038567841053009,\n",
              "  0.03845106437802315,\n",
              "  0.04073503240942955,\n",
              "  0.039146631956100464,\n",
              "  0.038050778210163116,\n",
              "  0.03805431351065636,\n",
              "  0.03770458698272705,\n",
              "  0.038088977336883545,\n",
              "  0.04092524200677872,\n",
              "  0.038054924458265305,\n",
              "  0.03827610984444618,\n",
              "  0.038602691143751144,\n",
              "  0.0388496108353138,\n",
              "  0.03924091160297394,\n",
              "  0.03780490905046463,\n",
              "  0.03896036371588707,\n",
              "  0.040253181010484695,\n",
              "  0.03953316807746887,\n",
              "  0.03994821757078171,\n",
              "  0.0426110215485096,\n",
              "  0.03981976956129074,\n",
              "  0.03896050155162811,\n",
              "  0.03763662651181221,\n",
              "  0.03772002458572388,\n",
              "  0.03790735825896263,\n",
              "  0.03876712918281555,\n",
              "  0.03855982795357704,\n",
              "  0.03979741036891937,\n",
              "  0.03946273401379585,\n",
              "  0.03931403532624245,\n",
              "  0.04236253350973129,\n",
              "  0.03885328024625778,\n",
              "  0.03769989311695099,\n",
              "  0.03734724596142769,\n",
              "  0.03865332156419754,\n",
              "  0.0392029844224453,\n",
              "  0.03734898194670677,\n",
              "  0.037242185324430466,\n",
              "  0.0415319949388504,\n",
              "  0.03948007524013519,\n",
              "  0.040432918816804886,\n",
              "  0.039339251816272736,\n",
              "  0.03786912187933922,\n",
              "  0.037085793912410736,\n",
              "  0.037958916276693344,\n",
              "  0.039532370865345,\n",
              "  0.03773270547389984,\n",
              "  0.037444107234478,\n",
              "  0.038036178797483444,\n",
              "  0.03981003910303116,\n",
              "  0.03870493918657303,\n",
              "  0.03768867626786232,\n",
              "  0.03768172860145569,\n",
              "  0.041145581752061844,\n",
              "  0.03957993537187576,\n",
              "  0.0391840785741806,\n",
              "  0.04244790971279144,\n",
              "  0.0369473434984684,\n",
              "  0.03760907053947449,\n",
              "  0.03762234002351761,\n",
              "  0.03705265000462532,\n",
              "  0.037865009158849716,\n",
              "  0.03752477094531059,\n",
              "  0.03721918538212776,\n",
              "  0.03774121403694153,\n",
              "  0.037695035338401794,\n",
              "  0.03835812956094742,\n",
              "  0.03864605352282524,\n",
              "  0.04021472483873367,\n",
              "  0.03913344442844391,\n",
              "  0.03923379257321358,\n",
              "  0.0367279127240181,\n",
              "  0.03901594504714012,\n",
              "  0.03959719464182854,\n",
              "  0.0366191640496254,\n",
              "  0.037394747138023376,\n",
              "  0.035529546439647675,\n",
              "  0.04192762076854706,\n",
              "  0.040917664766311646,\n",
              "  0.03908241167664528,\n",
              "  0.043664444237947464,\n",
              "  0.038908813148736954,\n",
              "  0.03761456906795502,\n",
              "  0.04169590771198273,\n",
              "  0.03820354864001274,\n",
              "  0.03661990165710449,\n",
              "  0.03667498379945755,\n",
              "  0.03668305277824402,\n",
              "  0.036435216665267944,\n",
              "  0.037810299545526505,\n",
              "  0.037207283079624176,\n",
              "  0.03788566589355469,\n",
              "  0.038155894726514816,\n",
              "  0.03643688187003136,\n",
              "  0.03635532036423683,\n",
              "  0.036561157554388046,\n",
              "  0.03675542399287224,\n",
              "  0.03772113844752312,\n",
              "  0.03632326051592827,\n",
              "  0.0360201932489872,\n",
              "  0.0388704389333725,\n",
              "  0.037293121218681335,\n",
              "  0.037205446511507034,\n",
              "  0.03749566525220871,\n",
              "  0.03733237087726593,\n",
              "  0.03616151586174965,\n",
              "  0.03597453236579895,\n",
              "  0.03792766109108925,\n",
              "  0.03620974346995354,\n",
              "  0.03632449731230736,\n",
              "  0.036466870456933975,\n",
              "  0.03787508234381676,\n",
              "  0.040584497153759,\n",
              "  0.03849438950419426,\n",
              "  0.036633189767599106,\n",
              "  0.0366603285074234,\n",
              "  0.039152417331933975,\n",
              "  0.03843556344509125,\n",
              "  0.039387717843055725,\n",
              "  0.04030614718794823,\n",
              "  0.04020413011312485,\n",
              "  0.04170030355453491,\n",
              "  0.04638597369194031,\n",
              "  0.04062909260392189,\n",
              "  0.03964201360940933,\n",
              "  0.03742353245615959,\n",
              "  0.03597006946802139,\n",
              "  0.0361974872648716,\n",
              "  0.03608652576804161,\n",
              "  0.03624218329787254,\n",
              "  0.03713125362992287,\n",
              "  0.03596191480755806,\n",
              "  0.03606032952666283,\n",
              "  0.03807768225669861,\n",
              "  0.038118939846754074,\n",
              "  0.03869505226612091,\n",
              "  0.040056511759757996,\n",
              "  0.03771170601248741,\n",
              "  0.03974850848317146,\n",
              "  0.03612937778234482,\n",
              "  0.03556165099143982,\n",
              "  0.03573483228683472,\n",
              "  0.036047324538230896,\n",
              "  0.03545616939663887,\n",
              "  0.035389821976423264,\n",
              "  0.03548983111977577,\n",
              "  0.035250961780548096,\n",
              "  0.03578900918364525,\n",
              "  0.03534052148461342,\n",
              "  0.0358886644244194,\n",
              "  0.03734242543578148,\n",
              "  0.040646955370903015,\n",
              "  0.035686392337083817,\n",
              "  0.035386212170124054,\n",
              "  0.03677517920732498,\n",
              "  0.03816451132297516,\n",
              "  0.03601313754916191,\n",
              "  0.035116154700517654,\n",
              "  0.03756916522979736,\n",
              "  0.0388670414686203,\n",
              "  0.038868498057127,\n",
              "  0.04017813131213188,\n",
              "  0.03741161897778511,\n",
              "  0.03551102429628372,\n",
              "  0.03505215048789978,\n",
              "  0.03581469878554344,\n",
              "  0.03520993888378143,\n",
              "  0.03518632426857948,\n",
              "  0.035954445600509644,\n",
              "  0.036727823317050934,\n",
              "  0.03860686346888542,\n",
              "  0.03721465542912483,\n",
              "  0.03573817387223244,\n",
              "  0.03751308098435402,\n",
              "  0.03701680898666382,\n",
              "  0.04085651412606239,\n",
              "  0.03624682128429413,\n",
              "  0.03554420545697212,\n",
              "  0.03811485320329666,\n",
              "  0.03916290029883385,\n",
              "  0.044018860906362534,\n",
              "  0.036395490169525146,\n",
              "  0.035447023808956146,\n",
              "  0.0363859198987484,\n",
              "  0.035546235740184784,\n",
              "  0.036384642124176025,\n",
              "  0.03563655912876129,\n",
              "  0.036444101482629776,\n",
              "  0.04066068306565285,\n",
              "  0.036357540637254715,\n",
              "  0.03906433656811714,\n",
              "  0.03986627981066704,\n",
              "  0.03635123744606972,\n",
              "  0.03807351365685463,\n",
              "  0.037917882204055786,\n",
              "  0.03867405280470848,\n",
              "  0.035839296877384186,\n",
              "  0.035768914967775345,\n",
              "  0.03516099229454994,\n",
              "  0.03654654324054718,\n",
              "  0.03507090359926224,\n",
              "  0.03464507684111595,\n",
              "  0.03524656221270561,\n",
              "  0.03465160354971886,\n",
              "  0.0348040871322155,\n",
              "  0.03502751886844635,\n",
              "  0.03505634143948555,\n",
              "  0.0354711078107357,\n",
              "  0.03509534150362015,\n",
              "  0.03559998422861099,\n",
              "  0.03673771396279335,\n",
              "  0.04207979515194893,\n",
              "  0.037036847323179245,\n",
              "  0.03866755962371826,\n",
              "  0.03790765255689621,\n",
              "  0.03906043991446495,\n",
              "  0.03683483600616455,\n",
              "  0.03498728945851326,\n",
              "  0.03812939301133156,\n",
              "  0.036639172583818436,\n",
              "  0.037339504808187485,\n",
              "  0.037913285195827484,\n",
              "  0.035816144198179245,\n",
              "  0.03501465171575546,\n",
              "  0.035696856677532196,\n",
              "  0.03540796786546707,\n",
              "  0.03495415300130844,\n",
              "  0.0376192182302475,\n",
              "  0.03475918993353844,\n",
              "  0.03477311506867409,\n",
              "  0.03389160707592964,\n",
              "  0.033922839909791946,\n",
              "  0.03487326204776764,\n",
              "  0.034722134470939636,\n",
              "  0.03416616842150688,\n",
              "  0.03464160114526749,\n",
              "  0.034758057445287704,\n",
              "  0.034373603761196136,\n",
              "  0.03419618681073189,\n",
              "  0.03386416286230087,\n",
              "  0.03396553918719292,\n",
              "  0.03438350185751915,\n",
              "  0.03372286260128021,\n",
              "  0.03447128087282181,\n",
              "  0.03426733240485191,\n",
              "  0.0352017842233181,\n",
              "  0.03749731183052063,\n",
              "  0.034112561494112015,\n",
              "  0.03436383977532387,\n",
              "  0.034842271357774734,\n",
              "  0.037879012525081635,\n",
              "  0.04098813980817795,\n",
              "  0.03491545841097832,\n",
              "  0.03361363708972931,\n",
              "  0.03460848703980446,\n",
              "  0.0356571339070797,\n",
              "  0.035931218415498734,\n",
              "  0.0361112579703331,\n",
              "  0.03385607898235321,\n",
              "  0.033210474997758865,\n",
              "  0.03382234647870064,\n",
              "  0.03589823096990585,\n",
              "  0.034523461014032364,\n",
              "  0.033751409500837326,\n",
              "  0.03496060520410538,\n",
              "  0.03745482861995697,\n",
              "  0.03683880344033241,\n",
              "  0.036006081849336624,\n",
              "  0.034859079867601395,\n",
              "  0.033916909247636795,\n",
              "  0.03411220386624336,\n",
              "  0.03318221867084503,\n",
              "  0.03330707550048828,\n",
              "  0.03350731357932091,\n",
              "  0.033245012164115906,\n",
              "  0.03376479819417,\n",
              "  0.034059178084135056,\n",
              "  0.03475102409720421,\n",
              "  0.033810362219810486,\n",
              "  0.03294738009572029,\n",
              "  0.033279236406087875,\n",
              "  0.03268484026193619,\n",
              "  0.03396310284733772,\n",
              "  0.03551310673356056,\n",
              "  0.037921104580163956,\n",
              "  0.03673612326383591,\n",
              "  0.03603528067469597,\n",
              "  0.034737344831228256,\n",
              "  0.03266270086169243,\n",
              "  0.033713992685079575,\n",
              "  0.033577293157577515,\n",
              "  0.03278093785047531,\n",
              "  0.03401170298457146,\n",
              "  0.035558804869651794,\n",
              "  0.0349823422729969,\n",
              "  0.03387407585978508,\n",
              "  0.03477008640766144,\n",
              "  0.03575435280799866,\n",
              "  0.03727532550692558,\n",
              "  0.03710310906171799,\n",
              "  0.03429565951228142,\n",
              "  0.0344352088868618,\n",
              "  0.033972881734371185,\n",
              "  0.0335041880607605,\n",
              "  0.035000354051589966,\n",
              "  0.03543367236852646,\n",
              "  0.03402607515454292,\n",
              "  0.032702405005693436,\n",
              "  0.032994404435157776,\n",
              "  0.032884836196899414,\n",
              "  0.03405557945370674,\n",
              "  0.03319444879889488,\n",
              "  0.0324559360742569,\n",
              "  0.03221835941076279,\n",
              "  0.032407574355602264,\n",
              "  0.03246840834617615,\n",
              "  0.032389525324106216,\n",
              "  0.032494593411684036,\n",
              "  0.032622337341308594,\n",
              "  0.033565960824489594,\n",
              "  0.03349632769823074,\n",
              "  0.03349619358778,\n",
              "  0.03438788279891014,\n",
              "  0.034334179013967514,\n",
              "  0.03552146628499031,\n",
              "  0.03637847676873207,\n",
              "  0.035270702093839645,\n",
              "  0.03348951414227486,\n",
              "  0.03335261344909668,\n",
              "  0.032235078513622284,\n",
              "  0.03272819146513939,\n",
              "  0.03338374197483063,\n",
              "  0.036674413830041885,\n",
              "  0.037702735513448715,\n",
              "  0.03495388105511665,\n",
              "  0.0329044833779335,\n",
              "  0.03224720060825348,\n",
              "  0.03227696567773819,\n",
              "  0.03323860466480255,\n",
              "  0.03326505050063133,\n",
              "  0.03248090669512749,\n",
              "  0.031677160412073135,\n",
              "  0.03233760595321655,\n",
              "  0.031882144510746,\n",
              "  0.03197702392935753,\n",
              "  0.03267678618431091,\n",
              "  0.032613605260849,\n",
              "  0.03183502331376076,\n",
              "  0.0317327156662941,\n",
              "  0.03179863840341568,\n",
              "  0.03304683789610863,\n",
              "  0.03287758678197861,\n",
              "  0.03294701874256134,\n",
              "  0.0318448469042778,\n",
              "  0.0314520001411438,\n",
              "  0.033122751861810684,\n",
              "  0.03268176317214966,\n",
              "  0.03223700821399689,\n",
              "  0.03423400968313217,\n",
              "  0.03200865536928177,\n",
              "  0.03170837461948395,\n",
              "  0.03192618489265442,\n",
              "  0.03256832808256149,\n",
              "  0.03451666235923767,\n",
              "  0.03312424197793007,\n",
              "  0.03521502763032913,\n",
              "  0.03202841058373451,\n",
              "  0.031760502606630325,\n",
              "  0.03127056732773781,\n",
              "  0.032338667660951614,\n",
              "  0.03137790784239769,\n",
              "  0.031726688146591187,\n",
              "  0.031383827328681946,\n",
              "  0.03370802477002144,\n",
              "  0.033357080072164536,\n",
              "  0.034729983657598495,\n",
              "  0.03378793224692345,\n",
              "  0.03130211681127548,\n",
              "  0.03176242485642433,\n",
              "  0.031188711524009705,\n",
              "  0.03177988901734352,\n",
              "  0.03175153583288193,\n",
              "  0.03532978892326355,\n",
              "  0.03479600325226784,\n",
              "  0.0326320119202137,\n",
              "  0.031960465013980865,\n",
              "  0.030904944986104965,\n",
              "  0.032385531812906265,\n",
              "  0.032397832721471786,\n",
              "  0.032657016068696976,\n",
              "  0.03446352109313011,\n",
              "  0.03372267261147499,\n",
              "  0.03417133539915085,\n",
              "  0.03004440851509571,\n",
              "  0.034164946526288986,\n",
              "  0.03231993690133095,\n",
              "  0.031159022822976112,\n",
              "  0.03377489373087883,\n",
              "  0.0318528488278389,\n",
              "  0.03199900686740875,\n",
              "  0.03335732966661453,\n",
              "  0.03338969871401787,\n",
              "  0.034060679376125336,\n",
              "  0.03449185937643051,\n",
              "  0.0335872583091259,\n",
              "  0.03587824106216431,\n",
              "  0.037666402757167816,\n",
              "  0.03243742138147354,\n",
              "  0.03257910534739494,\n",
              "  0.031050661578774452,\n",
              "  0.03128761798143387,\n",
              "  0.031808335334062576,\n",
              "  0.031990278512239456,\n",
              "  0.03253820165991783,\n",
              "  0.0339311808347702,\n",
              "  0.031855180859565735,\n",
              "  0.033107977360486984,\n",
              "  0.03293416649103165,\n",
              "  0.031090551987290382,\n",
              "  0.032052572816610336,\n",
              "  0.03057708777487278,\n",
              "  0.03169657289981842,\n",
              "  0.031521789729595184,\n",
              "  0.031181223690509796,\n",
              "  0.031196802854537964,\n",
              "  0.032965585589408875,\n",
              "  0.03130076453089714,\n",
              "  0.03123706765472889,\n",
              "  0.03853597119450569,\n",
              "  0.04257882758975029,\n",
              "  0.04423904046416283,\n",
              "  0.04424550011754036,\n",
              "  0.03572486340999603,\n",
              "  0.030519623309373856,\n",
              "  0.03174387663602829,\n",
              "  0.03169029951095581,\n",
              "  0.03095061145722866,\n",
              "  0.030192906036973,\n",
              "  0.0326031856238842,\n",
              "  0.031072044745087624,\n",
              "  0.03219477832317352,\n",
              "  0.030505163595080376,\n",
              "  0.030048005282878876,\n",
              "  0.03136735409498215,\n",
              "  0.032034214586019516,\n",
              "  0.03301338106393814,\n",
              "  0.03205912560224533,\n",
              "  0.032224081456661224,\n",
              "  0.030757466331124306,\n",
              "  0.03033214621245861,\n",
              "  0.03148038312792778,\n",
              "  0.032815951853990555,\n",
              "  0.030085178092122078,\n",
              "  0.030856436118483543,\n",
              "  0.030994175001978874,\n",
              "  0.03106771595776081,\n",
              "  0.030346602201461792,\n",
              "  0.03187326714396477,\n",
              "  0.03511706367135048,\n",
              "  ...],\n",
              " 'accuracy': [0.9876828193664551,\n",
              "  0.988196074962616,\n",
              "  0.9866564273834229,\n",
              "  0.9856299757957458,\n",
              "  0.9848601222038269,\n",
              "  0.9858865737915039,\n",
              "  0.9866564273834229,\n",
              "  0.988196074962616,\n",
              "  0.987169623374939,\n",
              "  0.9879394173622131,\n",
              "  0.9869130253791809,\n",
              "  0.987169623374939,\n",
              "  0.9869130253791809,\n",
              "  0.987169623374939,\n",
              "  0.9887092709541321,\n",
              "  0.98639976978302,\n",
              "  0.9879394173622131,\n",
              "  0.988196074962616,\n",
              "  0.9866564273834229,\n",
              "  0.9866564273834229,\n",
              "  0.9866564273834229,\n",
              "  0.9889658689498901,\n",
              "  0.9866564273834229,\n",
              "  0.987169623374939,\n",
              "  0.9866564273834229,\n",
              "  0.9858865737915039,\n",
              "  0.9876828193664551,\n",
              "  0.98639976978302,\n",
              "  0.9879394173622131,\n",
              "  0.9876828193664551,\n",
              "  0.988196074962616,\n",
              "  0.9869130253791809,\n",
              "  0.988196074962616,\n",
              "  0.987426221370697,\n",
              "  0.9869130253791809,\n",
              "  0.9887092709541321,\n",
              "  0.9876828193664551,\n",
              "  0.987426221370697,\n",
              "  0.9869130253791809,\n",
              "  0.9866564273834229,\n",
              "  0.9856299757957458,\n",
              "  0.987426221370697,\n",
              "  0.988196074962616,\n",
              "  0.987169623374939,\n",
              "  0.9866564273834229,\n",
              "  0.9876828193664551,\n",
              "  0.9887092709541321,\n",
              "  0.9887092709541321,\n",
              "  0.987169623374939,\n",
              "  0.987426221370697,\n",
              "  0.987169623374939,\n",
              "  0.9851167798042297,\n",
              "  0.9833204746246338,\n",
              "  0.9856299757957458,\n",
              "  0.986143171787262,\n",
              "  0.986143171787262,\n",
              "  0.9869130253791809,\n",
              "  0.9856299757957458,\n",
              "  0.988452672958374,\n",
              "  0.986143171787262,\n",
              "  0.9866564273834229,\n",
              "  0.9869130253791809,\n",
              "  0.9876828193664551,\n",
              "  0.988196074962616,\n",
              "  0.9887092709541321,\n",
              "  0.988196074962616,\n",
              "  0.9876828193664551,\n",
              "  0.987169623374939,\n",
              "  0.988196074962616,\n",
              "  0.988196074962616,\n",
              "  0.9869130253791809,\n",
              "  0.9889658689498901,\n",
              "  0.988452672958374,\n",
              "  0.9869130253791809,\n",
              "  0.987426221370697,\n",
              "  0.98639976978302,\n",
              "  0.987169623374939,\n",
              "  0.9866564273834229,\n",
              "  0.9856299757957458,\n",
              "  0.9866564273834229,\n",
              "  0.987426221370697,\n",
              "  0.987426221370697,\n",
              "  0.9851167798042297,\n",
              "  0.9838337302207947,\n",
              "  0.98639976978302,\n",
              "  0.986143171787262,\n",
              "  0.9838337302207947,\n",
              "  0.9828072786331177,\n",
              "  0.9828072786331177,\n",
              "  0.9856299757957458,\n",
              "  0.9851167798042297,\n",
              "  0.9879394173622131,\n",
              "  0.987169623374939,\n",
              "  0.9851167798042297,\n",
              "  0.9879394173622131,\n",
              "  0.9876828193664551,\n",
              "  0.9869130253791809,\n",
              "  0.9869130253791809,\n",
              "  0.9876828193664551,\n",
              "  0.9876828193664551,\n",
              "  0.987169623374939,\n",
              "  0.98639976978302,\n",
              "  0.9879394173622131,\n",
              "  0.988196074962616,\n",
              "  0.9887092709541321,\n",
              "  0.9879394173622131,\n",
              "  0.987426221370697,\n",
              "  0.9879394173622131,\n",
              "  0.9869130253791809,\n",
              "  0.9879394173622131,\n",
              "  0.9879394173622131,\n",
              "  0.987426221370697,\n",
              "  0.9879394173622131,\n",
              "  0.9858865737915039,\n",
              "  0.988196074962616,\n",
              "  0.987169623374939,\n",
              "  0.9869130253791809,\n",
              "  0.9879394173622131,\n",
              "  0.9866564273834229,\n",
              "  0.9889658689498901,\n",
              "  0.9876828193664551,\n",
              "  0.987426221370697,\n",
              "  0.988452672958374,\n",
              "  0.9879394173622131,\n",
              "  0.9892224669456482,\n",
              "  0.9876828193664551,\n",
              "  0.9892224669456482,\n",
              "  0.9892224669456482,\n",
              "  0.988196074962616,\n",
              "  0.987426221370697,\n",
              "  0.9869130253791809,\n",
              "  0.9869130253791809,\n",
              "  0.9851167798042297,\n",
              "  0.9892224669456482,\n",
              "  0.9876828193664551,\n",
              "  0.9838337302207947,\n",
              "  0.9866564273834229,\n",
              "  0.9879394173622131,\n",
              "  0.988452672958374,\n",
              "  0.988196074962616,\n",
              "  0.98639976978302,\n",
              "  0.987426221370697,\n",
              "  0.987426221370697,\n",
              "  0.9876828193664551,\n",
              "  0.987426221370697,\n",
              "  0.987426221370697,\n",
              "  0.98639976978302,\n",
              "  0.9876828193664551,\n",
              "  0.9876828193664551,\n",
              "  0.9887092709541321,\n",
              "  0.9876828193664551,\n",
              "  0.987169623374939,\n",
              "  0.987169623374939,\n",
              "  0.9866564273834229,\n",
              "  0.9866564273834229,\n",
              "  0.988452672958374,\n",
              "  0.988452672958374,\n",
              "  0.988452672958374,\n",
              "  0.987169623374939,\n",
              "  0.988196074962616,\n",
              "  0.987426221370697,\n",
              "  0.9879394173622131,\n",
              "  0.988196074962616,\n",
              "  0.988452672958374,\n",
              "  0.9866564273834229,\n",
              "  0.9879394173622131,\n",
              "  0.988196074962616,\n",
              "  0.988452672958374,\n",
              "  0.988452672958374,\n",
              "  0.988196074962616,\n",
              "  0.988196074962616,\n",
              "  0.9876828193664551,\n",
              "  0.98639976978302,\n",
              "  0.9866564273834229,\n",
              "  0.98639976978302,\n",
              "  0.9887092709541321,\n",
              "  0.9879394173622131,\n",
              "  0.988196074962616,\n",
              "  0.9876828193664551,\n",
              "  0.9889658689498901,\n",
              "  0.988196074962616,\n",
              "  0.9879394173622131,\n",
              "  0.988196074962616,\n",
              "  0.988452672958374,\n",
              "  0.9889658689498901,\n",
              "  0.9879394173622131,\n",
              "  0.987426221370697,\n",
              "  0.9876828193664551,\n",
              "  0.9856299757957458,\n",
              "  0.987169623374939,\n",
              "  0.9866564273834229,\n",
              "  0.988196074962616,\n",
              "  0.987169623374939,\n",
              "  0.987426221370697,\n",
              "  0.988196074962616,\n",
              "  0.9889658689498901,\n",
              "  0.9887092709541321,\n",
              "  0.9887092709541321,\n",
              "  0.987426221370697,\n",
              "  0.988196074962616,\n",
              "  0.9889658689498901,\n",
              "  0.988196074962616,\n",
              "  0.988452672958374,\n",
              "  0.9892224669456482,\n",
              "  0.9879394173622131,\n",
              "  0.9876828193664551,\n",
              "  0.9876828193664551,\n",
              "  0.9894790649414062,\n",
              "  0.9887092709541321,\n",
              "  0.9887092709541321,\n",
              "  0.9876828193664551,\n",
              "  0.9876828193664551,\n",
              "  0.9879394173622131,\n",
              "  0.988196074962616,\n",
              "  0.987169623374939,\n",
              "  0.9879394173622131,\n",
              "  0.98639976978302,\n",
              "  0.9866564273834229,\n",
              "  0.9869130253791809,\n",
              "  0.987169623374939,\n",
              "  0.9869130253791809,\n",
              "  0.9889658689498901,\n",
              "  0.9853733777999878,\n",
              "  0.9879394173622131,\n",
              "  0.987426221370697,\n",
              "  0.9887092709541321,\n",
              "  0.988452672958374,\n",
              "  0.988452672958374,\n",
              "  0.9876828193664551,\n",
              "  0.988452672958374,\n",
              "  0.988196074962616,\n",
              "  0.987426221370697,\n",
              "  0.9853733777999878,\n",
              "  0.98639976978302,\n",
              "  0.9866564273834229,\n",
              "  0.9876828193664551,\n",
              "  0.9897357225418091,\n",
              "  0.98639976978302,\n",
              "  0.9889658689498901,\n",
              "  0.9889658689498901,\n",
              "  0.9876828193664551,\n",
              "  0.9879394173622131,\n",
              "  0.9879394173622131,\n",
              "  0.988452672958374,\n",
              "  0.987426221370697,\n",
              "  0.988452672958374,\n",
              "  0.9887092709541321,\n",
              "  0.988452672958374,\n",
              "  0.988196074962616,\n",
              "  0.988452672958374,\n",
              "  0.9892224669456482,\n",
              "  0.988196074962616,\n",
              "  0.9876828193664551,\n",
              "  0.9866564273834229,\n",
              "  0.9879394173622131,\n",
              "  0.987426221370697,\n",
              "  0.988196074962616,\n",
              "  0.988452672958374,\n",
              "  0.9897357225418091,\n",
              "  0.9866564273834229,\n",
              "  0.9889658689498901,\n",
              "  0.9879394173622131,\n",
              "  0.9879394173622131,\n",
              "  0.9876828193664551,\n",
              "  0.987426221370697,\n",
              "  0.9879394173622131,\n",
              "  0.988452672958374,\n",
              "  0.988196074962616,\n",
              "  0.9889658689498901,\n",
              "  0.9892224669456482,\n",
              "  0.9889658689498901,\n",
              "  0.987426221370697,\n",
              "  0.9892224669456482,\n",
              "  0.9889658689498901,\n",
              "  0.9894790649414062,\n",
              "  0.987169623374939,\n",
              "  0.9876828193664551,\n",
              "  0.9889658689498901,\n",
              "  0.9897357225418091,\n",
              "  0.987169623374939,\n",
              "  0.988452672958374,\n",
              "  0.9853733777999878,\n",
              "  0.9848601222038269,\n",
              "  0.9851167798042297,\n",
              "  0.9794713854789734,\n",
              "  0.9846035242080688,\n",
              "  0.9853733777999878,\n",
              "  0.9889658689498901,\n",
              "  0.9889658689498901,\n",
              "  0.987426221370697,\n",
              "  0.9887092709541321,\n",
              "  0.9876828193664551,\n",
              "  0.988452672958374,\n",
              "  0.9889658689498901,\n",
              "  0.9892224669456482,\n",
              "  0.9887092709541321,\n",
              "  0.9892224669456482,\n",
              "  0.9887092709541321,\n",
              "  0.9889658689498901,\n",
              "  0.987426221370697,\n",
              "  0.9897357225418091,\n",
              "  0.9876828193664551,\n",
              "  0.987169623374939,\n",
              "  0.9889658689498901,\n",
              "  0.9889658689498901,\n",
              "  0.9876828193664551,\n",
              "  0.988196074962616,\n",
              "  0.9897357225418091,\n",
              "  0.9876828193664551,\n",
              "  0.988196074962616,\n",
              "  0.9894790649414062,\n",
              "  0.988452672958374,\n",
              "  0.9894790649414062,\n",
              "  0.9892224669456482,\n",
              "  0.988452672958374,\n",
              "  0.988196074962616,\n",
              "  0.988196074962616,\n",
              "  0.988452672958374,\n",
              "  0.988196074962616,\n",
              "  0.988452672958374,\n",
              "  0.9894790649414062,\n",
              "  0.988196074962616,\n",
              "  0.9869130253791809,\n",
              "  0.9899923205375671,\n",
              "  0.9876828193664551,\n",
              "  0.9892224669456482,\n",
              "  0.987169623374939,\n",
              "  0.988196074962616,\n",
              "  0.987426221370697,\n",
              "  0.9887092709541321,\n",
              "  0.9887092709541321,\n",
              "  0.988452672958374,\n",
              "  0.987426221370697,\n",
              "  0.9887092709541321,\n",
              "  0.988196074962616,\n",
              "  0.9897357225418091,\n",
              "  0.9887092709541321,\n",
              "  0.987426221370697,\n",
              "  0.9887092709541321,\n",
              "  0.9897357225418091,\n",
              "  0.9899923205375671,\n",
              "  0.987169623374939,\n",
              "  0.988452672958374,\n",
              "  0.9876828193664551,\n",
              "  0.9887092709541321,\n",
              "  0.9894790649414062,\n",
              "  0.9889658689498901,\n",
              "  0.9894790649414062,\n",
              "  0.9899923205375671,\n",
              "  0.9876828193664551,\n",
              "  0.9889658689498901,\n",
              "  0.9897357225418091,\n",
              "  0.9889658689498901,\n",
              "  0.986143171787262,\n",
              "  0.9853733777999878,\n",
              "  0.9848601222038269,\n",
              "  0.98639976978302,\n",
              "  0.9887092709541321,\n",
              "  0.9876828193664551,\n",
              "  0.9876828193664551,\n",
              "  0.987426221370697,\n",
              "  0.9889658689498901,\n",
              "  0.9899923205375671,\n",
              "  0.9897357225418091,\n",
              "  0.9889658689498901,\n",
              "  0.987169623374939,\n",
              "  0.9866564273834229,\n",
              "  0.9897357225418091,\n",
              "  0.9887092709541321,\n",
              "  0.9887092709541321,\n",
              "  0.9879394173622131,\n",
              "  0.987426221370697,\n",
              "  0.9899923205375671,\n",
              "  0.9892224669456482,\n",
              "  0.9894790649414062,\n",
              "  0.9876828193664551,\n",
              "  0.988196074962616,\n",
              "  0.9887092709541321,\n",
              "  0.9897357225418091,\n",
              "  0.9892224669456482,\n",
              "  0.9894790649414062,\n",
              "  0.9879394173622131,\n",
              "  0.9887092709541321,\n",
              "  0.987169623374939,\n",
              "  0.9892224669456482,\n",
              "  0.9894790649414062,\n",
              "  0.9876828193664551,\n",
              "  0.988196074962616,\n",
              "  0.988196074962616,\n",
              "  0.9887092709541321,\n",
              "  0.987426221370697,\n",
              "  0.988452672958374,\n",
              "  0.9889658689498901,\n",
              "  0.988452672958374,\n",
              "  0.9876828193664551,\n",
              "  0.9887092709541321,\n",
              "  0.9899923205375671,\n",
              "  0.988196074962616,\n",
              "  0.9899923205375671,\n",
              "  0.9879394173622131,\n",
              "  0.9894790649414062,\n",
              "  0.9899923205375671,\n",
              "  0.9897357225418091,\n",
              "  0.9897357225418091,\n",
              "  0.988452672958374,\n",
              "  0.9894790649414062,\n",
              "  0.9902489185333252,\n",
              "  0.9889658689498901,\n",
              "  0.9876828193664551,\n",
              "  0.9889658689498901,\n",
              "  0.9907621145248413,\n",
              "  0.9876828193664551,\n",
              "  0.988452672958374,\n",
              "  0.988196074962616,\n",
              "  0.9897357225418091,\n",
              "  0.988452672958374,\n",
              "  0.9887092709541321,\n",
              "  0.9887092709541321,\n",
              "  0.9889658689498901,\n",
              "  0.9902489185333252,\n",
              "  0.988196074962616,\n",
              "  0.9887092709541321,\n",
              "  0.988452672958374,\n",
              "  0.98639976978302,\n",
              "  0.98639976978302,\n",
              "  0.9858865737915039,\n",
              "  0.98639976978302,\n",
              "  0.98639976978302,\n",
              "  0.987169623374939,\n",
              "  0.9889658689498901,\n",
              "  0.9894790649414062,\n",
              "  0.9892224669456482,\n",
              "  0.9889658689498901,\n",
              "  0.9897357225418091,\n",
              "  0.9887092709541321,\n",
              "  0.9894790649414062,\n",
              "  0.988196074962616,\n",
              "  0.988452672958374,\n",
              "  0.988452672958374,\n",
              "  0.988196074962616,\n",
              "  0.9876828193664551,\n",
              "  0.9869130253791809,\n",
              "  0.9892224669456482,\n",
              "  0.9889658689498901,\n",
              "  0.9892224669456482,\n",
              "  0.988452672958374,\n",
              "  0.9879394173622131,\n",
              "  0.9894790649414062,\n",
              "  0.988452672958374,\n",
              "  0.9894790649414062,\n",
              "  0.988452672958374,\n",
              "  0.9876828193664551,\n",
              "  0.9897357225418091,\n",
              "  0.987426221370697,\n",
              "  0.9892224669456482,\n",
              "  0.9907621145248413,\n",
              "  0.9899923205375671,\n",
              "  0.9889658689498901,\n",
              "  0.9887092709541321,\n",
              "  0.9892224669456482,\n",
              "  0.9899923205375671,\n",
              "  0.9897357225418091,\n",
              "  0.9902489185333252,\n",
              "  0.9902489185333252,\n",
              "  0.9899923205375671,\n",
              "  0.9894790649414062,\n",
              "  0.988452672958374,\n",
              "  0.9887092709541321,\n",
              "  0.988452672958374,\n",
              "  0.9889658689498901,\n",
              "  0.9897357225418091,\n",
              "  0.9892224669456482,\n",
              "  0.9907621145248413,\n",
              "  0.988196074962616,\n",
              "  0.9889658689498901,\n",
              "  0.9892224669456482,\n",
              "  0.9892224669456482,\n",
              "  0.9899923205375671,\n",
              "  0.988452672958374,\n",
              "  0.988452672958374,\n",
              "  0.9889658689498901,\n",
              "  0.9902489185333252,\n",
              "  0.9899923205375671,\n",
              "  0.9897357225418091,\n",
              "  0.9897357225418091,\n",
              "  0.987169623374939,\n",
              "  0.9892224669456482,\n",
              "  0.9899923205375671,\n",
              "  0.9869130253791809,\n",
              "  0.98639976978302,\n",
              "  0.987169623374939,\n",
              "  0.9897357225418091,\n",
              "  0.9894790649414062,\n",
              "  0.987169623374939,\n",
              "  0.9833204746246338,\n",
              "  0.986143171787262,\n",
              "  0.987426221370697,\n",
              "  0.9887092709541321,\n",
              "  0.9894790649414062,\n",
              "  0.9889658689498901,\n",
              "  0.9892224669456482,\n",
              "  0.9894790649414062,\n",
              "  0.9879394173622131,\n",
              "  0.9899923205375671,\n",
              "  0.9894790649414062,\n",
              "  0.9894790649414062,\n",
              "  0.9887092709541321,\n",
              "  0.9889658689498901,\n",
              "  0.988196074962616,\n",
              "  0.988196074962616,\n",
              "  0.9887092709541321,\n",
              "  0.988452672958374,\n",
              "  0.9905055165290833,\n",
              "  0.9902489185333252,\n",
              "  0.9887092709541321,\n",
              "  0.9899923205375671,\n",
              "  0.9889658689498901,\n",
              "  0.988452672958374,\n",
              "  0.9889658689498901,\n",
              "  0.9899923205375671,\n",
              "  0.9902489185333252,\n",
              "  0.9897357225418091,\n",
              "  0.9887092709541321,\n",
              "  0.9902489185333252,\n",
              "  0.9897357225418091,\n",
              "  0.9887092709541321,\n",
              "  0.9887092709541321,\n",
              "  0.9879394173622131,\n",
              "  0.9887092709541321,\n",
              "  0.9894790649414062,\n",
              "  0.9889658689498901,\n",
              "  0.9887092709541321,\n",
              "  0.9902489185333252,\n",
              "  0.9899923205375671,\n",
              "  0.9902489185333252,\n",
              "  0.9892224669456482,\n",
              "  0.9897357225418091,\n",
              "  0.9902489185333252,\n",
              "  0.9887092709541321,\n",
              "  0.9879394173622131,\n",
              "  0.9902489185333252,\n",
              "  0.9894790649414062,\n",
              "  0.9894790649414062,\n",
              "  0.988452672958374,\n",
              "  0.9894790649414062,\n",
              "  0.9899923205375671,\n",
              "  0.9894790649414062,\n",
              "  0.9899923205375671,\n",
              "  0.9902489185333252,\n",
              "  0.987169623374939,\n",
              "  0.9897357225418091,\n",
              "  0.9894790649414062,\n",
              "  0.9894790649414062,\n",
              "  0.9894790649414062,\n",
              "  0.9889658689498901,\n",
              "  0.9897357225418091,\n",
              "  0.9894790649414062,\n",
              "  0.9887092709541321,\n",
              "  0.9892224669456482,\n",
              "  0.988452672958374,\n",
              "  0.987169623374939,\n",
              "  0.9889658689498901,\n",
              "  0.9892224669456482,\n",
              "  0.9910187125205994,\n",
              "  0.9902489185333252,\n",
              "  0.9894790649414062,\n",
              "  0.9899923205375671,\n",
              "  0.9894790649414062,\n",
              "  0.9894790649414062,\n",
              "  0.9892224669456482,\n",
              "  0.9889658689498901,\n",
              "  0.9897357225418091,\n",
              "  0.9894790649414062,\n",
              "  0.9902489185333252,\n",
              "  0.9905055165290833,\n",
              "  0.9907621145248413,\n",
              "  0.9889658689498901,\n",
              "  0.9905055165290833,\n",
              "  0.9902489185333252,\n",
              "  0.988452672958374,\n",
              "  0.9892224669456482,\n",
              "  0.9879394173622131,\n",
              "  0.9899923205375671,\n",
              "  0.988196074962616,\n",
              "  0.9897357225418091,\n",
              "  0.9902489185333252,\n",
              "  0.988196074962616,\n",
              "  0.9892224669456482,\n",
              "  0.9899923205375671,\n",
              "  0.9879394173622131,\n",
              "  0.9892224669456482,\n",
              "  0.9887092709541321,\n",
              "  0.9907621145248413,\n",
              "  0.9910187125205994,\n",
              "  0.9876828193664551,\n",
              "  0.9892224669456482,\n",
              "  0.988196074962616,\n",
              "  0.988452672958374,\n",
              "  0.9910187125205994,\n",
              "  0.9905055165290833,\n",
              "  0.9897357225418091,\n",
              "  0.9912753105163574,\n",
              "  0.9907621145248413,\n",
              "  0.9915319681167603,\n",
              "  0.9907621145248413,\n",
              "  0.9907621145248413,\n",
              "  0.9894790649414062,\n",
              "  0.9894790649414062,\n",
              "  0.988196074962616,\n",
              "  0.9892224669456482,\n",
              "  0.9894790649414062,\n",
              "  0.9892224669456482,\n",
              "  0.9910187125205994,\n",
              "  0.9892224669456482,\n",
              "  0.9887092709541321,\n",
              "  0.9907621145248413,\n",
              "  0.9892224669456482,\n",
              "  0.9917885661125183,\n",
              "  0.9892224669456482,\n",
              "  0.9889658689498901,\n",
              "  0.9887092709541321,\n",
              "  0.9876828193664551,\n",
              "  0.988196074962616,\n",
              "  0.9905055165290833,\n",
              "  0.988196074962616,\n",
              "  0.9897357225418091,\n",
              "  0.9902489185333252,\n",
              "  0.9910187125205994,\n",
              "  0.9892224669456482,\n",
              "  0.9907621145248413,\n",
              "  0.9894790649414062,\n",
              "  0.9899923205375671,\n",
              "  0.9897357225418091,\n",
              "  0.9899923205375671,\n",
              "  0.9902489185333252,\n",
              "  0.9905055165290833,\n",
              "  0.9905055165290833,\n",
              "  0.9894790649414062,\n",
              "  0.9902489185333252,\n",
              "  0.9910187125205994,\n",
              "  0.9902489185333252,\n",
              "  0.9902489185333252,\n",
              "  0.9910187125205994,\n",
              "  0.9902489185333252,\n",
              "  0.9902489185333252,\n",
              "  0.9889658689498901,\n",
              "  0.9905055165290833,\n",
              "  0.9902489185333252,\n",
              "  0.9899923205375671,\n",
              "  0.9910187125205994,\n",
              "  0.9910187125205994,\n",
              "  0.9907621145248413,\n",
              "  0.9910187125205994,\n",
              "  0.9899923205375671,\n",
              "  0.9899923205375671,\n",
              "  0.9899923205375671,\n",
              "  0.9902489185333252,\n",
              "  0.9894790649414062,\n",
              "  0.9889658689498901,\n",
              "  0.9887092709541321,\n",
              "  0.9892224669456482,\n",
              "  0.9892224669456482,\n",
              "  0.9887092709541321,\n",
              "  0.9879394173622131,\n",
              "  0.9897357225418091,\n",
              "  0.988196074962616,\n",
              "  0.9905055165290833,\n",
              "  0.9907621145248413,\n",
              "  0.9899923205375671,\n",
              "  0.9907621145248413,\n",
              "  0.9894790649414062,\n",
              "  0.9899923205375671,\n",
              "  0.9910187125205994,\n",
              "  0.9912753105163574,\n",
              "  0.9894790649414062,\n",
              "  0.9897357225418091,\n",
              "  0.9894790649414062,\n",
              "  0.9894790649414062,\n",
              "  0.9897357225418091,\n",
              "  0.9897357225418091,\n",
              "  0.9905055165290833,\n",
              "  0.9907621145248413,\n",
              "  0.9912753105163574,\n",
              "  0.9897357225418091,\n",
              "  0.9912753105163574,\n",
              "  0.9907621145248413,\n",
              "  0.9912753105163574,\n",
              "  0.9912753105163574,\n",
              "  0.9910187125205994,\n",
              "  0.9910187125205994,\n",
              "  0.9915319681167603,\n",
              "  0.9905055165290833,\n",
              "  0.988452672958374,\n",
              "  0.9907621145248413,\n",
              "  0.9912753105163574,\n",
              "  0.9907621145248413,\n",
              "  0.9892224669456482,\n",
              "  0.9912753105163574,\n",
              "  0.9915319681167603,\n",
              "  0.9905055165290833,\n",
              "  0.9897357225418091,\n",
              "  0.9889658689498901,\n",
              "  0.9902489185333252,\n",
              "  0.9889658689498901,\n",
              "  0.9912753105163574,\n",
              "  0.9915319681167603,\n",
              "  0.9910187125205994,\n",
              "  0.9910187125205994,\n",
              "  0.9910187125205994,\n",
              "  0.9915319681167603,\n",
              "  0.9910187125205994,\n",
              "  0.9907621145248413,\n",
              "  0.9907621145248413,\n",
              "  0.9912753105163574,\n",
              "  0.9889658689498901,\n",
              "  0.9892224669456482,\n",
              "  0.988196074962616,\n",
              "  0.9902489185333252,\n",
              "  0.9902489185333252,\n",
              "  0.9897357225418091,\n",
              "  0.9899923205375671,\n",
              "  0.98639976978302,\n",
              "  0.9912753105163574,\n",
              "  0.9912753105163574,\n",
              "  0.9899923205375671,\n",
              "  0.9905055165290833,\n",
              "  0.9905055165290833,\n",
              "  0.9905055165290833,\n",
              "  0.9902489185333252,\n",
              "  0.9889658689498901,\n",
              "  0.9915319681167603,\n",
              "  0.9897357225418091,\n",
              "  0.9887092709541321,\n",
              "  0.9899923205375671,\n",
              "  0.9902489185333252,\n",
              "  0.9892224669456482,\n",
              "  0.9902489185333252,\n",
              "  0.9907621145248413,\n",
              "  0.9910187125205994,\n",
              "  0.9907621145248413,\n",
              "  0.9910187125205994,\n",
              "  0.9907621145248413,\n",
              "  0.9915319681167603,\n",
              "  0.9915319681167603,\n",
              "  0.9912753105163574,\n",
              "  0.9912753105163574,\n",
              "  0.9905055165290833,\n",
              "  0.9912753105163574,\n",
              "  0.9915319681167603,\n",
              "  0.9912753105163574,\n",
              "  0.9907621145248413,\n",
              "  0.9912753105163574,\n",
              "  0.9889658689498901,\n",
              "  0.9902489185333252,\n",
              "  0.9892224669456482,\n",
              "  0.9899923205375671,\n",
              "  0.9897357225418091,\n",
              "  0.9905055165290833,\n",
              "  0.9915319681167603,\n",
              "  0.9899923205375671,\n",
              "  0.9905055165290833,\n",
              "  0.9905055165290833,\n",
              "  0.9897357225418091,\n",
              "  0.9910187125205994,\n",
              "  0.9907621145248413,\n",
              "  0.9894790649414062,\n",
              "  0.9902489185333252,\n",
              "  0.9912753105163574,\n",
              "  0.9905055165290833,\n",
              "  0.9905055165290833,\n",
              "  0.9915319681167603,\n",
              "  0.9910187125205994,\n",
              "  0.9910187125205994,\n",
              "  0.9912753105163574,\n",
              "  0.9915319681167603,\n",
              "  0.9915319681167603,\n",
              "  0.9912753105163574,\n",
              "  0.9910187125205994,\n",
              "  0.9910187125205994,\n",
              "  0.9923017621040344,\n",
              "  0.9920451641082764,\n",
              "  0.9917885661125183,\n",
              "  0.9910187125205994,\n",
              "  0.9910187125205994,\n",
              "  0.9907621145248413,\n",
              "  0.9912753105163574,\n",
              "  0.9905055165290833,\n",
              "  0.9887092709541321,\n",
              "  0.9912753105163574,\n",
              "  0.9912753105163574,\n",
              "  0.9894790649414062,\n",
              "  0.9912753105163574,\n",
              "  0.9894790649414062,\n",
              "  0.9910187125205994,\n",
              "  0.9917885661125183,\n",
              "  0.9907621145248413,\n",
              "  0.9925583600997925,\n",
              "  0.9905055165290833,\n",
              "  0.9910187125205994,\n",
              "  0.9910187125205994,\n",
              "  0.9912753105163574,\n",
              "  0.9910187125205994,\n",
              "  0.9905055165290833,\n",
              "  0.9907621145248413,\n",
              "  0.9915319681167603,\n",
              "  0.9912753105163574,\n",
              "  0.9899923205375671,\n",
              "  0.9902489185333252,\n",
              "  0.9907621145248413,\n",
              "  0.9907621145248413,\n",
              "  0.9910187125205994,\n",
              "  0.9915319681167603,\n",
              "  0.9907621145248413,\n",
              "  0.9907621145248413,\n",
              "  0.9912753105163574,\n",
              "  0.9912753105163574,\n",
              "  0.9910187125205994,\n",
              "  0.9912753105163574,\n",
              "  0.9905055165290833,\n",
              "  0.9910187125205994,\n",
              "  0.9912753105163574,\n",
              "  0.9915319681167603,\n",
              "  0.9907621145248413,\n",
              "  0.9920451641082764,\n",
              "  0.9897357225418091,\n",
              "  0.9892224669456482,\n",
              "  0.9907621145248413,\n",
              "  0.9912753105163574,\n",
              "  0.9905055165290833,\n",
              "  0.9917885661125183,\n",
              "  0.9920451641082764,\n",
              "  0.9912753105163574,\n",
              "  0.9915319681167603,\n",
              "  0.9907621145248413,\n",
              "  0.9902489185333252,\n",
              "  0.9902489185333252,\n",
              "  0.9907621145248413,\n",
              "  0.9912753105163574,\n",
              "  0.9899923205375671,\n",
              "  0.9889658689498901,\n",
              "  0.9905055165290833,\n",
              "  0.9917885661125183,\n",
              "  0.9915319681167603,\n",
              "  0.9907621145248413,\n",
              "  0.9912753105163574,\n",
              "  0.9912753105163574,\n",
              "  0.9910187125205994,\n",
              "  0.9907621145248413,\n",
              "  0.9915319681167603,\n",
              "  0.9912753105163574,\n",
              "  0.9910187125205994,\n",
              "  0.9912753105163574,\n",
              "  0.9912753105163574,\n",
              "  0.9912753105163574,\n",
              "  0.9915319681167603,\n",
              "  0.9917885661125183,\n",
              "  0.9912753105163574,\n",
              "  0.9912753105163574,\n",
              "  0.9917885661125183,\n",
              "  0.9910187125205994,\n",
              "  0.9905055165290833,\n",
              "  0.9912753105163574,\n",
              "  0.9907621145248413,\n",
              "  0.9910187125205994,\n",
              "  0.9907621145248413,\n",
              "  0.9907621145248413,\n",
              "  0.9905055165290833,\n",
              "  0.9902489185333252,\n",
              "  0.9907621145248413,\n",
              "  0.9907621145248413,\n",
              "  0.9912753105163574,\n",
              "  0.9912753105163574,\n",
              "  0.9917885661125183,\n",
              "  0.9889658689498901,\n",
              "  0.9894790649414062,\n",
              "  0.9899923205375671,\n",
              "  0.9912753105163574,\n",
              "  0.9917885661125183,\n",
              "  0.9925583600997925,\n",
              "  0.9915319681167603,\n",
              "  0.9912753105163574,\n",
              "  0.9907621145248413,\n",
              "  0.9925583600997925,\n",
              "  0.9917885661125183,\n",
              "  0.9917885661125183,\n",
              "  0.9925583600997925,\n",
              "  0.9920451641082764,\n",
              "  0.9920451641082764,\n",
              "  0.9917885661125183,\n",
              "  0.9923017621040344,\n",
              "  0.9917885661125183,\n",
              "  0.9912753105163574,\n",
              "  0.9917885661125183,\n",
              "  0.9928149580955505,\n",
              "  0.9920451641082764,\n",
              "  0.9920451641082764,\n",
              "  0.9917885661125183,\n",
              "  0.9915319681167603,\n",
              "  0.9923017621040344,\n",
              "  0.9912753105163574,\n",
              "  0.9912753105163574,\n",
              "  0.9925583600997925,\n",
              "  0.9923017621040344,\n",
              "  0.9912753105163574,\n",
              "  0.9902489185333252,\n",
              "  0.9923017621040344,\n",
              "  0.9899923205375671,\n",
              "  0.9917885661125183,\n",
              "  0.9917885661125183,\n",
              "  0.9933282136917114,\n",
              "  0.9920451641082764,\n",
              "  0.9920451641082764,\n",
              "  0.9925583600997925,\n",
              "  0.9920451641082764,\n",
              "  0.9915319681167603,\n",
              "  0.9917885661125183,\n",
              "  0.9905055165290833,\n",
              "  0.9912753105163574,\n",
              "  0.9930716156959534,\n",
              "  0.9930716156959534,\n",
              "  0.9930716156959534,\n",
              "  0.9915319681167603,\n",
              "  0.9917885661125183,\n",
              "  0.9915319681167603,\n",
              "  0.9910187125205994,\n",
              "  0.9923017621040344,\n",
              "  0.9910187125205994,\n",
              "  0.9917885661125183,\n",
              "  0.9923017621040344,\n",
              "  0.9910187125205994,\n",
              "  0.9923017621040344,\n",
              "  0.9910187125205994,\n",
              "  0.9910187125205994,\n",
              "  0.9912753105163574,\n",
              "  0.9928149580955505,\n",
              "  0.9905055165290833,\n",
              "  0.9925583600997925,\n",
              "  0.9925583600997925,\n",
              "  0.9915319681167603,\n",
              "  0.9920451641082764,\n",
              "  0.9907621145248413,\n",
              "  0.9912753105163574,\n",
              "  0.9902489185333252,\n",
              "  0.9902489185333252,\n",
              "  0.9915319681167603,\n",
              "  0.9925583600997925,\n",
              "  0.9905055165290833,\n",
              "  0.9899923205375671,\n",
              "  0.9912753105163574,\n",
              "  0.9920451641082764,\n",
              "  0.9928149580955505,\n",
              "  0.9923017621040344,\n",
              "  0.9917885661125183,\n",
              "  0.9912753105163574,\n",
              "  0.9910187125205994,\n",
              "  0.9912753105163574,\n",
              "  0.9925583600997925,\n",
              "  0.9902489185333252,\n",
              "  0.9917885661125183,\n",
              "  0.9923017621040344,\n",
              "  0.9920451641082764,\n",
              "  0.9938414096832275,\n",
              "  0.9925583600997925,\n",
              "  0.9920451641082764,\n",
              "  0.9930716156959534,\n",
              "  0.9910187125205994,\n",
              "  0.9917885661125183,\n",
              "  0.9923017621040344,\n",
              "  0.9923017621040344,\n",
              "  0.9897357225418091,\n",
              "  0.986143171787262,\n",
              "  0.986143171787262,\n",
              "  0.9879394173622131,\n",
              "  0.9910187125205994,\n",
              "  0.9928149580955505,\n",
              "  0.9917885661125183,\n",
              "  0.9915319681167603,\n",
              "  0.9920451641082764,\n",
              "  0.9928149580955505,\n",
              "  0.9912753105163574,\n",
              "  0.9923017621040344,\n",
              "  0.9925583600997925,\n",
              "  0.9923017621040344,\n",
              "  0.9920451641082764,\n",
              "  0.9917885661125183,\n",
              "  0.9912753105163574,\n",
              "  0.9912753105163574,\n",
              "  0.9923017621040344,\n",
              "  0.9923017621040344,\n",
              "  0.9920451641082764,\n",
              "  0.9923017621040344,\n",
              "  0.9923017621040344,\n",
              "  0.9912753105163574,\n",
              "  0.9925583600997925,\n",
              "  0.9920451641082764,\n",
              "  0.9925583600997925,\n",
              "  0.9917885661125183,\n",
              "  0.9930716156959534,\n",
              "  0.9917885661125183,\n",
              "  0.9907621145248413,\n",
              "  ...],\n",
              " 'val_loss': [0.05542799085378647,\n",
              "  0.054842207580804825,\n",
              "  0.057215459644794464,\n",
              "  0.07078858464956284,\n",
              "  0.060533422976732254,\n",
              "  0.05485081672668457,\n",
              "  0.05495979264378548,\n",
              "  0.05975307151675224,\n",
              "  0.05479110777378082,\n",
              "  0.054424796253442764,\n",
              "  0.0562426820397377,\n",
              "  0.061440352350473404,\n",
              "  0.05616920441389084,\n",
              "  0.05453236401081085,\n",
              "  0.054588962346315384,\n",
              "  0.05516562983393669,\n",
              "  0.0549408420920372,\n",
              "  0.05614182725548744,\n",
              "  0.05696716159582138,\n",
              "  0.05640904977917671,\n",
              "  0.054390329867601395,\n",
              "  0.057860132306814194,\n",
              "  0.056136809289455414,\n",
              "  0.055311765521764755,\n",
              "  0.05480114370584488,\n",
              "  0.06165849044919014,\n",
              "  0.05499955266714096,\n",
              "  0.054900337010622025,\n",
              "  0.054609913378953934,\n",
              "  0.054212599992752075,\n",
              "  0.05519317463040352,\n",
              "  0.05971872806549072,\n",
              "  0.05480779707431793,\n",
              "  0.057447321712970734,\n",
              "  0.05933408811688423,\n",
              "  0.056636568158864975,\n",
              "  0.05484075844287872,\n",
              "  0.05802612379193306,\n",
              "  0.057000551372766495,\n",
              "  0.054595690220594406,\n",
              "  0.05644456669688225,\n",
              "  0.05480090156197548,\n",
              "  0.0542641282081604,\n",
              "  0.05725216865539551,\n",
              "  0.0546051487326622,\n",
              "  0.05433101952075958,\n",
              "  0.05410078912973404,\n",
              "  0.055419955402612686,\n",
              "  0.05624809116125107,\n",
              "  0.054096076637506485,\n",
              "  0.058482419699430466,\n",
              "  0.06832189857959747,\n",
              "  0.055156245827674866,\n",
              "  0.05663016065955162,\n",
              "  0.05738142877817154,\n",
              "  0.0556071512401104,\n",
              "  0.06072560325264931,\n",
              "  0.05499095097184181,\n",
              "  0.054868798702955246,\n",
              "  0.0548911914229393,\n",
              "  0.05596616864204407,\n",
              "  0.05841677635908127,\n",
              "  0.05431682989001274,\n",
              "  0.054041143506765366,\n",
              "  0.054535187780857086,\n",
              "  0.05815814808011055,\n",
              "  0.059129878878593445,\n",
              "  0.05449244752526283,\n",
              "  0.05558253452181816,\n",
              "  0.054797954857349396,\n",
              "  0.05569763109087944,\n",
              "  0.05456482991576195,\n",
              "  0.054406505078077316,\n",
              "  0.054164256900548935,\n",
              "  0.054276417940855026,\n",
              "  0.054235152900218964,\n",
              "  0.05938303470611572,\n",
              "  0.06285224854946136,\n",
              "  0.05662689730525017,\n",
              "  0.05422913283109665,\n",
              "  0.05772722512483597,\n",
              "  0.05607595667243004,\n",
              "  0.05528789386153221,\n",
              "  0.058906782418489456,\n",
              "  0.06952319294214249,\n",
              "  0.05831311270594597,\n",
              "  0.054504331201314926,\n",
              "  0.06055256351828575,\n",
              "  0.05928436294198036,\n",
              "  0.06289225816726685,\n",
              "  0.054064493626356125,\n",
              "  0.060554005205631256,\n",
              "  0.055604126304388046,\n",
              "  0.059938929975032806,\n",
              "  0.05441921949386597,\n",
              "  0.05748926103115082,\n",
              "  0.05599299445748329,\n",
              "  0.05600578337907791,\n",
              "  0.05451417341828346,\n",
              "  0.0542273111641407,\n",
              "  0.06022989749908447,\n",
              "  0.05460497364401817,\n",
              "  0.05453693866729736,\n",
              "  0.05583819001913071,\n",
              "  0.05544270575046539,\n",
              "  0.054112594574689865,\n",
              "  0.0540112666785717,\n",
              "  0.054181549698114395,\n",
              "  0.05607280880212784,\n",
              "  0.053967755287885666,\n",
              "  0.05491053685545921,\n",
              "  0.05403776839375496,\n",
              "  0.055566392838954926,\n",
              "  0.05704503133893013,\n",
              "  0.05825904756784439,\n",
              "  0.057372160255908966,\n",
              "  0.05533090978860855,\n",
              "  0.05657359957695007,\n",
              "  0.05426136776804924,\n",
              "  0.05424802750349045,\n",
              "  0.05510127171874046,\n",
              "  0.0545329749584198,\n",
              "  0.054994143545627594,\n",
              "  0.0594233013689518,\n",
              "  0.05664350837469101,\n",
              "  0.054367199540138245,\n",
              "  0.05413848161697388,\n",
              "  0.05395828187465668,\n",
              "  0.05409190431237221,\n",
              "  0.05444616451859474,\n",
              "  0.07184623926877975,\n",
              "  0.05422860383987427,\n",
              "  0.05604136362671852,\n",
              "  0.0542428232729435,\n",
              "  0.07331979274749756,\n",
              "  0.054465554654598236,\n",
              "  0.054984282702207565,\n",
              "  0.0546792671084404,\n",
              "  0.054474491626024246,\n",
              "  0.053972989320755005,\n",
              "  0.05767329782247543,\n",
              "  0.054223209619522095,\n",
              "  0.05629527568817139,\n",
              "  0.055179666727781296,\n",
              "  0.054980915039777756,\n",
              "  0.06304099410772324,\n",
              "  0.05446145310997963,\n",
              "  0.05383654683828354,\n",
              "  0.0544453002512455,\n",
              "  0.05440524220466614,\n",
              "  0.056472297757864,\n",
              "  0.055079977959394455,\n",
              "  0.05404878035187721,\n",
              "  0.055178333073854446,\n",
              "  0.05390292778611183,\n",
              "  0.053851958364248276,\n",
              "  0.05389224737882614,\n",
              "  0.05433608591556549,\n",
              "  0.056303851306438446,\n",
              "  0.06072217598557472,\n",
              "  0.05475866422057152,\n",
              "  0.05575292184948921,\n",
              "  0.054343320429325104,\n",
              "  0.057654354721307755,\n",
              "  0.054631318897008896,\n",
              "  0.06186874210834503,\n",
              "  0.05420094355940819,\n",
              "  0.05427778884768486,\n",
              "  0.05482800304889679,\n",
              "  0.05403301492333412,\n",
              "  0.05586422234773636,\n",
              "  0.05446077138185501,\n",
              "  0.060777224600315094,\n",
              "  0.056852828711271286,\n",
              "  0.054595980793237686,\n",
              "  0.054397765547037125,\n",
              "  0.053974103182554245,\n",
              "  0.054477062076330185,\n",
              "  0.05432632565498352,\n",
              "  0.054900508373975754,\n",
              "  0.05377500131726265,\n",
              "  0.05599815398454666,\n",
              "  0.061131980270147324,\n",
              "  0.05621730536222458,\n",
              "  0.055211957544088364,\n",
              "  0.053678203374147415,\n",
              "  0.05689027160406113,\n",
              "  0.05487598106265068,\n",
              "  0.0605299137532711,\n",
              "  0.062126170843839645,\n",
              "  0.0543024018406868,\n",
              "  0.05666463449597359,\n",
              "  0.05598224326968193,\n",
              "  0.05416566878557205,\n",
              "  0.05413300171494484,\n",
              "  0.05454684793949127,\n",
              "  0.05749396234750748,\n",
              "  0.05731851980090141,\n",
              "  0.05731282755732536,\n",
              "  0.05417453497648239,\n",
              "  0.05368552729487419,\n",
              "  0.05497421324253082,\n",
              "  0.055429376661777496,\n",
              "  0.05402224510908127,\n",
              "  0.05397002026438713,\n",
              "  0.05549980700016022,\n",
              "  0.055671028792858124,\n",
              "  0.05382108688354492,\n",
              "  0.05628297105431557,\n",
              "  0.05388185381889343,\n",
              "  0.056495871394872665,\n",
              "  0.05564244091510773,\n",
              "  0.058810606598854065,\n",
              "  0.05805452913045883,\n",
              "  0.05413077771663666,\n",
              "  0.060885343700647354,\n",
              "  0.05574991554021835,\n",
              "  0.059050943702459335,\n",
              "  0.05816049501299858,\n",
              "  0.054438699036836624,\n",
              "  0.05484279990196228,\n",
              "  0.056338898837566376,\n",
              "  0.05668579041957855,\n",
              "  0.05784325301647186,\n",
              "  0.05872933566570282,\n",
              "  0.054055359214544296,\n",
              "  0.0543990395963192,\n",
              "  0.06011687219142914,\n",
              "  0.05380934476852417,\n",
              "  0.053531862795352936,\n",
              "  0.057691801339387894,\n",
              "  0.05446134880185127,\n",
              "  0.0636422336101532,\n",
              "  0.06520048528909683,\n",
              "  0.05376666039228439,\n",
              "  0.05583484470844269,\n",
              "  0.054244015365839005,\n",
              "  0.054132163524627686,\n",
              "  0.054261479526758194,\n",
              "  0.05509861186146736,\n",
              "  0.05379258841276169,\n",
              "  0.06591656804084778,\n",
              "  0.05774075910449028,\n",
              "  0.05505910888314247,\n",
              "  0.055615998804569244,\n",
              "  0.05452680587768555,\n",
              "  0.055581651628017426,\n",
              "  0.05496915429830551,\n",
              "  0.05669286102056503,\n",
              "  0.0541377030313015,\n",
              "  0.054247625172138214,\n",
              "  0.05456550046801567,\n",
              "  0.05452285334467888,\n",
              "  0.07504167407751083,\n",
              "  0.05440400168299675,\n",
              "  0.05469389259815216,\n",
              "  0.054912105202674866,\n",
              "  0.054137349128723145,\n",
              "  0.058044467121362686,\n",
              "  0.06172342225909233,\n",
              "  0.054433658719062805,\n",
              "  0.05801614746451378,\n",
              "  0.056088920682668686,\n",
              "  0.056564390659332275,\n",
              "  0.05924682691693306,\n",
              "  0.05394558236002922,\n",
              "  0.05631699040532112,\n",
              "  0.05705742910504341,\n",
              "  0.05364760756492615,\n",
              "  0.054594364017248154,\n",
              "  0.056084658950567245,\n",
              "  0.05386020243167877,\n",
              "  0.05357677862048149,\n",
              "  0.0536581426858902,\n",
              "  0.054405517876148224,\n",
              "  0.06024821847677231,\n",
              "  0.054243363440036774,\n",
              "  0.053806938230991364,\n",
              "  0.055614277720451355,\n",
              "  0.054807838052511215,\n",
              "  0.07979781180620193,\n",
              "  0.055517688393592834,\n",
              "  0.07101336866617203,\n",
              "  0.06255249679088593,\n",
              "  0.05548827722668648,\n",
              "  0.06620632857084274,\n",
              "  0.05634860694408417,\n",
              "  0.054174453020095825,\n",
              "  0.05485820397734642,\n",
              "  0.0563557893037796,\n",
              "  0.062191855162382126,\n",
              "  0.05389697849750519,\n",
              "  0.0552908219397068,\n",
              "  0.054232172667980194,\n",
              "  0.05459509789943695,\n",
              "  0.05448932945728302,\n",
              "  0.05576251819729805,\n",
              "  0.05436132475733757,\n",
              "  0.057237859815359116,\n",
              "  0.05378100648522377,\n",
              "  0.0586574450135231,\n",
              "  0.059005413204431534,\n",
              "  0.054539959877729416,\n",
              "  0.05451171472668648,\n",
              "  0.05395735055208206,\n",
              "  0.05458257719874382,\n",
              "  0.05425654351711273,\n",
              "  0.05591056868433952,\n",
              "  0.05920810252428055,\n",
              "  0.05369093641638756,\n",
              "  0.054330430924892426,\n",
              "  0.0552108958363533,\n",
              "  0.053691983222961426,\n",
              "  0.054005227982997894,\n",
              "  0.053847938776016235,\n",
              "  0.05777319148182869,\n",
              "  0.053951721638441086,\n",
              "  0.0548066645860672,\n",
              "  0.05373074859380722,\n",
              "  0.05330514907836914,\n",
              "  0.054069194942712784,\n",
              "  0.0540025494992733,\n",
              "  0.056989382952451706,\n",
              "  0.053779829293489456,\n",
              "  0.056268397718667984,\n",
              "  0.053944092243909836,\n",
              "  0.053920622915029526,\n",
              "  0.058850884437561035,\n",
              "  0.05372316762804985,\n",
              "  0.053632743656635284,\n",
              "  0.05389169976115227,\n",
              "  0.05376168340444565,\n",
              "  0.0539265014231205,\n",
              "  0.05793619155883789,\n",
              "  0.05606268718838692,\n",
              "  0.05870874971151352,\n",
              "  0.0539691224694252,\n",
              "  0.056294891983270645,\n",
              "  0.05380508303642273,\n",
              "  0.05388813465833664,\n",
              "  0.05642499402165413,\n",
              "  0.054467152804136276,\n",
              "  0.05733664706349373,\n",
              "  0.05483073368668556,\n",
              "  0.05431670695543289,\n",
              "  0.055987946689128876,\n",
              "  0.05411802604794502,\n",
              "  0.05383629351854324,\n",
              "  0.0538269504904747,\n",
              "  0.053976792842149734,\n",
              "  0.053878773003816605,\n",
              "  0.05388972535729408,\n",
              "  0.0599520243704319,\n",
              "  0.05524594336748123,\n",
              "  0.06501756608486176,\n",
              "  0.07388868182897568,\n",
              "  0.05631611868739128,\n",
              "  0.054836567491292953,\n",
              "  0.05719904974102974,\n",
              "  0.061165593564510345,\n",
              "  0.055994633585214615,\n",
              "  0.054862622171640396,\n",
              "  0.05368147790431976,\n",
              "  0.05384296551346779,\n",
              "  0.054624177515506744,\n",
              "  0.06143930181860924,\n",
              "  0.06542452424764633,\n",
              "  0.05392831563949585,\n",
              "  0.05408609285950661,\n",
              "  0.05644417926669121,\n",
              "  0.05609003081917763,\n",
              "  0.05374732241034508,\n",
              "  0.0542178750038147,\n",
              "  0.05666062608361244,\n",
              "  0.05459370091557503,\n",
              "  0.06317126750946045,\n",
              "  0.055457763373851776,\n",
              "  0.054119180887937546,\n",
              "  0.05464418977499008,\n",
              "  0.054034583270549774,\n",
              "  0.05513324588537216,\n",
              "  0.056223783642053604,\n",
              "  0.05374952405691147,\n",
              "  0.057265348732471466,\n",
              "  0.05429552495479584,\n",
              "  0.05505971983075142,\n",
              "  0.05627158656716347,\n",
              "  0.05680683255195618,\n",
              "  0.05394112318754196,\n",
              "  0.06000432372093201,\n",
              "  0.05382643640041351,\n",
              "  0.05350898578763008,\n",
              "  0.05453801155090332,\n",
              "  0.05429740250110626,\n",
              "  0.053694579750299454,\n",
              "  0.054565075784921646,\n",
              "  0.053525228053331375,\n",
              "  0.06281037628650665,\n",
              "  0.05423729494214058,\n",
              "  0.05387183651328087,\n",
              "  0.05591423436999321,\n",
              "  0.05372563377022743,\n",
              "  0.054151859134435654,\n",
              "  0.05541608855128288,\n",
              "  0.05428384616971016,\n",
              "  0.05353479087352753,\n",
              "  0.05571042746305466,\n",
              "  0.0541948638856411,\n",
              "  0.06148148328065872,\n",
              "  0.05403745174407959,\n",
              "  0.05365358293056488,\n",
              "  0.05412996560335159,\n",
              "  0.0616469569504261,\n",
              "  0.05369630083441734,\n",
              "  0.05920913815498352,\n",
              "  0.053963832557201385,\n",
              "  0.05554866045713425,\n",
              "  0.055775176733732224,\n",
              "  0.05354746803641319,\n",
              "  0.05660129338502884,\n",
              "  0.05456627532839775,\n",
              "  0.054254502058029175,\n",
              "  0.06715728342533112,\n",
              "  0.05738488584756851,\n",
              "  0.054871220141649246,\n",
              "  0.05363762378692627,\n",
              "  0.0633954107761383,\n",
              "  0.05839097872376442,\n",
              "  0.056341446936130524,\n",
              "  0.054177526384592056,\n",
              "  0.05642583966255188,\n",
              "  0.056211747229099274,\n",
              "  0.05407878756523132,\n",
              "  0.0552385188639164,\n",
              "  0.053724877536296844,\n",
              "  0.05438217893242836,\n",
              "  0.05368254333734512,\n",
              "  0.06342354416847229,\n",
              "  0.05487997829914093,\n",
              "  0.053635936230421066,\n",
              "  0.060616008937358856,\n",
              "  0.05536428466439247,\n",
              "  0.05426696687936783,\n",
              "  0.05345413088798523,\n",
              "  0.05414484441280365,\n",
              "  0.06801613420248032,\n",
              "  0.05696992576122284,\n",
              "  0.054205816239118576,\n",
              "  0.054816871881484985,\n",
              "  0.05447036772966385,\n",
              "  0.05382543057203293,\n",
              "  0.05408595874905586,\n",
              "  0.05339518561959267,\n",
              "  0.05662773549556732,\n",
              "  0.05378841608762741,\n",
              "  0.053216733038425446,\n",
              "  0.05472511425614357,\n",
              "  0.05438130721449852,\n",
              "  0.05582379922270775,\n",
              "  0.054483089596033096,\n",
              "  0.055625904351472855,\n",
              "  0.053191058337688446,\n",
              "  0.05385608226060867,\n",
              "  0.05447990819811821,\n",
              "  0.053684160113334656,\n",
              "  0.05492688715457916,\n",
              "  0.05389414727687836,\n",
              "  0.05367511883378029,\n",
              "  0.05321718752384186,\n",
              "  0.05538064241409302,\n",
              "  0.054062359035015106,\n",
              "  0.05316992476582527,\n",
              "  0.0556761808693409,\n",
              "  0.05330144986510277,\n",
              "  0.057048168033361435,\n",
              "  0.053189922124147415,\n",
              "  0.054327692836523056,\n",
              "  0.05497791990637779,\n",
              "  0.05470617860555649,\n",
              "  0.05458391457796097,\n",
              "  0.053100280463695526,\n",
              "  0.05378672108054161,\n",
              "  0.0536855012178421,\n",
              "  0.05584312975406647,\n",
              "  0.05855393782258034,\n",
              "  0.05422583222389221,\n",
              "  0.053601671010255814,\n",
              "  0.05832478404045105,\n",
              "  0.054787710309028625,\n",
              "  0.05586135387420654,\n",
              "  0.05774465203285217,\n",
              "  0.054169997572898865,\n",
              "  0.05730455368757248,\n",
              "  0.05416982248425484,\n",
              "  0.06275124102830887,\n",
              "  0.06591497361660004,\n",
              "  0.05340256914496422,\n",
              "  0.05470115691423416,\n",
              "  0.05384635925292969,\n",
              "  0.05365455150604248,\n",
              "  0.05333952233195305,\n",
              "  0.055730950087308884,\n",
              "  0.054555412381887436,\n",
              "  0.05342123284935951,\n",
              "  0.05348869413137436,\n",
              "  0.05994570627808571,\n",
              "  0.05382007360458374,\n",
              "  0.055865198373794556,\n",
              "  0.06157819181680679,\n",
              "  0.055900104343891144,\n",
              "  0.05415486916899681,\n",
              "  0.053918931633234024,\n",
              "  0.053313616663217545,\n",
              "  0.053414952009916306,\n",
              "  0.05388949438929558,\n",
              "  0.05856725201010704,\n",
              "  0.05366819351911545,\n",
              "  0.056576233357191086,\n",
              "  0.05372992157936096,\n",
              "  0.05374928563833237,\n",
              "  0.053745392709970474,\n",
              "  0.0561327300965786,\n",
              "  0.05624377354979515,\n",
              "  0.05639876797795296,\n",
              "  0.05923893302679062,\n",
              "  0.060303568840026855,\n",
              "  0.05642572417855263,\n",
              "  0.05362239480018616,\n",
              "  0.05430091917514801,\n",
              "  0.054853081703186035,\n",
              "  0.053681157529354095,\n",
              "  0.05418338626623154,\n",
              "  0.05405735969543457,\n",
              "  0.05398355796933174,\n",
              "  0.05522291362285614,\n",
              "  0.05358771234750748,\n",
              "  0.05308850109577179,\n",
              "  0.05337017774581909,\n",
              "  0.054117221385240555,\n",
              "  0.053701940923929214,\n",
              "  0.0605640709400177,\n",
              "  0.0536704882979393,\n",
              "  0.053748153150081635,\n",
              "  0.054280877113342285,\n",
              "  0.053324662148952484,\n",
              "  0.05357882007956505,\n",
              "  0.05367646366357803,\n",
              "  0.053906284272670746,\n",
              "  0.053763192147016525,\n",
              "  0.054137907922267914,\n",
              "  0.053837548941373825,\n",
              "  0.053946979343891144,\n",
              "  0.05527433007955551,\n",
              "  0.05325603857636452,\n",
              "  0.05482986569404602,\n",
              "  0.05339266359806061,\n",
              "  0.053248561918735504,\n",
              "  0.05335256829857826,\n",
              "  0.05700496956706047,\n",
              "  0.058693379163742065,\n",
              "  0.053389087319374084,\n",
              "  0.053971581161022186,\n",
              "  0.054980479180812836,\n",
              "  0.05390971153974533,\n",
              "  0.054119773209095,\n",
              "  0.05386083200573921,\n",
              "  0.05634173005819321,\n",
              "  0.054235439747571945,\n",
              "  0.05441450700163841,\n",
              "  0.05571218580007553,\n",
              "  0.0552167147397995,\n",
              "  0.0536641925573349,\n",
              "  0.053232502192258835,\n",
              "  0.05328626185655594,\n",
              "  0.053735386580228806,\n",
              "  0.054780177772045135,\n",
              "  0.05446672812104225,\n",
              "  0.05417900159955025,\n",
              "  0.054167598485946655,\n",
              "  0.05397624149918556,\n",
              "  0.055587995797395706,\n",
              "  0.05524493381381035,\n",
              "  0.05670083686709404,\n",
              "  0.05400266870856285,\n",
              "  0.053886108100414276,\n",
              "  0.053842779248952866,\n",
              "  0.05312215909361839,\n",
              "  0.05370335653424263,\n",
              "  0.054013509303331375,\n",
              "  0.05674639344215393,\n",
              "  0.05337950587272644,\n",
              "  0.05412694066762924,\n",
              "  0.05447838827967644,\n",
              "  0.05407673120498657,\n",
              "  0.05426160246133804,\n",
              "  0.05862787738442421,\n",
              "  0.05336746945977211,\n",
              "  0.05504896491765976,\n",
              "  0.053585298359394073,\n",
              "  0.05698804557323456,\n",
              "  0.05322893708944321,\n",
              "  0.053241096436977386,\n",
              "  0.05307590961456299,\n",
              "  0.05454721301794052,\n",
              "  0.05319743975996971,\n",
              "  0.05308385565876961,\n",
              "  0.05444907397031784,\n",
              "  0.05372758209705353,\n",
              "  0.05344725400209427,\n",
              "  0.05422220751643181,\n",
              "  0.05470655485987663,\n",
              "  0.05365068465471268,\n",
              "  0.053651098161935806,\n",
              "  0.055167630314826965,\n",
              "  0.05289306491613388,\n",
              "  0.0534931942820549,\n",
              "  0.05299723148345947,\n",
              "  0.05912449583411217,\n",
              "  0.053660109639167786,\n",
              "  0.054181285202503204,\n",
              "  0.057769909501075745,\n",
              "  0.05746661126613617,\n",
              "  0.05316704884171486,\n",
              "  0.059931982308626175,\n",
              "  0.054783619940280914,\n",
              "  0.05290690436959267,\n",
              "  0.05320840701460838,\n",
              "  0.052551012486219406,\n",
              "  0.05293255299329758,\n",
              "  0.05334274470806122,\n",
              "  0.054484639316797256,\n",
              "  0.053030289709568024,\n",
              "  0.06214998662471771,\n",
              "  0.052789557725191116,\n",
              "  0.05236785486340523,\n",
              "  0.052406635135412216,\n",
              "  0.05357301980257034,\n",
              "  0.0530930794775486,\n",
              "  0.05254904553294182,\n",
              "  0.05309773236513138,\n",
              "  0.05433892458677292,\n",
              "  0.0534106083214283,\n",
              "  0.054836731404066086,\n",
              "  0.052748654037714005,\n",
              "  0.05268685147166252,\n",
              "  0.05241438001394272,\n",
              "  0.05243603140115738,\n",
              "  0.05380554124712944,\n",
              "  0.053631287068128586,\n",
              "  0.054111432284116745,\n",
              "  0.052555084228515625,\n",
              "  0.052137721329927444,\n",
              "  0.05567089468240738,\n",
              "  0.05906541272997856,\n",
              "  0.05276709794998169,\n",
              "  0.05253903195261955,\n",
              "  0.052888769656419754,\n",
              "  0.053978659212589264,\n",
              "  0.05384000763297081,\n",
              "  0.055768825113773346,\n",
              "  0.052995648235082626,\n",
              "  0.05396604537963867,\n",
              "  0.07127457857131958,\n",
              "  0.05638360232114792,\n",
              "  0.057415928691625595,\n",
              "  0.05416465178132057,\n",
              "  0.053500667214393616,\n",
              "  0.05306868255138397,\n",
              "  0.05304534360766411,\n",
              "  0.052803244441747665,\n",
              "  0.057001132518053055,\n",
              "  0.05229843035340309,\n",
              "  0.05244344100356102,\n",
              "  0.055250391364097595,\n",
              "  0.052928466349840164,\n",
              "  0.05440361425280571,\n",
              "  0.061155352741479874,\n",
              "  0.05306918919086456,\n",
              "  0.058143552392721176,\n",
              "  0.052681878209114075,\n",
              "  0.053452569991350174,\n",
              "  0.05297263339161873,\n",
              "  0.05329612269997597,\n",
              "  0.05242544785141945,\n",
              "  0.05250396206974983,\n",
              "  0.051966723054647446,\n",
              "  0.052358053624629974,\n",
              "  0.052663128823041916,\n",
              "  0.05332651734352112,\n",
              "  0.05273668095469475,\n",
              "  0.052381303161382675,\n",
              "  0.05273352935910225,\n",
              "  0.05475376546382904,\n",
              "  0.05342662334442139,\n",
              "  0.053203877061605453,\n",
              "  0.05422743409872055,\n",
              "  0.054691560566425323,\n",
              "  0.05236218869686127,\n",
              "  0.05260400474071503,\n",
              "  0.05429469048976898,\n",
              "  0.05292204022407532,\n",
              "  0.0615953765809536,\n",
              "  0.05385706573724747,\n",
              "  0.05406589061021805,\n",
              "  0.052461348474025726,\n",
              "  0.05301819369196892,\n",
              "  0.052981216460466385,\n",
              "  0.05279438942670822,\n",
              "  0.05238834768533707,\n",
              "  0.05308862403035164,\n",
              "  0.054926060140132904,\n",
              "  0.05287368223071098,\n",
              "  0.05275541543960571,\n",
              "  0.05378095060586929,\n",
              "  0.05282477289438248,\n",
              "  0.06518770754337311,\n",
              "  0.053849563002586365,\n",
              "  0.05340808629989624,\n",
              "  0.052701886743307114,\n",
              "  0.05292016267776489,\n",
              "  0.07296466827392578,\n",
              "  0.05370211601257324,\n",
              "  0.053220413625240326,\n",
              "  0.0533597394824028,\n",
              "  0.05326889082789421,\n",
              "  0.055642664432525635,\n",
              "  0.0532647930085659,\n",
              "  0.053952526301145554,\n",
              "  0.05457760766148567,\n",
              "  0.05289832502603531,\n",
              "  0.055864494293928146,\n",
              "  0.0550723634660244,\n",
              "  0.05354410037398338,\n",
              "  0.05657706782221794,\n",
              "  0.05329771712422371,\n",
              "  0.05326198413968086,\n",
              "  0.054447900503873825,\n",
              "  0.05269088223576546,\n",
              "  0.052925363183021545,\n",
              "  0.052828703075647354,\n",
              "  0.0528254397213459,\n",
              "  0.05300263687968254,\n",
              "  0.05462713539600372,\n",
              "  0.05283048003911972,\n",
              "  0.05315002426505089,\n",
              "  0.053213946521282196,\n",
              "  0.05304780229926109,\n",
              "  0.05262083187699318,\n",
              "  0.05416427552700043,\n",
              "  0.05279010906815529,\n",
              "  0.05753638222813606,\n",
              "  0.05557990446686745,\n",
              "  0.05490616336464882,\n",
              "  0.05754009634256363,\n",
              "  0.055483438074588776,\n",
              "  0.05748884379863739,\n",
              "  0.056450869888067245,\n",
              "  0.05385177582502365,\n",
              "  0.055058833211660385,\n",
              "  0.053683482110500336,\n",
              "  0.05848895013332367,\n",
              "  0.054145485162734985,\n",
              "  0.05505967512726784,\n",
              "  0.053745586425065994,\n",
              "  0.05587483197450638,\n",
              "  0.053443990647792816,\n",
              "  0.05361015349626541,\n",
              "  0.055074382573366165,\n",
              "  0.05423861742019653,\n",
              "  0.05737520754337311,\n",
              "  0.05334611237049103,\n",
              "  0.05341775342822075,\n",
              "  0.053568266332149506,\n",
              "  0.05408402159810066,\n",
              "  0.0547543503344059,\n",
              "  0.053258806467056274,\n",
              "  0.053342461585998535,\n",
              "  0.05267791077494621,\n",
              "  0.05402182415127754,\n",
              "  0.054971154779195786,\n",
              "  0.05378634110093117,\n",
              "  0.053279753774404526,\n",
              "  0.053423985838890076,\n",
              "  0.0536990649998188,\n",
              "  0.05394560098648071,\n",
              "  0.05341878533363342,\n",
              "  0.05310255289077759,\n",
              "  0.05339992791414261,\n",
              "  0.05377209186553955,\n",
              "  0.05366988107562065,\n",
              "  0.06283538788557053,\n",
              "  0.0540001317858696,\n",
              "  0.05687423795461655,\n",
              "  0.05354127287864685,\n",
              "  0.05543405935168266,\n",
              "  0.05371528118848801,\n",
              "  0.0530005544424057,\n",
              "  0.05742170661687851,\n",
              "  0.053798481822013855,\n",
              "  0.053125135600566864,\n",
              "  0.05408569425344467,\n",
              "  0.053597260266542435,\n",
              "  0.05448857322335243,\n",
              "  0.05318015441298485,\n",
              "  0.05473148822784424,\n",
              "  0.056916240602731705,\n",
              "  0.06440087407827377,\n",
              "  0.05477658659219742,\n",
              "  0.05571654066443443,\n",
              "  0.05345592275261879,\n",
              "  0.05397747457027435,\n",
              "  0.05344608053565025,\n",
              "  0.05347367003560066,\n",
              "  0.05428051948547363,\n",
              "  0.05378970876336098,\n",
              "  0.05373558774590492,\n",
              "  0.05343475937843323,\n",
              "  0.0538230761885643,\n",
              "  0.054553575813770294,\n",
              "  0.053580012172460556,\n",
              "  0.05359417945146561,\n",
              "  0.053552400320768356,\n",
              "  0.053733691573143005,\n",
              "  0.057619981467723846,\n",
              "  0.05402927100658417,\n",
              "  0.05601099878549576,\n",
              "  0.05607497692108154,\n",
              "  0.053317755460739136,\n",
              "  0.053400348871946335,\n",
              "  0.05397307872772217,\n",
              "  0.05369526892900467,\n",
              "  0.053265638649463654,\n",
              "  0.054627783596515656,\n",
              "  0.055490341037511826,\n",
              "  0.05376623943448067,\n",
              "  0.05369546636939049,\n",
              "  0.05449983477592468,\n",
              "  0.05564016476273537,\n",
              "  0.05385590344667435,\n",
              "  0.065987229347229,\n",
              "  0.05686755105853081,\n",
              "  0.055169131606817245,\n",
              "  0.053468357771635056,\n",
              "  0.054005615413188934,\n",
              "  0.054122503846883774,\n",
              "  0.05612988397479057,\n",
              "  0.0535392127931118,\n",
              "  0.05396363511681557,\n",
              "  0.05454277619719505,\n",
              "  0.05364043638110161,\n",
              "  0.053530555218458176,\n",
              "  0.05330853909254074,\n",
              "  0.05370235815644264,\n",
              "  0.053952500224113464,\n",
              "  0.053422052413225174,\n",
              "  0.0540044829249382,\n",
              "  0.05382784828543663,\n",
              "  0.05365333706140518,\n",
              "  0.05367051810026169,\n",
              "  0.05433712899684906,\n",
              "  0.05358085781335831,\n",
              "  0.05505813658237457,\n",
              "  0.05431103706359863,\n",
              "  0.055496249347925186,\n",
              "  0.05802159383893013,\n",
              "  0.055365901440382004,\n",
              "  0.05480695143342018,\n",
              "  0.05477767437696457,\n",
              "  0.05405661463737488,\n",
              "  0.054002098739147186,\n",
              "  0.05464440584182739,\n",
              "  0.0544009692966938,\n",
              "  0.055214930325746536,\n",
              "  0.05559081584215164,\n",
              "  0.062001731246709824,\n",
              "  0.05636031925678253,\n",
              "  0.055449340492486954,\n",
              "  0.05426138639450073,\n",
              "  0.053985126316547394,\n",
              "  0.05394727736711502,\n",
              "  0.05362403392791748,\n",
              "  0.053450774401426315,\n",
              "  0.05359586328268051,\n",
              "  0.05315527692437172,\n",
              "  0.05409965664148331,\n",
              "  0.054466862231492996,\n",
              "  0.05475776270031929,\n",
              "  0.05480366572737694,\n",
              "  0.05463295057415962,\n",
              "  0.05449066311120987,\n",
              "  0.0551358163356781,\n",
              "  0.05612843483686447,\n",
              "  0.054668061435222626,\n",
              "  0.05366656556725502,\n",
              "  0.054300080984830856,\n",
              "  0.05496379733085632,\n",
              "  0.05511131137609482,\n",
              "  0.05426158756017685,\n",
              "  0.05507594719529152,\n",
              "  0.05359445884823799,\n",
              "  0.05475806072354317,\n",
              "  0.05754745379090309,\n",
              "  0.05391610413789749,\n",
              "  0.05505048856139183,\n",
              "  0.05459023267030716,\n",
              "  0.05437202379107475,\n",
              "  0.057054221630096436,\n",
              "  0.05536428466439247,\n",
              "  0.05523901805281639,\n",
              "  0.05521867424249649,\n",
              "  0.056090157479047775,\n",
              "  0.05524292588233948,\n",
              "  0.05544614419341087,\n",
              "  0.05557175353169441,\n",
              "  0.05367657542228699,\n",
              "  0.0638638436794281,\n",
              "  0.0595734640955925,\n",
              "  0.05515986680984497,\n",
              "  0.0549517460167408,\n",
              "  0.0556037612259388,\n",
              "  0.054982442408800125,\n",
              "  0.054289426654577255,\n",
              "  0.054406896233558655,\n",
              "  0.05866770073771477,\n",
              "  0.05650246888399124,\n",
              "  0.05822639912366867,\n",
              "  0.0555553212761879,\n",
              "  0.05570150539278984,\n",
              "  0.055596884340047836,\n",
              "  0.060223981738090515,\n",
              "  0.05725836381316185,\n",
              "  0.058615025132894516,\n",
              "  0.05451643094420433,\n",
              "  0.05704810097813606,\n",
              "  0.05881256237626076,\n",
              "  0.057635605335235596,\n",
              "  0.054670535027980804,\n",
              "  0.05954479053616524,\n",
              "  0.05545365437865257,\n",
              "  0.060191381722688675,\n",
              "  0.055053163319826126,\n",
              "  0.05594157800078392,\n",
              "  0.0552329421043396,\n",
              "  0.05704663321375847,\n",
              "  0.05511097237467766,\n",
              "  0.057277146726846695,\n",
              "  0.05641474202275276,\n",
              "  0.059872083365917206,\n",
              "  0.05862228572368622,\n",
              "  0.05638040229678154,\n",
              "  0.05501683056354523,\n",
              "  0.05485992878675461,\n",
              "  0.05819220468401909,\n",
              "  0.05860059708356857,\n",
              "  0.05926615744829178,\n",
              "  0.055367350578308105,\n",
              "  0.0566275380551815,\n",
              "  0.05564197152853012,\n",
              "  0.057955000549554825,\n",
              "  0.05581203103065491,\n",
              "  0.056056078523397446,\n",
              "  0.05595593899488449,\n",
              "  0.056616391986608505,\n",
              "  0.0554141104221344,\n",
              "  0.06010681763291359,\n",
              "  0.05570659413933754,\n",
              "  0.055844396352767944,\n",
              "  0.05584786459803581,\n",
              "  0.055685389786958694,\n",
              "  0.05996915325522423,\n",
              "  0.05787598714232445,\n",
              "  0.0816282406449318,\n",
              "  0.06303644180297852,\n",
              "  0.05635247379541397,\n",
              "  0.05640513449907303,\n",
              "  0.05548705533146858,\n",
              "  0.05636407807469368,\n",
              "  0.056796908378601074,\n",
              "  0.05622990429401398,\n",
              "  0.057457685470581055,\n",
              "  0.056686729192733765,\n",
              "  0.05660010129213333,\n",
              "  0.057137761265039444,\n",
              "  0.055744435638189316,\n",
              "  0.0556139312684536,\n",
              "  0.05706801638007164,\n",
              "  0.0599234402179718,\n",
              "  0.05797129124403,\n",
              "  0.05638383701443672,\n",
              "  0.05706427991390228,\n",
              "  0.05627286061644554,\n",
              "  0.05627889931201935,\n",
              "  0.059200674295425415,\n",
              "  0.056363947689533234,\n",
              "  0.05790305510163307,\n",
              "  0.05704670399427414,\n",
              "  0.05630820617079735,\n",
              "  0.05751332640647888,\n",
              "  0.06366392225027084,\n",
              "  0.06276325136423111,\n",
              "  ...],\n",
              " 'val_accuracy': [0.983846127986908,\n",
              "  0.983846127986908,\n",
              "  0.9815384745597839,\n",
              "  0.9776923060417175,\n",
              "  0.9815384745597839,\n",
              "  0.9830769300460815,\n",
              "  0.9846153855323792,\n",
              "  0.9807692170143127,\n",
              "  0.983846127986908,\n",
              "  0.983846127986908,\n",
              "  0.9830769300460815,\n",
              "  0.9815384745597839,\n",
              "  0.9815384745597839,\n",
              "  0.9830769300460815,\n",
              "  0.9830769300460815,\n",
              "  0.9830769300460815,\n",
              "  0.9830769300460815,\n",
              "  0.9815384745597839,\n",
              "  0.9815384745597839,\n",
              "  0.9815384745597839,\n",
              "  0.983846127986908,\n",
              "  0.9807692170143127,\n",
              "  0.9815384745597839,\n",
              "  0.9815384745597839,\n",
              "  0.9846153855323792,\n",
              "  0.9784615635871887,\n",
              "  0.9830769300460815,\n",
              "  0.9823076725006104,\n",
              "  0.9830769300460815,\n",
              "  0.983846127986908,\n",
              "  0.9823076725006104,\n",
              "  0.9807692170143127,\n",
              "  0.9830769300460815,\n",
              "  0.9807692170143127,\n",
              "  0.9815384745597839,\n",
              "  0.9823076725006104,\n",
              "  0.9853846430778503,\n",
              "  0.9807692170143127,\n",
              "  0.9815384745597839,\n",
              "  0.9846153855323792,\n",
              "  0.983846127986908,\n",
              "  0.983846127986908,\n",
              "  0.9830769300460815,\n",
              "  0.9815384745597839,\n",
              "  0.9830769300460815,\n",
              "  0.9823076725006104,\n",
              "  0.983846127986908,\n",
              "  0.9815384745597839,\n",
              "  0.9815384745597839,\n",
              "  0.9830769300460815,\n",
              "  0.9815384745597839,\n",
              "  0.9784615635871887,\n",
              "  0.9823076725006104,\n",
              "  0.9830769300460815,\n",
              "  0.9830769300460815,\n",
              "  0.9846153855323792,\n",
              "  0.9815384745597839,\n",
              "  0.9830769300460815,\n",
              "  0.983846127986908,\n",
              "  0.9823076725006104,\n",
              "  0.983846127986908,\n",
              "  0.9792307615280151,\n",
              "  0.983846127986908,\n",
              "  0.983846127986908,\n",
              "  0.983846127986908,\n",
              "  0.9807692170143127,\n",
              "  0.9815384745597839,\n",
              "  0.983846127986908,\n",
              "  0.9853846430778503,\n",
              "  0.9823076725006104,\n",
              "  0.9815384745597839,\n",
              "  0.983846127986908,\n",
              "  0.9830769300460815,\n",
              "  0.983846127986908,\n",
              "  0.9823076725006104,\n",
              "  0.9823076725006104,\n",
              "  0.9807692170143127,\n",
              "  0.9800000190734863,\n",
              "  0.9815384745597839,\n",
              "  0.9830769300460815,\n",
              "  0.9807692170143127,\n",
              "  0.9823076725006104,\n",
              "  0.9823076725006104,\n",
              "  0.9815384745597839,\n",
              "  0.9792307615280151,\n",
              "  0.9815384745597839,\n",
              "  0.983846127986908,\n",
              "  0.9784615635871887,\n",
              "  0.9784615635871887,\n",
              "  0.9792307615280151,\n",
              "  0.9830769300460815,\n",
              "  0.9807692170143127,\n",
              "  0.9830769300460815,\n",
              "  0.9792307615280151,\n",
              "  0.9823076725006104,\n",
              "  0.9807692170143127,\n",
              "  0.9823076725006104,\n",
              "  0.9815384745597839,\n",
              "  0.983846127986908,\n",
              "  0.9823076725006104,\n",
              "  0.9815384745597839,\n",
              "  0.9830769300460815,\n",
              "  0.9823076725006104,\n",
              "  0.9823076725006104,\n",
              "  0.9815384745597839,\n",
              "  0.9823076725006104,\n",
              "  0.9823076725006104,\n",
              "  0.9823076725006104,\n",
              "  0.9815384745597839,\n",
              "  0.9830769300460815,\n",
              "  0.983846127986908,\n",
              "  0.983846127986908,\n",
              "  0.9830769300460815,\n",
              "  0.9807692170143127,\n",
              "  0.9823076725006104,\n",
              "  0.9823076725006104,\n",
              "  0.983846127986908,\n",
              "  0.9807692170143127,\n",
              "  0.9815384745597839,\n",
              "  0.9823076725006104,\n",
              "  0.9823076725006104,\n",
              "  0.9815384745597839,\n",
              "  0.9823076725006104,\n",
              "  0.9807692170143127,\n",
              "  0.9807692170143127,\n",
              "  0.983846127986908,\n",
              "  0.9823076725006104,\n",
              "  0.9830769300460815,\n",
              "  0.9815384745597839,\n",
              "  0.9815384745597839,\n",
              "  0.9761538505554199,\n",
              "  0.9830769300460815,\n",
              "  0.9823076725006104,\n",
              "  0.9815384745597839,\n",
              "  0.9753845930099487,\n",
              "  0.9815384745597839,\n",
              "  0.9830769300460815,\n",
              "  0.983846127986908,\n",
              "  0.9815384745597839,\n",
              "  0.9815384745597839,\n",
              "  0.9807692170143127,\n",
              "  0.9830769300460815,\n",
              "  0.9815384745597839,\n",
              "  0.9830769300460815,\n",
              "  0.9823076725006104,\n",
              "  0.9807692170143127,\n",
              "  0.9823076725006104,\n",
              "  0.9815384745597839,\n",
              "  0.9823076725006104,\n",
              "  0.9823076725006104,\n",
              "  0.9815384745597839,\n",
              "  0.9823076725006104,\n",
              "  0.9815384745597839,\n",
              "  0.9830769300460815,\n",
              "  0.983846127986908,\n",
              "  0.983846127986908,\n",
              "  0.9815384745597839,\n",
              "  0.9823076725006104,\n",
              "  0.9815384745597839,\n",
              "  0.9792307615280151,\n",
              "  0.983846127986908,\n",
              "  0.9823076725006104,\n",
              "  0.9815384745597839,\n",
              "  0.9807692170143127,\n",
              "  0.9823076725006104,\n",
              "  0.9800000190734863,\n",
              "  0.9830769300460815,\n",
              "  0.9830769300460815,\n",
              "  0.9823076725006104,\n",
              "  0.9823076725006104,\n",
              "  0.9830769300460815,\n",
              "  0.983846127986908,\n",
              "  0.9807692170143127,\n",
              "  0.9815384745597839,\n",
              "  0.983846127986908,\n",
              "  0.9830769300460815,\n",
              "  0.9823076725006104,\n",
              "  0.983846127986908,\n",
              "  0.9815384745597839,\n",
              "  0.9823076725006104,\n",
              "  0.9823076725006104,\n",
              "  0.9823076725006104,\n",
              "  0.9815384745597839,\n",
              "  0.9823076725006104,\n",
              "  0.9823076725006104,\n",
              "  0.983846127986908,\n",
              "  0.9807692170143127,\n",
              "  0.9815384745597839,\n",
              "  0.9815384745597839,\n",
              "  0.9815384745597839,\n",
              "  0.983846127986908,\n",
              "  0.9807692170143127,\n",
              "  0.9830769300460815,\n",
              "  0.983846127986908,\n",
              "  0.9823076725006104,\n",
              "  0.9830769300460815,\n",
              "  0.9807692170143127,\n",
              "  0.9807692170143127,\n",
              "  0.9815384745597839,\n",
              "  0.9815384745597839,\n",
              "  0.9823076725006104,\n",
              "  0.9823076725006104,\n",
              "  0.9830769300460815,\n",
              "  0.983846127986908,\n",
              "  0.983846127986908,\n",
              "  0.9830769300460815,\n",
              "  0.9823076725006104,\n",
              "  0.9823076725006104,\n",
              "  0.9823076725006104,\n",
              "  0.983846127986908,\n",
              "  0.9823076725006104,\n",
              "  0.9823076725006104,\n",
              "  0.9815384745597839,\n",
              "  0.9823076725006104,\n",
              "  0.9815384745597839,\n",
              "  0.9815384745597839,\n",
              "  0.9823076725006104,\n",
              "  0.9792307615280151,\n",
              "  0.9807692170143127,\n",
              "  0.983846127986908,\n",
              "  0.9823076725006104,\n",
              "  0.9823076725006104,\n",
              "  0.9815384745597839,\n",
              "  0.9815384745597839,\n",
              "  0.9815384745597839,\n",
              "  0.9815384745597839,\n",
              "  0.9823076725006104,\n",
              "  0.9823076725006104,\n",
              "  0.9815384745597839,\n",
              "  0.983846127986908,\n",
              "  0.9815384745597839,\n",
              "  0.983846127986908,\n",
              "  0.9807692170143127,\n",
              "  0.9800000190734863,\n",
              "  0.983846127986908,\n",
              "  0.9815384745597839,\n",
              "  0.9815384745597839,\n",
              "  0.9823076725006104,\n",
              "  0.983846127986908,\n",
              "  0.9823076725006104,\n",
              "  0.9815384745597839,\n",
              "  0.9800000190734863,\n",
              "  0.9823076725006104,\n",
              "  0.9823076725006104,\n",
              "  0.9830769300460815,\n",
              "  0.9823076725006104,\n",
              "  0.9823076725006104,\n",
              "  0.9815384745597839,\n",
              "  0.9823076725006104,\n",
              "  0.983846127986908,\n",
              "  0.983846127986908,\n",
              "  0.9830769300460815,\n",
              "  0.9823076725006104,\n",
              "  0.9730769395828247,\n",
              "  0.9815384745597839,\n",
              "  0.9807692170143127,\n",
              "  0.9830769300460815,\n",
              "  0.9815384745597839,\n",
              "  0.9815384745597839,\n",
              "  0.9815384745597839,\n",
              "  0.983846127986908,\n",
              "  0.9815384745597839,\n",
              "  0.9830769300460815,\n",
              "  0.9823076725006104,\n",
              "  0.9823076725006104,\n",
              "  0.9823076725006104,\n",
              "  0.9823076725006104,\n",
              "  0.9815384745597839,\n",
              "  0.9823076725006104,\n",
              "  0.9815384745597839,\n",
              "  0.983846127986908,\n",
              "  0.983846127986908,\n",
              "  0.9823076725006104,\n",
              "  0.983846127986908,\n",
              "  0.9815384745597839,\n",
              "  0.9823076725006104,\n",
              "  0.9815384745597839,\n",
              "  0.9823076725006104,\n",
              "  0.9823076725006104,\n",
              "  0.9823076725006104,\n",
              "  0.9723076820373535,\n",
              "  0.9823076725006104,\n",
              "  0.9800000190734863,\n",
              "  0.9800000190734863,\n",
              "  0.983846127986908,\n",
              "  0.9784615635871887,\n",
              "  0.9830769300460815,\n",
              "  0.9823076725006104,\n",
              "  0.9823076725006104,\n",
              "  0.9830769300460815,\n",
              "  0.9815384745597839,\n",
              "  0.9846153855323792,\n",
              "  0.9823076725006104,\n",
              "  0.9846153855323792,\n",
              "  0.9815384745597839,\n",
              "  0.9830769300460815,\n",
              "  0.9830769300460815,\n",
              "  0.9815384745597839,\n",
              "  0.9823076725006104,\n",
              "  0.9823076725006104,\n",
              "  0.9823076725006104,\n",
              "  0.9815384745597839,\n",
              "  0.9823076725006104,\n",
              "  0.9823076725006104,\n",
              "  0.983846127986908,\n",
              "  0.9830769300460815,\n",
              "  0.9823076725006104,\n",
              "  0.983846127986908,\n",
              "  0.9823076725006104,\n",
              "  0.9823076725006104,\n",
              "  0.9823076725006104,\n",
              "  0.9830769300460815,\n",
              "  0.9823076725006104,\n",
              "  0.983846127986908,\n",
              "  0.983846127986908,\n",
              "  0.9823076725006104,\n",
              "  0.983846127986908,\n",
              "  0.9823076725006104,\n",
              "  0.9823076725006104,\n",
              "  0.9823076725006104,\n",
              "  0.9823076725006104,\n",
              "  0.9823076725006104,\n",
              "  0.9830769300460815,\n",
              "  0.9823076725006104,\n",
              "  0.9830769300460815,\n",
              "  0.983846127986908,\n",
              "  0.9823076725006104,\n",
              "  0.9823076725006104,\n",
              "  0.9823076725006104,\n",
              "  0.9823076725006104,\n",
              "  0.9846153855323792,\n",
              "  0.9823076725006104,\n",
              "  0.9823076725006104,\n",
              "  0.9823076725006104,\n",
              "  0.9823076725006104,\n",
              "  0.9823076725006104,\n",
              "  0.9823076725006104,\n",
              "  0.9830769300460815,\n",
              "  0.983846127986908,\n",
              "  0.9823076725006104,\n",
              "  0.9830769300460815,\n",
              "  0.9830769300460815,\n",
              "  0.9830769300460815,\n",
              "  0.9823076725006104,\n",
              "  0.9823076725006104,\n",
              "  0.9846153855323792,\n",
              "  0.9823076725006104,\n",
              "  0.9823076725006104,\n",
              "  0.9830769300460815,\n",
              "  0.983846127986908,\n",
              "  0.9830769300460815,\n",
              "  0.9823076725006104,\n",
              "  0.9830769300460815,\n",
              "  0.9823076725006104,\n",
              "  0.9792307615280151,\n",
              "  0.9746153950691223,\n",
              "  0.9830769300460815,\n",
              "  0.9830769300460815,\n",
              "  0.9815384745597839,\n",
              "  0.9807692170143127,\n",
              "  0.9830769300460815,\n",
              "  0.9823076725006104,\n",
              "  0.9823076725006104,\n",
              "  0.983846127986908,\n",
              "  0.9830769300460815,\n",
              "  0.9815384745597839,\n",
              "  0.9807692170143127,\n",
              "  0.983846127986908,\n",
              "  0.983846127986908,\n",
              "  0.9846153855323792,\n",
              "  0.9830769300460815,\n",
              "  0.9830769300460815,\n",
              "  0.9846153855323792,\n",
              "  0.983846127986908,\n",
              "  0.983846127986908,\n",
              "  0.9807692170143127,\n",
              "  0.9830769300460815,\n",
              "  0.9823076725006104,\n",
              "  0.9830769300460815,\n",
              "  0.9823076725006104,\n",
              "  0.9823076725006104,\n",
              "  0.9846153855323792,\n",
              "  0.9823076725006104,\n",
              "  0.9830769300460815,\n",
              "  0.983846127986908,\n",
              "  0.9823076725006104,\n",
              "  0.983846127986908,\n",
              "  0.9830769300460815,\n",
              "  0.983846127986908,\n",
              "  0.9830769300460815,\n",
              "  0.983846127986908,\n",
              "  0.9823076725006104,\n",
              "  0.983846127986908,\n",
              "  0.983846127986908,\n",
              "  0.9830769300460815,\n",
              "  0.983846127986908,\n",
              "  0.9823076725006104,\n",
              "  0.9815384745597839,\n",
              "  0.983846127986908,\n",
              "  0.9846153855323792,\n",
              "  0.983846127986908,\n",
              "  0.9823076725006104,\n",
              "  0.9830769300460815,\n",
              "  0.9830769300460815,\n",
              "  0.9830769300460815,\n",
              "  0.9823076725006104,\n",
              "  0.9830769300460815,\n",
              "  0.983846127986908,\n",
              "  0.9807692170143127,\n",
              "  0.983846127986908,\n",
              "  0.983846127986908,\n",
              "  0.9823076725006104,\n",
              "  0.9807692170143127,\n",
              "  0.9823076725006104,\n",
              "  0.9823076725006104,\n",
              "  0.9823076725006104,\n",
              "  0.9846153855323792,\n",
              "  0.9830769300460815,\n",
              "  0.9846153855323792,\n",
              "  0.9830769300460815,\n",
              "  0.983846127986908,\n",
              "  0.9830769300460815,\n",
              "  0.9815384745597839,\n",
              "  0.9823076725006104,\n",
              "  0.983846127986908,\n",
              "  0.9846153855323792,\n",
              "  0.9807692170143127,\n",
              "  0.9830769300460815,\n",
              "  0.983846127986908,\n",
              "  0.9830769300460815,\n",
              "  0.9823076725006104,\n",
              "  0.983846127986908,\n",
              "  0.983846127986908,\n",
              "  0.9846153855323792,\n",
              "  0.9830769300460815,\n",
              "  0.983846127986908,\n",
              "  0.9846153855323792,\n",
              "  0.9815384745597839,\n",
              "  0.9830769300460815,\n",
              "  0.9830769300460815,\n",
              "  0.9823076725006104,\n",
              "  0.9846153855323792,\n",
              "  0.9830769300460815,\n",
              "  0.9830769300460815,\n",
              "  0.9830769300460815,\n",
              "  0.9792307615280151,\n",
              "  0.9830769300460815,\n",
              "  0.983846127986908,\n",
              "  0.983846127986908,\n",
              "  0.9830769300460815,\n",
              "  0.983846127986908,\n",
              "  0.983846127986908,\n",
              "  0.9830769300460815,\n",
              "  0.9830769300460815,\n",
              "  0.9846153855323792,\n",
              "  0.9846153855323792,\n",
              "  0.983846127986908,\n",
              "  0.983846127986908,\n",
              "  0.983846127986908,\n",
              "  0.9853846430778503,\n",
              "  0.9830769300460815,\n",
              "  0.9830769300460815,\n",
              "  0.9846153855323792,\n",
              "  0.983846127986908,\n",
              "  0.9830769300460815,\n",
              "  0.983846127986908,\n",
              "  0.9853846430778503,\n",
              "  0.9846153855323792,\n",
              "  0.983846127986908,\n",
              "  0.983846127986908,\n",
              "  0.983846127986908,\n",
              "  0.9830769300460815,\n",
              "  0.9846153855323792,\n",
              "  0.983846127986908,\n",
              "  0.9830769300460815,\n",
              "  0.9830769300460815,\n",
              "  0.9830769300460815,\n",
              "  0.9846153855323792,\n",
              "  0.9853846430778503,\n",
              "  0.9846153855323792,\n",
              "  0.9830769300460815,\n",
              "  0.9853846430778503,\n",
              "  0.9846153855323792,\n",
              "  0.9830769300460815,\n",
              "  0.9823076725006104,\n",
              "  0.9846153855323792,\n",
              "  0.983846127986908,\n",
              "  0.9823076725006104,\n",
              "  0.983846127986908,\n",
              "  0.9846153855323792,\n",
              "  0.9807692170143127,\n",
              "  0.983846127986908,\n",
              "  0.983846127986908,\n",
              "  0.9830769300460815,\n",
              "  0.9800000190734863,\n",
              "  0.9800000190734863,\n",
              "  0.9830769300460815,\n",
              "  0.9830769300460815,\n",
              "  0.983846127986908,\n",
              "  0.9830769300460815,\n",
              "  0.9846153855323792,\n",
              "  0.9830769300460815,\n",
              "  0.983846127986908,\n",
              "  0.983846127986908,\n",
              "  0.9846153855323792,\n",
              "  0.9830769300460815,\n",
              "  0.983846127986908,\n",
              "  0.9823076725006104,\n",
              "  0.9792307615280151,\n",
              "  0.9823076725006104,\n",
              "  0.9846153855323792,\n",
              "  0.9830769300460815,\n",
              "  0.9846153855323792,\n",
              "  0.9830769300460815,\n",
              "  0.983846127986908,\n",
              "  0.9830769300460815,\n",
              "  0.983846127986908,\n",
              "  0.9830769300460815,\n",
              "  0.9846153855323792,\n",
              "  0.983846127986908,\n",
              "  0.983846127986908,\n",
              "  0.9830769300460815,\n",
              "  0.9823076725006104,\n",
              "  0.9830769300460815,\n",
              "  0.9823076725006104,\n",
              "  0.9815384745597839,\n",
              "  0.983846127986908,\n",
              "  0.983846127986908,\n",
              "  0.9846153855323792,\n",
              "  0.9830769300460815,\n",
              "  0.9830769300460815,\n",
              "  0.983846127986908,\n",
              "  0.983846127986908,\n",
              "  0.983846127986908,\n",
              "  0.9846153855323792,\n",
              "  0.983846127986908,\n",
              "  0.9830769300460815,\n",
              "  0.983846127986908,\n",
              "  0.9853846430778503,\n",
              "  0.9846153855323792,\n",
              "  0.9792307615280151,\n",
              "  0.983846127986908,\n",
              "  0.9846153855323792,\n",
              "  0.983846127986908,\n",
              "  0.983846127986908,\n",
              "  0.983846127986908,\n",
              "  0.983846127986908,\n",
              "  0.9846153855323792,\n",
              "  0.9846153855323792,\n",
              "  0.9853846430778503,\n",
              "  0.983846127986908,\n",
              "  0.983846127986908,\n",
              "  0.983846127986908,\n",
              "  0.9846153855323792,\n",
              "  0.9853846430778503,\n",
              "  0.9846153855323792,\n",
              "  0.983846127986908,\n",
              "  0.983846127986908,\n",
              "  0.9815384745597839,\n",
              "  0.9807692170143127,\n",
              "  0.983846127986908,\n",
              "  0.9830769300460815,\n",
              "  0.9830769300460815,\n",
              "  0.9846153855323792,\n",
              "  0.9853846430778503,\n",
              "  0.9846153855323792,\n",
              "  0.983846127986908,\n",
              "  0.9853846430778503,\n",
              "  0.9853846430778503,\n",
              "  0.9846153855323792,\n",
              "  0.9846153855323792,\n",
              "  0.983846127986908,\n",
              "  0.9846153855323792,\n",
              "  0.983846127986908,\n",
              "  0.9846153855323792,\n",
              "  0.983846127986908,\n",
              "  0.983846127986908,\n",
              "  0.9846153855323792,\n",
              "  0.9830769300460815,\n",
              "  0.9830769300460815,\n",
              "  0.9830769300460815,\n",
              "  0.9861538410186768,\n",
              "  0.9853846430778503,\n",
              "  0.9823076725006104,\n",
              "  0.9830769300460815,\n",
              "  0.9846153855323792,\n",
              "  0.9846153855323792,\n",
              "  0.9846153855323792,\n",
              "  0.9830769300460815,\n",
              "  0.983846127986908,\n",
              "  0.9830769300460815,\n",
              "  0.9861538410186768,\n",
              "  0.9846153855323792,\n",
              "  0.9823076725006104,\n",
              "  0.9830769300460815,\n",
              "  0.9807692170143127,\n",
              "  0.983846127986908,\n",
              "  0.983846127986908,\n",
              "  0.983846127986908,\n",
              "  0.9846153855323792,\n",
              "  0.983846127986908,\n",
              "  0.9853846430778503,\n",
              "  0.983846127986908,\n",
              "  0.9846153855323792,\n",
              "  0.983846127986908,\n",
              "  0.9853846430778503,\n",
              "  0.983846127986908,\n",
              "  0.9846153855323792,\n",
              "  0.9846153855323792,\n",
              "  0.9861538410186768,\n",
              "  0.983846127986908,\n",
              "  0.9846153855323792,\n",
              "  0.9846153855323792,\n",
              "  0.9846153855323792,\n",
              "  0.9853846430778503,\n",
              "  0.9846153855323792,\n",
              "  0.9846153855323792,\n",
              "  0.983846127986908,\n",
              "  0.983846127986908,\n",
              "  0.983846127986908,\n",
              "  0.9830769300460815,\n",
              "  0.9846153855323792,\n",
              "  0.9846153855323792,\n",
              "  0.9830769300460815,\n",
              "  0.9830769300460815,\n",
              "  0.9846153855323792,\n",
              "  0.9853846430778503,\n",
              "  0.9846153855323792,\n",
              "  0.9846153855323792,\n",
              "  0.9830769300460815,\n",
              "  0.9853846430778503,\n",
              "  0.983846127986908,\n",
              "  0.9815384745597839,\n",
              "  0.9846153855323792,\n",
              "  0.9846153855323792,\n",
              "  0.9846153855323792,\n",
              "  0.9853846430778503,\n",
              "  0.9846153855323792,\n",
              "  0.9846153855323792,\n",
              "  0.9846153855323792,\n",
              "  0.9846153855323792,\n",
              "  0.983846127986908,\n",
              "  0.9846153855323792,\n",
              "  0.983846127986908,\n",
              "  0.9846153855323792,\n",
              "  0.9846153855323792,\n",
              "  0.9846153855323792,\n",
              "  0.9846153855323792,\n",
              "  0.9846153855323792,\n",
              "  0.9830769300460815,\n",
              "  0.9846153855323792,\n",
              "  0.9846153855323792,\n",
              "  0.9846153855323792,\n",
              "  0.9815384745597839,\n",
              "  0.9846153855323792,\n",
              "  0.9846153855323792,\n",
              "  0.9846153855323792,\n",
              "  0.9861538410186768,\n",
              "  0.9846153855323792,\n",
              "  0.9846153855323792,\n",
              "  0.9846153855323792,\n",
              "  0.9853846430778503,\n",
              "  0.9784615635871887,\n",
              "  0.9830769300460815,\n",
              "  0.983846127986908,\n",
              "  0.9846153855323792,\n",
              "  0.9846153855323792,\n",
              "  0.983846127986908,\n",
              "  0.9846153855323792,\n",
              "  0.9846153855323792,\n",
              "  0.9830769300460815,\n",
              "  0.9846153855323792,\n",
              "  0.9846153855323792,\n",
              "  0.9846153855323792,\n",
              "  0.9846153855323792,\n",
              "  0.9853846430778503,\n",
              "  0.9815384745597839,\n",
              "  0.9853846430778503,\n",
              "  0.9830769300460815,\n",
              "  0.983846127986908,\n",
              "  0.9853846430778503,\n",
              "  0.9846153855323792,\n",
              "  0.9846153855323792,\n",
              "  0.9846153855323792,\n",
              "  0.983846127986908,\n",
              "  0.9846153855323792,\n",
              "  0.9846153855323792,\n",
              "  0.9846153855323792,\n",
              "  0.9846153855323792,\n",
              "  0.9846153855323792,\n",
              "  0.983846127986908,\n",
              "  0.9861538410186768,\n",
              "  0.9853846430778503,\n",
              "  0.983846127986908,\n",
              "  0.9853846430778503,\n",
              "  0.9846153855323792,\n",
              "  0.9853846430778503,\n",
              "  0.9853846430778503,\n",
              "  0.9846153855323792,\n",
              "  0.9853846430778503,\n",
              "  0.9846153855323792,\n",
              "  0.9823076725006104,\n",
              "  0.9853846430778503,\n",
              "  0.9846153855323792,\n",
              "  0.9846153855323792,\n",
              "  0.983846127986908,\n",
              "  0.983846127986908,\n",
              "  0.983846127986908,\n",
              "  0.9846153855323792,\n",
              "  0.9846153855323792,\n",
              "  0.9853846430778503,\n",
              "  0.9846153855323792,\n",
              "  0.9853846430778503,\n",
              "  0.9853846430778503,\n",
              "  0.9846153855323792,\n",
              "  0.9807692170143127,\n",
              "  0.9853846430778503,\n",
              "  0.9846153855323792,\n",
              "  0.9853846430778503,\n",
              "  0.9846153855323792,\n",
              "  0.9769230484962463,\n",
              "  0.983846127986908,\n",
              "  0.983846127986908,\n",
              "  0.9846153855323792,\n",
              "  0.9846153855323792,\n",
              "  0.9853846430778503,\n",
              "  0.983846127986908,\n",
              "  0.9861538410186768,\n",
              "  0.983846127986908,\n",
              "  0.9846153855323792,\n",
              "  0.983846127986908,\n",
              "  0.983846127986908,\n",
              "  0.983846127986908,\n",
              "  0.9853846430778503,\n",
              "  0.983846127986908,\n",
              "  0.9846153855323792,\n",
              "  0.9846153855323792,\n",
              "  0.983846127986908,\n",
              "  0.983846127986908,\n",
              "  0.9853846430778503,\n",
              "  0.9846153855323792,\n",
              "  0.9846153855323792,\n",
              "  0.9853846430778503,\n",
              "  0.9846153855323792,\n",
              "  0.9853846430778503,\n",
              "  0.983846127986908,\n",
              "  0.983846127986908,\n",
              "  0.9846153855323792,\n",
              "  0.983846127986908,\n",
              "  0.9853846430778503,\n",
              "  0.9853846430778503,\n",
              "  0.9861538410186768,\n",
              "  0.9830769300460815,\n",
              "  0.9830769300460815,\n",
              "  0.9853846430778503,\n",
              "  0.9861538410186768,\n",
              "  0.9861538410186768,\n",
              "  0.9853846430778503,\n",
              "  0.9846153855323792,\n",
              "  0.9846153855323792,\n",
              "  0.9861538410186768,\n",
              "  0.9830769300460815,\n",
              "  0.983846127986908,\n",
              "  0.983846127986908,\n",
              "  0.9853846430778503,\n",
              "  0.983846127986908,\n",
              "  0.983846127986908,\n",
              "  0.983846127986908,\n",
              "  0.9823076725006104,\n",
              "  0.9861538410186768,\n",
              "  0.9846153855323792,\n",
              "  0.983846127986908,\n",
              "  0.9846153855323792,\n",
              "  0.9830769300460815,\n",
              "  0.9853846430778503,\n",
              "  0.9846153855323792,\n",
              "  0.9846153855323792,\n",
              "  0.9853846430778503,\n",
              "  0.983846127986908,\n",
              "  0.9853846430778503,\n",
              "  0.9853846430778503,\n",
              "  0.983846127986908,\n",
              "  0.983846127986908,\n",
              "  0.983846127986908,\n",
              "  0.983846127986908,\n",
              "  0.9830769300460815,\n",
              "  0.9830769300460815,\n",
              "  0.983846127986908,\n",
              "  0.9846153855323792,\n",
              "  0.9830769300460815,\n",
              "  0.9846153855323792,\n",
              "  0.983846127986908,\n",
              "  0.9830769300460815,\n",
              "  0.9853846430778503,\n",
              "  0.986923098564148,\n",
              "  0.9853846430778503,\n",
              "  0.9853846430778503,\n",
              "  0.983846127986908,\n",
              "  0.983846127986908,\n",
              "  0.983846127986908,\n",
              "  0.9846153855323792,\n",
              "  0.9830769300460815,\n",
              "  0.983846127986908,\n",
              "  0.9853846430778503,\n",
              "  0.9823076725006104,\n",
              "  0.986923098564148,\n",
              "  0.9830769300460815,\n",
              "  0.983846127986908,\n",
              "  0.9823076725006104,\n",
              "  0.983846127986908,\n",
              "  0.9830769300460815,\n",
              "  0.9853846430778503,\n",
              "  0.9830769300460815,\n",
              "  0.9846153855323792,\n",
              "  0.9830769300460815,\n",
              "  0.9830769300460815,\n",
              "  0.9853846430778503,\n",
              "  0.9846153855323792,\n",
              "  0.9846153855323792,\n",
              "  0.983846127986908,\n",
              "  0.9846153855323792,\n",
              "  0.9830769300460815,\n",
              "  0.9830769300460815,\n",
              "  0.9861538410186768,\n",
              "  0.9830769300460815,\n",
              "  0.9830769300460815,\n",
              "  0.9830769300460815,\n",
              "  0.9846153855323792,\n",
              "  0.9830769300460815,\n",
              "  0.9830769300460815,\n",
              "  0.9830769300460815,\n",
              "  0.9830769300460815,\n",
              "  0.9853846430778503,\n",
              "  0.9861538410186768,\n",
              "  0.9830769300460815,\n",
              "  0.983846127986908,\n",
              "  0.9846153855323792,\n",
              "  0.9830769300460815,\n",
              "  0.983846127986908,\n",
              "  0.9807692170143127,\n",
              "  0.9861538410186768,\n",
              "  0.9846153855323792,\n",
              "  0.9846153855323792,\n",
              "  0.9853846430778503,\n",
              "  0.9830769300460815,\n",
              "  0.9830769300460815,\n",
              "  0.9853846430778503,\n",
              "  0.983846127986908,\n",
              "  0.9853846430778503,\n",
              "  0.983846127986908,\n",
              "  0.9853846430778503,\n",
              "  0.9846153855323792,\n",
              "  0.9846153855323792,\n",
              "  0.983846127986908,\n",
              "  0.9853846430778503,\n",
              "  0.983846127986908,\n",
              "  0.983846127986908,\n",
              "  0.9846153855323792,\n",
              "  0.9846153855323792,\n",
              "  0.9830769300460815,\n",
              "  0.9853846430778503,\n",
              "  0.9830769300460815,\n",
              "  0.983846127986908,\n",
              "  0.9853846430778503,\n",
              "  0.9861538410186768,\n",
              "  0.983846127986908,\n",
              "  0.9853846430778503,\n",
              "  0.9830769300460815,\n",
              "  0.9853846430778503,\n",
              "  0.983846127986908,\n",
              "  0.9846153855323792,\n",
              "  0.983846127986908,\n",
              "  0.983846127986908,\n",
              "  0.986923098564148,\n",
              "  0.9846153855323792,\n",
              "  0.9846153855323792,\n",
              "  0.9846153855323792,\n",
              "  0.983846127986908,\n",
              "  0.983846127986908,\n",
              "  0.9846153855323792,\n",
              "  0.9846153855323792,\n",
              "  0.9853846430778503,\n",
              "  0.9846153855323792,\n",
              "  0.9853846430778503,\n",
              "  0.9846153855323792,\n",
              "  0.9853846430778503,\n",
              "  0.9846153855323792,\n",
              "  0.9846153855323792,\n",
              "  0.983846127986908,\n",
              "  0.983846127986908,\n",
              "  0.983846127986908,\n",
              "  0.986923098564148,\n",
              "  0.9846153855323792,\n",
              "  0.9853846430778503,\n",
              "  0.9846153855323792,\n",
              "  0.9830769300460815,\n",
              "  0.9853846430778503,\n",
              "  0.983846127986908,\n",
              "  0.9830769300460815,\n",
              "  0.9846153855323792,\n",
              "  0.9846153855323792,\n",
              "  0.9853846430778503,\n",
              "  0.9846153855323792,\n",
              "  0.983846127986908,\n",
              "  0.983846127986908,\n",
              "  0.9846153855323792,\n",
              "  0.9853846430778503,\n",
              "  0.983846127986908,\n",
              "  0.9853846430778503,\n",
              "  0.9830769300460815,\n",
              "  0.983846127986908,\n",
              "  0.9846153855323792,\n",
              "  0.9846153855323792,\n",
              "  0.9830769300460815,\n",
              "  0.9853846430778503,\n",
              "  0.9830769300460815,\n",
              "  0.986923098564148,\n",
              "  0.983846127986908,\n",
              "  0.9846153855323792,\n",
              "  0.9853846430778503,\n",
              "  0.983846127986908,\n",
              "  0.9846153855323792,\n",
              "  0.9846153855323792,\n",
              "  0.9830769300460815,\n",
              "  0.9846153855323792,\n",
              "  0.9853846430778503,\n",
              "  0.9846153855323792,\n",
              "  0.9830769300460815,\n",
              "  0.9846153855323792,\n",
              "  0.9853846430778503,\n",
              "  0.9861538410186768,\n",
              "  0.9853846430778503,\n",
              "  0.9846153855323792,\n",
              "  0.9830769300460815,\n",
              "  0.9861538410186768,\n",
              "  0.9846153855323792,\n",
              "  0.9853846430778503,\n",
              "  0.9846153855323792,\n",
              "  0.9846153855323792,\n",
              "  0.9853846430778503,\n",
              "  0.9846153855323792,\n",
              "  0.9846153855323792,\n",
              "  0.9846153855323792,\n",
              "  0.9830769300460815,\n",
              "  0.9830769300460815,\n",
              "  0.9823076725006104,\n",
              "  0.9846153855323792,\n",
              "  0.9846153855323792,\n",
              "  0.9861538410186768,\n",
              "  0.9846153855323792,\n",
              "  0.9846153855323792,\n",
              "  0.9846153855323792,\n",
              "  0.9861538410186768,\n",
              "  0.986923098564148,\n",
              "  0.9861538410186768,\n",
              "  0.983846127986908,\n",
              "  0.9830769300460815,\n",
              "  0.983846127986908,\n",
              "  0.9861538410186768,\n",
              "  0.983846127986908,\n",
              "  0.9830769300460815,\n",
              "  0.9853846430778503,\n",
              "  0.9853846430778503,\n",
              "  0.9853846430778503,\n",
              "  0.9846153855323792,\n",
              "  0.9830769300460815,\n",
              "  0.9846153855323792,\n",
              "  0.9846153855323792,\n",
              "  0.9830769300460815,\n",
              "  0.9823076725006104,\n",
              "  0.983846127986908,\n",
              "  0.9738461375236511,\n",
              "  0.9846153855323792,\n",
              "  0.9846153855323792,\n",
              "  0.9846153855323792,\n",
              "  0.9846153855323792,\n",
              "  0.9846153855323792,\n",
              "  0.9846153855323792,\n",
              "  0.9830769300460815,\n",
              "  0.9861538410186768,\n",
              "  0.9846153855323792,\n",
              "  0.9846153855323792,\n",
              "  0.9853846430778503,\n",
              "  0.9846153855323792,\n",
              "  0.9846153855323792,\n",
              "  0.9846153855323792,\n",
              "  0.9846153855323792,\n",
              "  0.9853846430778503,\n",
              "  0.983846127986908,\n",
              "  0.983846127986908,\n",
              "  0.9846153855323792,\n",
              "  0.9846153855323792,\n",
              "  0.986923098564148,\n",
              "  0.9846153855323792,\n",
              "  0.9853846430778503,\n",
              "  0.9830769300460815,\n",
              "  0.9846153855323792,\n",
              "  0.9853846430778503,\n",
              "  0.9846153855323792,\n",
              "  0.983846127986908,\n",
              "  ...]}"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_hist = pd.DataFrame(history.history)\n",
        "df_hist"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "T0EDI4t8Dfix",
        "outputId": "3be8a4a6-e018-4f23-8f1f-a53ba89b75af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          loss  accuracy  val_loss  val_accuracy\n",
              "0     0.045866  0.987683  0.055428      0.983846\n",
              "1     0.045932  0.988196  0.054842      0.983846\n",
              "2     0.046787  0.986656  0.057215      0.981538\n",
              "3     0.049330  0.985630  0.070789      0.977692\n",
              "4     0.050803  0.984860  0.060533      0.981538\n",
              "...        ...       ...       ...           ...\n",
              "1995  0.023139  0.992815  0.074193      0.983077\n",
              "1996  0.021526  0.993841  0.073247      0.983077\n",
              "1997  0.020512  0.994868  0.075091      0.983846\n",
              "1998  0.022185  0.994611  0.075241      0.983846\n",
              "1999  0.022132  0.993585  0.076821      0.984615\n",
              "\n",
              "[2000 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a8700c80-33a1-440f-82cf-0e6bb3777e6c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.045866</td>\n",
              "      <td>0.987683</td>\n",
              "      <td>0.055428</td>\n",
              "      <td>0.983846</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.045932</td>\n",
              "      <td>0.988196</td>\n",
              "      <td>0.054842</td>\n",
              "      <td>0.983846</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.046787</td>\n",
              "      <td>0.986656</td>\n",
              "      <td>0.057215</td>\n",
              "      <td>0.981538</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.049330</td>\n",
              "      <td>0.985630</td>\n",
              "      <td>0.070789</td>\n",
              "      <td>0.977692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.050803</td>\n",
              "      <td>0.984860</td>\n",
              "      <td>0.060533</td>\n",
              "      <td>0.981538</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1995</th>\n",
              "      <td>0.023139</td>\n",
              "      <td>0.992815</td>\n",
              "      <td>0.074193</td>\n",
              "      <td>0.983077</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996</th>\n",
              "      <td>0.021526</td>\n",
              "      <td>0.993841</td>\n",
              "      <td>0.073247</td>\n",
              "      <td>0.983077</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1997</th>\n",
              "      <td>0.020512</td>\n",
              "      <td>0.994868</td>\n",
              "      <td>0.075091</td>\n",
              "      <td>0.983846</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998</th>\n",
              "      <td>0.022185</td>\n",
              "      <td>0.994611</td>\n",
              "      <td>0.075241</td>\n",
              "      <td>0.983846</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999</th>\n",
              "      <td>0.022132</td>\n",
              "      <td>0.993585</td>\n",
              "      <td>0.076821</td>\n",
              "      <td>0.984615</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2000 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a8700c80-33a1-440f-82cf-0e6bb3777e6c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a8700c80-33a1-440f-82cf-0e6bb3777e6c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a8700c80-33a1-440f-82cf-0e6bb3777e6c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_vloss = df_hist['val_loss']\n",
        "y_vloss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGIf9UoFFMV0",
        "outputId": "673973be-d1e1-4caa-eefd-ac70060e4480"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       0.055428\n",
              "1       0.054842\n",
              "2       0.057215\n",
              "3       0.070789\n",
              "4       0.060533\n",
              "          ...   \n",
              "1995    0.074193\n",
              "1996    0.073247\n",
              "1997    0.075091\n",
              "1998    0.075241\n",
              "1999    0.076821\n",
              "Name: val_loss, Length: 2000, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_loss = df_hist['loss']\n",
        "y_loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1gl96TuF68Z",
        "outputId": "5e00a8e3-1783-4643-d6b3-e6e1902cf636"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       0.045866\n",
              "1       0.045932\n",
              "2       0.046787\n",
              "3       0.049330\n",
              "4       0.050803\n",
              "          ...   \n",
              "1995    0.023139\n",
              "1996    0.021526\n",
              "1997    0.020512\n",
              "1998    0.022185\n",
              "1999    0.022132\n",
              "Name: loss, Length: 2000, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "FLcRFrIZF_ST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_len = np.arange(len(y_loss))\n",
        "plt.plot(x_len, y_vloss,\"o\", c='red',markersize=2, label=\"testset_loss\")\n",
        "plt.plot(x_len, y_loss,\"o\", c='blue',markersize=2, label=\"trainset_loss\")\n",
        "\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "Ik6YrEBuGbQx",
        "outputId": "b7937383-2189-4667-ebeb-5f6150366194"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 선형 회귀를 적용하여 \n",
        "- 데이터를 기반으로 미래의 수치를 예측하는 문제"
      ],
      "metadata": {
        "id": "DK1z52TIHna1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "fYfC1gMDHrsO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df= pd.read_csv(\"/content/gdrive/MyDrive/Colab/data/housing.csv\", delim_whitespace=True, header=None) # 공백으로 구분\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "TPo8ZPaaJX0G",
        "outputId": "eada9a2e-9fb9-49e6-85f2-09e88ca20a2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          0     1      2   3      4      5     6       7   8      9     10  \\\n",
              "0    0.00632  18.0   2.31   0  0.538  6.575  65.2  4.0900   1  296.0  15.3   \n",
              "1    0.02731   0.0   7.07   0  0.469  6.421  78.9  4.9671   2  242.0  17.8   \n",
              "2    0.02729   0.0   7.07   0  0.469  7.185  61.1  4.9671   2  242.0  17.8   \n",
              "3    0.03237   0.0   2.18   0  0.458  6.998  45.8  6.0622   3  222.0  18.7   \n",
              "4    0.06905   0.0   2.18   0  0.458  7.147  54.2  6.0622   3  222.0  18.7   \n",
              "..       ...   ...    ...  ..    ...    ...   ...     ...  ..    ...   ...   \n",
              "501  0.06263   0.0  11.93   0  0.573  6.593  69.1  2.4786   1  273.0  21.0   \n",
              "502  0.04527   0.0  11.93   0  0.573  6.120  76.7  2.2875   1  273.0  21.0   \n",
              "503  0.06076   0.0  11.93   0  0.573  6.976  91.0  2.1675   1  273.0  21.0   \n",
              "504  0.10959   0.0  11.93   0  0.573  6.794  89.3  2.3889   1  273.0  21.0   \n",
              "505  0.04741   0.0  11.93   0  0.573  6.030  80.8  2.5050   1  273.0  21.0   \n",
              "\n",
              "         11    12    13  \n",
              "0    396.90  4.98  24.0  \n",
              "1    396.90  9.14  21.6  \n",
              "2    392.83  4.03  34.7  \n",
              "3    394.63  2.94  33.4  \n",
              "4    396.90  5.33  36.2  \n",
              "..      ...   ...   ...  \n",
              "501  391.99  9.67  22.4  \n",
              "502  396.90  9.08  20.6  \n",
              "503  396.90  5.64  23.9  \n",
              "504  393.45  6.48  22.0  \n",
              "505  396.90  7.88  11.9  \n",
              "\n",
              "[506 rows x 14 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ce97cb8e-127d-48d3-b4fc-b63c2be054c7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00632</td>\n",
              "      <td>18.0</td>\n",
              "      <td>2.31</td>\n",
              "      <td>0</td>\n",
              "      <td>0.538</td>\n",
              "      <td>6.575</td>\n",
              "      <td>65.2</td>\n",
              "      <td>4.0900</td>\n",
              "      <td>1</td>\n",
              "      <td>296.0</td>\n",
              "      <td>15.3</td>\n",
              "      <td>396.90</td>\n",
              "      <td>4.98</td>\n",
              "      <td>24.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.02731</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>6.421</td>\n",
              "      <td>78.9</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2</td>\n",
              "      <td>242.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>396.90</td>\n",
              "      <td>9.14</td>\n",
              "      <td>21.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.02729</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>7.185</td>\n",
              "      <td>61.1</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2</td>\n",
              "      <td>242.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>392.83</td>\n",
              "      <td>4.03</td>\n",
              "      <td>34.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.03237</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>6.998</td>\n",
              "      <td>45.8</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3</td>\n",
              "      <td>222.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>394.63</td>\n",
              "      <td>2.94</td>\n",
              "      <td>33.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.06905</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>7.147</td>\n",
              "      <td>54.2</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3</td>\n",
              "      <td>222.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>396.90</td>\n",
              "      <td>5.33</td>\n",
              "      <td>36.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>501</th>\n",
              "      <td>0.06263</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.93</td>\n",
              "      <td>0</td>\n",
              "      <td>0.573</td>\n",
              "      <td>6.593</td>\n",
              "      <td>69.1</td>\n",
              "      <td>2.4786</td>\n",
              "      <td>1</td>\n",
              "      <td>273.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>391.99</td>\n",
              "      <td>9.67</td>\n",
              "      <td>22.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>502</th>\n",
              "      <td>0.04527</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.93</td>\n",
              "      <td>0</td>\n",
              "      <td>0.573</td>\n",
              "      <td>6.120</td>\n",
              "      <td>76.7</td>\n",
              "      <td>2.2875</td>\n",
              "      <td>1</td>\n",
              "      <td>273.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>396.90</td>\n",
              "      <td>9.08</td>\n",
              "      <td>20.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>503</th>\n",
              "      <td>0.06076</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.93</td>\n",
              "      <td>0</td>\n",
              "      <td>0.573</td>\n",
              "      <td>6.976</td>\n",
              "      <td>91.0</td>\n",
              "      <td>2.1675</td>\n",
              "      <td>1</td>\n",
              "      <td>273.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>396.90</td>\n",
              "      <td>5.64</td>\n",
              "      <td>23.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>504</th>\n",
              "      <td>0.10959</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.93</td>\n",
              "      <td>0</td>\n",
              "      <td>0.573</td>\n",
              "      <td>6.794</td>\n",
              "      <td>89.3</td>\n",
              "      <td>2.3889</td>\n",
              "      <td>1</td>\n",
              "      <td>273.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>393.45</td>\n",
              "      <td>6.48</td>\n",
              "      <td>22.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>505</th>\n",
              "      <td>0.04741</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.93</td>\n",
              "      <td>0</td>\n",
              "      <td>0.573</td>\n",
              "      <td>6.030</td>\n",
              "      <td>80.8</td>\n",
              "      <td>2.5050</td>\n",
              "      <td>1</td>\n",
              "      <td>273.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>396.90</td>\n",
              "      <td>7.88</td>\n",
              "      <td>11.9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>506 rows × 14 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ce97cb8e-127d-48d3-b4fc-b63c2be054c7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ce97cb8e-127d-48d3-b4fc-b63c2be054c7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ce97cb8e-127d-48d3-b4fc-b63c2be054c7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YQxkYM0J6EE",
        "outputId": "6a74edd0-0938-4ef7-dd36-830138a1d7a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 506 entries, 0 to 505\n",
            "Data columns (total 14 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   0       506 non-null    float64\n",
            " 1   1       506 non-null    float64\n",
            " 2   2       506 non-null    float64\n",
            " 3   3       506 non-null    int64  \n",
            " 4   4       506 non-null    float64\n",
            " 5   5       506 non-null    float64\n",
            " 6   6       506 non-null    float64\n",
            " 7   7       506 non-null    float64\n",
            " 8   8       506 non-null    int64  \n",
            " 9   9       506 non-null    float64\n",
            " 10  10      506 non-null    float64\n",
            " 11  11      506 non-null    float64\n",
            " 12  12      506 non-null    float64\n",
            " 13  13      506 non-null    float64\n",
            "dtypes: float64(12), int64(2)\n",
            "memory usage: 55.5 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "4zuA5cCiKznF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = df.values\n",
        "x=data[:,0:13]\n",
        "y=data[:,13]\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.3)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OuxcMKXQNfP9",
        "outputId": "70217f24-825b-4486-b317-2b1ec9ff663d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(354, 13)\n",
            "(152, 13)\n",
            "(354,)\n",
            "(152,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(30, input_dim=13, activation='relu'))\n",
        "model.add(Dense(6, activation='relu'))\n",
        "model.add(Dense(1)) #ws\n",
        "\n",
        "model.summary() "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCxYRBVfKHWi",
        "outputId": "91aa713f-75a5-4843-c850-562b5bd4271a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_14 (Dense)             (None, 30)                420       \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 6)                 186       \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 1)                 7         \n",
            "=================================================================\n",
            "Total params: 613\n",
            "Trainable params: 613\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 출력층의 활성화 함수 없앰\n",
        "- Dense 가중합(ws)만 계산\n",
        "- 선형 회귀에서 가중합(ws)이 활성화 함수가 된다\n",
        "- 항등함수를 만든다. (출력층에 활성화 함수가 없는것)"
      ],
      "metadata": {
        "id": "G_5jfTtrLvM-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile( loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "model.fit(x_train, y_train, epochs=200, batch_size=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gnkz_JtULItn",
        "outputId": "7a6ebc0a-71ae-4142-e081-0742455f7a38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "36/36 [==============================] - 1s 3ms/step - loss: 947.3772\n",
            "Epoch 2/200\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 565.6769\n",
            "Epoch 3/200\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 463.4813\n",
            "Epoch 4/200\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 219.8228\n",
            "Epoch 5/200\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 177.5109\n",
            "Epoch 6/200\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 155.3385\n",
            "Epoch 7/200\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 139.8050\n",
            "Epoch 8/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 130.3652\n",
            "Epoch 9/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 111.8800\n",
            "Epoch 10/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 100.0257\n",
            "Epoch 11/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 89.7428\n",
            "Epoch 12/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 81.1078\n",
            "Epoch 13/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 74.0163\n",
            "Epoch 14/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 69.9296\n",
            "Epoch 15/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 67.6143\n",
            "Epoch 16/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 66.6032\n",
            "Epoch 17/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 64.3507\n",
            "Epoch 18/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 64.2302\n",
            "Epoch 19/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 62.4055\n",
            "Epoch 20/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 62.3945\n",
            "Epoch 21/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 61.7306\n",
            "Epoch 22/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 60.4031\n",
            "Epoch 23/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 59.4615\n",
            "Epoch 24/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 59.1646\n",
            "Epoch 25/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 58.6484\n",
            "Epoch 26/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 57.5026\n",
            "Epoch 27/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 56.6096\n",
            "Epoch 28/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 55.8156\n",
            "Epoch 29/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 55.3092\n",
            "Epoch 30/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 54.5697\n",
            "Epoch 31/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 53.9555\n",
            "Epoch 32/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 53.0150\n",
            "Epoch 33/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 52.9874\n",
            "Epoch 34/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 51.7887\n",
            "Epoch 35/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 50.9643\n",
            "Epoch 36/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 49.9795\n",
            "Epoch 37/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 52.0187\n",
            "Epoch 38/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 51.2455\n",
            "Epoch 39/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 48.3817\n",
            "Epoch 40/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 48.2988\n",
            "Epoch 41/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 47.6952\n",
            "Epoch 42/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 46.0864\n",
            "Epoch 43/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 45.5260\n",
            "Epoch 44/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 44.6495\n",
            "Epoch 45/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 44.1618\n",
            "Epoch 46/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 44.1423\n",
            "Epoch 47/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 43.3485\n",
            "Epoch 48/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 43.2179\n",
            "Epoch 49/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 42.5382\n",
            "Epoch 50/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 42.9585\n",
            "Epoch 51/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 42.6403\n",
            "Epoch 52/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 42.1622\n",
            "Epoch 53/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 41.6567\n",
            "Epoch 54/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 42.8779\n",
            "Epoch 55/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 42.5781\n",
            "Epoch 56/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 41.6269\n",
            "Epoch 57/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 40.2597\n",
            "Epoch 58/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 40.3189\n",
            "Epoch 59/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 40.5033\n",
            "Epoch 60/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 39.7526\n",
            "Epoch 61/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 40.0572\n",
            "Epoch 62/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 39.6776\n",
            "Epoch 63/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 38.9195\n",
            "Epoch 64/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 39.3783\n",
            "Epoch 65/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 38.6777\n",
            "Epoch 66/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 38.5687\n",
            "Epoch 67/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 39.0740\n",
            "Epoch 68/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 37.8741\n",
            "Epoch 69/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 38.8807\n",
            "Epoch 70/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 37.8299\n",
            "Epoch 71/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 37.9794\n",
            "Epoch 72/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 37.2136\n",
            "Epoch 73/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 37.1264\n",
            "Epoch 74/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 36.4759\n",
            "Epoch 75/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 37.7615\n",
            "Epoch 76/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 37.3428\n",
            "Epoch 77/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 36.1906\n",
            "Epoch 78/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 36.6888\n",
            "Epoch 79/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 37.4392\n",
            "Epoch 80/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 35.6966\n",
            "Epoch 81/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 37.1094\n",
            "Epoch 82/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 35.8347\n",
            "Epoch 83/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 35.5948\n",
            "Epoch 84/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 35.3935\n",
            "Epoch 85/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 34.7276\n",
            "Epoch 86/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 34.8018\n",
            "Epoch 87/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 34.6300\n",
            "Epoch 88/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 35.7395\n",
            "Epoch 89/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 34.1060\n",
            "Epoch 90/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 33.9413\n",
            "Epoch 91/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 34.9628\n",
            "Epoch 92/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 33.8276\n",
            "Epoch 93/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 33.5702\n",
            "Epoch 94/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 33.4942\n",
            "Epoch 95/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 33.9390\n",
            "Epoch 96/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 34.3501\n",
            "Epoch 97/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 33.7173\n",
            "Epoch 98/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 33.1280\n",
            "Epoch 99/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 33.1564\n",
            "Epoch 100/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 33.4382\n",
            "Epoch 101/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 34.9766\n",
            "Epoch 102/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 33.0137\n",
            "Epoch 103/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 33.6319\n",
            "Epoch 104/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 32.3037\n",
            "Epoch 105/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 34.2041\n",
            "Epoch 106/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 33.1014\n",
            "Epoch 107/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 35.7279\n",
            "Epoch 108/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 33.6918\n",
            "Epoch 109/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 32.6627\n",
            "Epoch 110/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 32.5845\n",
            "Epoch 111/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 32.3328\n",
            "Epoch 112/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 31.8470\n",
            "Epoch 113/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 31.8858\n",
            "Epoch 114/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 32.6310\n",
            "Epoch 115/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 31.5145\n",
            "Epoch 116/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 32.9722\n",
            "Epoch 117/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 32.3028\n",
            "Epoch 118/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 31.5257\n",
            "Epoch 119/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 31.4768\n",
            "Epoch 120/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 31.4383\n",
            "Epoch 121/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 31.5783\n",
            "Epoch 122/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 32.0638\n",
            "Epoch 123/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 31.3494\n",
            "Epoch 124/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 33.7901\n",
            "Epoch 125/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 30.9187\n",
            "Epoch 126/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 30.9800\n",
            "Epoch 127/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 30.9786\n",
            "Epoch 128/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 31.3577\n",
            "Epoch 129/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 31.0060\n",
            "Epoch 130/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 30.3120\n",
            "Epoch 131/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 31.5883\n",
            "Epoch 132/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 30.6636\n",
            "Epoch 133/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 31.1340\n",
            "Epoch 134/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 32.1267\n",
            "Epoch 135/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 31.8347\n",
            "Epoch 136/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 31.4257\n",
            "Epoch 137/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 30.3583\n",
            "Epoch 138/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 33.4044\n",
            "Epoch 139/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 30.4326\n",
            "Epoch 140/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 31.7961\n",
            "Epoch 141/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 30.2312\n",
            "Epoch 142/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 30.1469\n",
            "Epoch 143/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 30.7501\n",
            "Epoch 144/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 29.8628\n",
            "Epoch 145/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 30.4510\n",
            "Epoch 146/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 30.0469\n",
            "Epoch 147/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 30.0376\n",
            "Epoch 148/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 29.9599\n",
            "Epoch 149/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 29.3880\n",
            "Epoch 150/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 29.7576\n",
            "Epoch 151/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 30.7000\n",
            "Epoch 152/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 29.6124\n",
            "Epoch 153/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 30.3170\n",
            "Epoch 154/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 29.1322\n",
            "Epoch 155/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 29.6162\n",
            "Epoch 156/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 30.0981\n",
            "Epoch 157/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 30.6938\n",
            "Epoch 158/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 30.6223\n",
            "Epoch 159/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 30.2513\n",
            "Epoch 160/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 30.0644\n",
            "Epoch 161/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 29.4501\n",
            "Epoch 162/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 30.1291\n",
            "Epoch 163/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 31.8408\n",
            "Epoch 164/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 29.3910\n",
            "Epoch 165/200\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 28.7687\n",
            "Epoch 166/200\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 30.4035\n",
            "Epoch 167/200\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 31.4946\n",
            "Epoch 168/200\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 29.0741\n",
            "Epoch 169/200\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 31.6678\n",
            "Epoch 170/200\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 28.8224\n",
            "Epoch 171/200\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 29.0310\n",
            "Epoch 172/200\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 29.1747\n",
            "Epoch 173/200\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 30.4181\n",
            "Epoch 174/200\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 28.8298\n",
            "Epoch 175/200\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 28.8580\n",
            "Epoch 176/200\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 32.9172\n",
            "Epoch 177/200\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 28.4435\n",
            "Epoch 178/200\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 28.9658\n",
            "Epoch 179/200\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 28.8976\n",
            "Epoch 180/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 30.1946\n",
            "Epoch 181/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 29.0847\n",
            "Epoch 182/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 29.4425\n",
            "Epoch 183/200\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 29.0012\n",
            "Epoch 184/200\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 29.1218\n",
            "Epoch 185/200\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 28.7898\n",
            "Epoch 186/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 28.2983\n",
            "Epoch 187/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 28.9354\n",
            "Epoch 188/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 28.5670\n",
            "Epoch 189/200\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 28.2834\n",
            "Epoch 190/200\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 28.6670\n",
            "Epoch 191/200\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 29.6562\n",
            "Epoch 192/200\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 27.8980\n",
            "Epoch 193/200\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 28.8387\n",
            "Epoch 194/200\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 28.9040\n",
            "Epoch 195/200\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 28.3008\n",
            "Epoch 196/200\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 29.3799\n",
            "Epoch 197/200\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 30.8799\n",
            "Epoch 198/200\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 29.6830\n",
            "Epoch 199/200\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 28.6936\n",
            "Epoch 200/200\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 28.5543\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f03f6fd46d0>"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 회귀 평가\n",
        "- MSE\n",
        "- MAE\n",
        "- 실제 값 - 오차"
      ],
      "metadata": {
        "id": "grEUakg8Nkht"
      }
    }
  ]
}